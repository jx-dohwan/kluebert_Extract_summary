
## ğŸ’¡í”„ë¡œì íŠ¸ ì†Œê°œ

#### 1ï¸âƒ£ ì£¼ì œ : í…ìŠ¤íŠ¸ ì¶”ì¶œ ìš”ì•½<br>
#### 2ï¸âƒ£ ì„¤ëª… : [Fine-tune BERT for Extractive Summarization](https://arxiv.org/pdf/1903.10318v2.pdf)ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œ ìš”ì•½ ëª¨ë¸ êµ¬í˜„<br> 
#### 3ï¸âƒ£ ëª¨ë¸ : Hugging Face [klue/bert-base](https://huggingface.co/klue/bert-base) ëª¨ë¸ ì‚¬ìš©í•˜ì—¬ ì§„í–‰<br><br>

### í•´ë‹¹ í”„ë¡œì íŠ¸ì— ê´€í•œ ìì„¸í•œ ì‚¬í•­ì€ ë¸”ë¡œê·¸ì— ì •ë¦¬í•´ ë†“ì•˜ë‹¤.
- [KlueBERTë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ì„¸ ì¤„ ìš”ì•½ ì„œë¹„ìŠ¤_1(ft.ë…¼ë¬¸ ì†Œê°œ)](https://velog.io/@jx7789/KlueBERT%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%89%B4%EC%8A%A4-%EC%84%B8-%EC%A4%84-%EC%9A%94%EC%95%BD-%EC%84%9C%EB%B9%84%EC%8A%A41ft.%EB%85%BC%EB%AC%B8%EC%86%8C%EA%B0%9C)
- [KlueBERTë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ì„¸ ì¤„ ìš”ì•½ ì„œë¹„ìŠ¤_2(ft.ë°ì´í„°)](https://velog.io/@jx7789/KlueBERT%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%89%B4%EC%8A%A4-%EC%84%B8-%EC%A4%84-%EC%9A%94%EC%95%BD-%EC%84%9C%EB%B9%84%EC%8A%A42ft.%EB%8D%B0%EC%9D%B4%ED%84%B0)
- [KlueBERTë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ì„¸ ì¤„ ìš”ì•½ ì„œë¹„ìŠ¤_3(ft.ëª¨ë¸)](https://velog.io/@jx7789/KlueBERT%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%89%B4%EC%8A%A4-%EC%84%B8-%EC%A4%84-%EC%9A%94%EC%95%BD-%EC%84%9C%EB%B9%84%EC%8A%A43ft.%EB%AA%A8%EB%8D%B8)
- [KlueBERTë¥¼ í™œìš©í•œ ë‰´ìŠ¤ ì„¸ ì¤„ ìš”ì•½ ì„œë¹„ìŠ¤_4(ft.í‰ê°€)](https://velog.io/@jx7789/KlueBERT%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%89%B4%EC%8A%A4-%EC%84%B8-%EC%A4%84-%EC%9A%94%EC%95%BD-%EC%84%9C%EB%B9%84%EC%8A%A44ft.%ED%8F%89%EA%B0%80)

## ë…¼ë¬¸ ì†Œê°œ
- BERTë¥¼ ê¸°ë°˜ìœ¼ë¡œ Simple Classifier, Inter-sentence Transformer, Recurrent Neural Network ì„¸ê°€ì§€ ì¢…ë¥˜ì˜ summarization-specific layersë¥¼ ì¶”ê°€í•˜ì—¬ ì¶”ì¶œ ìš”ì•½ ì‹¤í—˜ ì§„í–‰
<br>

![](img/bertsum.png)
### ë¶€ì—°ì„¤ëª…
- Embedding Multiple Sentences
  - ë¬¸ì¥ì˜ ì‹œì‘ : [CLS], ë¬¸ì¥ì˜ ë : [SEP] ì„ ì‚½ì…í•˜ì—¬ ê¸°ì¡´ [SEP]ë§Œ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ë“¤ì„ êµ¬ë¶„í•˜ë˜ BERTëª¨ë¸ì„ ê°œì„ í–ˆë‹¤.
  - ì—¬ëŸ¬ê°œì˜ [CLS] í† í°ì„ ì‚¬ìš©í•˜ì—¬ ê° ë¬¸ì¥ë“¤ì˜ featureë¥¼ [CLS] í† í°ì— ì €ì¥í•œë‹¤.
- Interval segment Embedding
  - ì—¬ëŸ¬ ë¬¸ì¥ì´ í¬í•¨ëœ ë¬¸ì¥ì—ì„œ ë¬¸ì„œë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©ë¨
  - ìš”ì•½ ë¬¸ì„œì˜ íŠ¹ì„± ìƒ ë‘ê°œ ì´ìƒì˜ ë¬¸ì¥ì´ í¬í•¨ë˜ë¯€ë¡œ ê¸°ë³¸ì˜ ë°©ì‹ê³¼ëŠ” ë‹¤ë¥´ê²Œ ë¬¸ì¥1~4ë¥¼ Aì™€ Bë¥¼ ë²ˆê°ˆì•„ê°€ë©° êµ¬ë¶„
- Summarization Layers
  - BERTë¡œë¶€í„° ë¬¸ì¥ vectorì— ëŒ€í•œ ì •ë³´ë¥¼ ì–»ì€ ë‹¤ìŒì— ì¶”ì¶œ ìš”ì•½ì„ ìœ„í•˜ì—¬ ë¬¸ì„œ ë‹¨ìœ„ì˜ featureë¥¼ ì¡ê¸° ìœ„í•´ ê·¸ ê²°ê´ê°’ ìœ„ì— summarization-specific layersë¥¼ ìŒ“ëŠ”ë‹¤. 
  - Simple Classifier
    - ê¸°ì¡´ BERTì™€ ê°™ì´ Linear layer ë° Sigmoid function
  - Inter-sentence Transformer
    - ë¬¸ì¥ representationsì„ ìœ„í•˜ì—¬ Transformer layerì„ ì‚¬ìš©í•˜ë©° ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” Transformer layerë¡œë¶€í„° ë‚˜ì˜¨ ë¬¸ì¥ vectorë¥¼ sigmoid classifier ë„£ëŠ”ë‹¤. ê·¸ë¦¬ê³  Layerê°€ 2ê°œì¼ ë•Œì˜ ì„±ëŠ¥ì´ ì œì¼ ì¢‹ì•˜ë‹¤.
  - Recurrent Neural Network
    - Transformerì™€ RNNê²°í•©ì‹œ ì„±ëŠ¥ì´ ì¢‹ì•˜ìœ¼ë©° BERT outputì„ LSTM layerë¡œ ë„˜ê²¨ì¤€ë‹¤. ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” sigmoid classifierë¥¼ ì‚¬ìš©í•œë‹¤.


---
## 1. train

```
logdirlocation = 'LOG/KLUE'
os.makedirs(logdirlocation, exist_ok=True)

!python SRC/train.py \
  -mode train \
  -encoder transformer \
  -dropout 0.1 \
  -bert_data_path data/bert_data/train/korean \
  -model_path MODEL/KLUE/bert_transformer_result \
  -lr 2e-3 \
  -visible_gpus 0 \
  -gpu_ranks 0 \
  -world_size 1 \
  -report_every 1000\
  -save_checkpoint_steps 10000 \
  -batch_size 1000 \
  -decay_method noam \
  -train_steps 50000 \
  -accum_count 2 \
  -log_file LOG/KLUE/bert_transformer_result.txt \
  -use_interval true \
  -warmup_steps 10000 \
  -ff_size 2048 \
  -inter_layers 2 \
  -heads 8
     
```

## 2. Test
```
!python SRC/train.py \
  -mode inference \
  -visible_gpus -1 \
  -gpu_ranks -1 \
  -world_size 0 \
  -log_file LOG/KLUE/bert_transformer_result.txt \
  -test_from MODEL/KLUE/bert_transformer_result/model_step_50000.pt \
  -input_text raw_data/valid/valid_0.txt
```

## 3. [Rouge](https://github.com/jx-dohwan/kluebert_Extract_summary/blob/main/rouge_evaluation.ipynb)
---




