{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPyNceW0BEua",
        "outputId": "f7ced648-c5d5-4905-9ba7-4b1c78f8b92c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install multiprocess\n",
        "!pip install tensorboardX\n",
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcQCpV2F3pHz",
        "outputId": "6bfab0c1-d0d2-48ad-e224-67cb1c5318cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.6\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill, multiprocess\n",
            "Successfully installed dill-0.3.6 multiprocess-0.70.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path '/content/pyrouge/tools/ROUGE-1.5.5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHs_wTK54nzT",
        "outputId": "6dcf572e-8b92-4bfe-ace1-c08991221c56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyrouge\n",
            "  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191620 sha256=e79aa0f2f6e60356c455faf91a7dd0058f15ec93817b870688ef9a9234580673\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/85/fd/ccd28e53c9f6a691e6ea96050a0cad95f9a4a6361269d765ca\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "  Downloading https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m202.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.8/dist-packages (0.1.3)\n",
            "Name: pyrouge\n",
            "Version: 0.1.3\n",
            "Summary: A Python wrapper for the ROUGE summarization evaluation package.\n",
            "Home-page: https://github.com/noutenki/pyrouge\n",
            "Author: Benjamin Heinzerling, Anders Johannsen\n",
            "Author-email: benjamin.heinzerling@h-its.org\n",
            "License: LICENSE.txt\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "Cloning into 'pyrouge'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Total 393 (delta 0), reused 0 (delta 0), pack-reused 393\u001b[K\n",
            "Receiving objects: 100% (393/393), 298.74 KiB | 2.53 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "2023-03-04 01:54:31,996 [MainThread  ] [INFO ]  Set ROUGE home directory to /content/pyrouge/tools/ROUGE-1.5.5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NRPxVhuL1zoz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import easydict\n",
        "from rouge import Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YgIb22wn1zpD"
      },
      "outputs": [],
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/valid'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 총 4만개는 학습시간이 60시간 걸림 그래서 각각 5%데이터로 해보자"
      ],
      "metadata": {
        "id": "5nAlMQI_zriQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Kl63oe5B1zpI"
      },
      "outputs": [],
      "source": [
        "def data_load(DATAPATH):\n",
        "    filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "    filenames.sort()\n",
        "    filenames\n",
        "    list_dic = []\n",
        "\n",
        "    for file in filenames:\n",
        "      filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "      with open(filelocation, 'r') as json_file:\n",
        "        data = json.load(json_file)['documents']\n",
        "        data_len = round(len(data) * 0.05)\n",
        "        data = data[:data_len]\n",
        "        for x in tqdm (range(len(data))):\n",
        "          text = data[x]['text']\n",
        "          text = str(text).replace('\"', \"'\")\n",
        "\n",
        "          extractive = data[x]['extractive']\n",
        "          for index, value in enumerate(extractive):\n",
        "            if value == None:\n",
        "              extractive[index] = 0\n",
        "\n",
        "          p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "          texts = p.findall(text)\n",
        "\n",
        "          sentences = []\n",
        "          for t in texts:\n",
        "            sentence = t[:-3]\n",
        "            sentences.append(sentence)\n",
        "\n",
        "          mydict = {}\n",
        "          mydict['text'] = sentences\n",
        "          mydict['extractive'] = extractive\n",
        "          list_dic.append(mydict)\n",
        "\n",
        "    return list_dic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_dic = data_load(DATAPATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64OTybY4ET57",
        "outputId": "0b2e29b4-424e-476e-b855-44cf6d54ec04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:00<00:00, 15300.23it/s]\n",
            "100%|██████████| 1506/1506 [00:00<00:00, 10897.66it/s]\n",
            "100%|██████████| 350/350 [00:00<00:00, 9149.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6MHG0vnz7sj",
        "outputId": "fd6ecea7-fafa-454b-e690-9ab63dc35f2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2006"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformer vs rnn vs classification\n",
        "- colab computing 부족으로 실행중단\n",
        "- 논문에서는 transformer가 가장 좋다고 소개했기 때문에 transformer를 가지고 최종 학습 및 평가 진행"
      ],
      "metadata": {
        "id": "elgA0t7rSkLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_texts = []\n",
        "for j in tqdm(range(len(list_dic))):\n",
        "    selected_texts.append([list_dic[j]['text'][i] for i in list_dic[j]['extractive']])\n",
        "\n",
        "input_text2 = []\n",
        "for i in tqdm(range(len(list_dic))):\n",
        "    input_text2.append(list_dic[i]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-yxnpc2SsTZ",
        "outputId": "4bfb130d-3283-4d12-be05-743e9beb4c97"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2006/2006 [00:00<00:00, 362412.73it/s]\n",
            "100%|██████████| 2006/2006 [00:00<00:00, 740714.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys \n",
        "sys.path.append(\"/content/drive/MyDrive/인공지능/추출요약\")\n",
        "from SRC.train import new_inference"
      ],
      "metadata": {
        "id": "BRdLtBy_SwQK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_path = \"/content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_1000.pt\"\n",
        "rnn_path = \"/content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_1000.pt\"\n",
        "classification_path = \"/content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_1000.pt\""
      ],
      "metadata": {
        "id": "bB8AdMBYSzIA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_hypotheses = []\n",
        "for i in tqdm(range(len(input_text2))):\n",
        "    transformer_hypotheses.append(new_inference(input_text2[i], transformer_path, \"transformer\", \"0\", \"0\",1))\n",
        "\n",
        "rnn_hypotheses = []\n",
        "for i in tqdm(range(len(input_text2))):\n",
        "    rnn_hypotheses.append(new_inference(input_text2[i], rnn_path, \"rnn\", \"0\", \"0\",1))\n",
        "\n",
        "classification_hypotheses = []\n",
        "for i in tqdm(range(len(input_text2))):\n",
        "    classification_hypotheses.append(new_inference(input_text2[i], classification_path, \"classifier\", \"0\", \"0\",1))"
      ],
      "metadata": {
        "id": "3kLZVDQnTWw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_references_list = []\n",
        "transformer_hypotheses_list = []\n",
        "\n",
        "for re, hy in tqdm(zip(selected_texts, transformer_hypotheses)):\n",
        "    transformer_references_list.append(' '.join(re))\n",
        "    transformer_hypotheses_list.append(' '.join(hy))\n",
        "\n",
        "rnn_references_list = []\n",
        "rnn_hypotheses_list = []\n",
        "\n",
        "for re, hy in tqdm(zip(selected_texts, rnn_hypotheses)):\n",
        "    rnn_references_list.append(' '.join(re))\n",
        "    rnn_hypotheses_list.append(' '.join(hy))\n",
        "\n",
        "classification_references_list = []\n",
        "classification_hypotheses_list = []\n",
        "\n",
        "for re, hy in tqdm(zip(selected_texts, classification_hypotheses)):\n",
        "    classification_references_list.append(' '.join(re))\n",
        "    classification_hypotheses_list.append(' '.join(hy))"
      ],
      "metadata": {
        "id": "0VIofGRET6kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_f_r_summary(hypotheses, references):\n",
        "    rouge = Rouge()\n",
        "\n",
        "    scores = rouge.get_scores(hypotheses, references, avg=True)\n",
        "    rouge_f_1 = scores['rouge-1']['f']\n",
        "    rouge_r_1 = scores['rouge-1']['r']\n",
        "    rouge_f_2 = scores['rouge-2']['f']\n",
        "    rouge_r_2 = scores['rouge-2']['r']\n",
        "    rouge_f_L = scores['rouge-l']['f']\n",
        "    rouge_r_L = scores['rouge-l']['r']\n",
        "    return rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L\n",
        "\n",
        "rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L= rouge_f_r_summary(transformer_hypotheses_list, transformer_references_list)\n",
        "print(\"--------------------------Rouge-F---------------------------\")\n",
        "print(\"Rouge-F_1:\", rouge_f_1)\n",
        "print(\"Rouge-F_2:\", rouge_f_2)\n",
        "print(\"Rouge-F_L:\", rouge_f_L)\n",
        "print(\"\")\n",
        "print(\"--------------------------Rouge-R---------------------------\")\n",
        "print(\"Rouge-R_1:\", rouge_r_1)\n",
        "print(\"Rouge-R_2:\", rouge_r_2)\n",
        "print(\"Rouge-R_L:\", rouge_r_L)\n"
      ],
      "metadata": {
        "id": "wrqVZcK_UJEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(zip([rouge_f_1], [rouge_f_2] , [rouge_f_L], [rouge_r_1], [rouge_r_2], [rouge_r_L] ),\n",
        "                  columns=['rouge_f_1','rouge_f_L',  'rouge_f_2', 'rouge_r_1', 'rouge_r_2', 'rouge_r_L'])\n",
        "df.to_csv(\"/content/drive/MyDrive/인공지능/추출요약/rouge_scores/transformer_1000_score.csv\", mode='w', index = False)\n"
      ],
      "metadata": {
        "id": "WrsxKm9iUmk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_f_r_summary(hypotheses, references):\n",
        "    rouge = Rouge()\n",
        "\n",
        "    scores = rouge.get_scores(hypotheses, references, avg=True)\n",
        "    rouge_f_1 = scores['rouge-1']['f']\n",
        "    rouge_r_1 = scores['rouge-1']['r']\n",
        "    rouge_f_2 = scores['rouge-2']['f']\n",
        "    rouge_r_2 = scores['rouge-2']['r']\n",
        "    rouge_f_L = scores['rouge-l']['f']\n",
        "    rouge_r_L = scores['rouge-l']['r']\n",
        "    return rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L\n",
        "\n",
        "rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L= rouge_f_r_summary(rnn_hypotheses_list, rnn_references_list)\n",
        "print(\"--------------------------Rouge-F---------------------------\")\n",
        "print(\"Rouge-F_1:\", rouge_f_1)\n",
        "print(\"Rouge-F_2:\", rouge_f_2)\n",
        "print(\"Rouge-F_L:\", rouge_f_L)\n",
        "print(\"\")\n",
        "print(\"--------------------------Rouge-R---------------------------\")\n",
        "print(\"Rouge-R_1:\", rouge_r_1)\n",
        "print(\"Rouge-R_2:\", rouge_r_2)\n",
        "print(\"Rouge-R_L:\", rouge_r_L)\n"
      ],
      "metadata": {
        "id": "CJliCrWxUcli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(zip([rouge_f_1], [rouge_f_2] , [rouge_f_L], [rouge_r_1], [rouge_r_2], [rouge_r_L] ),\n",
        "                  columns=['rouge_f_1','rouge_f_L',  'rouge_f_2', 'rouge_r_1', 'rouge_r_2', 'rouge_r_L'])\n",
        "df.to_csv(\"/content/drive/MyDrive/인공지능/추출요약/rouge_scores/rnn_1000_score.csv\", mode='w', index = False)\n"
      ],
      "metadata": {
        "id": "AicjI-10Utx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_f_r_summary(hypotheses, references):\n",
        "    rouge = Rouge()\n",
        "\n",
        "    scores = rouge.get_scores(hypotheses, references, avg=True)\n",
        "    rouge_f_1 = scores['rouge-1']['f']\n",
        "    rouge_r_1 = scores['rouge-1']['r']\n",
        "    rouge_f_2 = scores['rouge-2']['f']\n",
        "    rouge_r_2 = scores['rouge-2']['r']\n",
        "    rouge_f_L = scores['rouge-l']['f']\n",
        "    rouge_r_L = scores['rouge-l']['r']\n",
        "    return rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L\n",
        "\n",
        "rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L= rouge_f_r_summary(classification_hypotheses_list, classification_references_list)\n",
        "print(\"--------------------------Rouge-F---------------------------\")\n",
        "print(\"Rouge-F_1:\", rouge_f_1)\n",
        "print(\"Rouge-F_2:\", rouge_f_2)\n",
        "print(\"Rouge-F_L:\", rouge_f_L)\n",
        "print(\"\")\n",
        "print(\"--------------------------Rouge-R---------------------------\")\n",
        "print(\"Rouge-R_1:\", rouge_r_1)\n",
        "print(\"Rouge-R_2:\", rouge_r_2)\n",
        "print(\"Rouge-R_L:\", rouge_r_L)\n"
      ],
      "metadata": {
        "id": "vvSeq-QZUi7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(zip([rouge_f_1], [rouge_f_2] , [rouge_f_L], [rouge_r_1], [rouge_r_2], [rouge_r_L] ),\n",
        "                  columns=['rouge_f_1','rouge_f_L',  'rouge_f_2', 'rouge_r_1', 'rouge_r_2', 'rouge_r_L'])\n",
        "df.to_csv(\"/content/drive/MyDrive/인공지능/추출요약/rouge_scores/classification_1000_score.csv\", mode='w', index = False)\n"
      ],
      "metadata": {
        "id": "r7w6j4rBUxbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 모델 : transformer 5만 step"
      ],
      "metadata": {
        "id": "dTefLS90SfAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 원본 본문 및 요약 추출"
      ],
      "metadata": {
        "id": "ubGpLblHEbXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_texts = []\n",
        "for j in tqdm(range(len(list_dic))):\n",
        "    selected_texts.append([list_dic[j]['text'][i] for i in list_dic[j]['extractive']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wk5NZa0FPNa",
        "outputId": "8670cca0-73cb-4ee8-edec-0d7f8457c382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2006/2006 [00:00<00:00, 263647.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiunOkDSFRtj",
        "outputId": "25126445-48a5-4d9c-d9e1-99ef02cba353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[1] 취소소송은 처분 등이 있음을 안 날부터 90일 이내에 제기하여야 하고,',\n",
              " '다만 허가에 붙은 기한이 그 허가된 사업의 성질상 부당하게 짧은 경우에는 이를 그 허가 자체의 존속기간이 아니라 그 허가조건의 존속기간으로 보아 그 기한이 도래함으로써 그 조건의 개정을 고려한다는 뜻으로 해석할 수 있다.',\n",
              " '이 공사기간을 사도개설허가 자체의 존속기간(유효기간)으로 볼 수 없다는 이유로 사도개설허가가 당연히 실효되는 것은 아니라고 한 사례.']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예측 추출요약 - 4만개 60시간 걸림 각각 5%데이터로로 해보자"
      ],
      "metadata": {
        "id": "zPQ2IQL4Efi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJe5Utu21zpP",
        "outputId": "3dbced46-4332-4563-9b7f-f9ea1f42fb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2006/2006 [00:00<00:00, 963556.32it/s]\n"
          ]
        }
      ],
      "source": [
        "input_text2 = []\n",
        "for i in tqdm(range(len(list_dic))):\n",
        "    input_text2.append(list_dic[i]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnUBrBnZ1zpW",
        "outputId": "bd76d3c4-62a2-4822-a219-79689cca49a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[1] 취소소송은 처분 등이 있음을 안 날부터 90일 이내에 제기하여야 하고,',\n",
              " '처분 등이 있은 날부터 1년을 경과하면',\n",
              " '제기하지 못하며( 행정소송법 제20조 제1항, 제2항), 청구취지를 변경하여 구 소가 취하되고 새로운 소가 제기된 것으로 변경되었을 때에 새로운 소에 대한 제소기간의 준수 등은 원칙적으로 소의 변경이 있은 때를 기준으로 하여야 한다.',\n",
              " '[2] 일반적으로 행정처분에 효력기간이 정하여져 있는 경우에는 그 기간의 경과로 그 행정처분의 효력은 상실되며,',\n",
              " '다만 허가에 붙은 기한이 그 허가된 사업의 성질상 부당하게 짧은 경우에는 이를 그 허가 자체의 존속기간이 아니라 그 허가조건의 존속기간으로 보아 그 기한이 도래함으로써 그 조건의 개정을 고려한다는 뜻으로 해석할 수 있다.',\n",
              " '[3] 사도개설허가에서 정해진 공사기간 내에 사도로 준공검사를 받지 못한 경우,',\n",
              " '이 공사기간을 사도개설허가 자체의 존속기간(유효기간)으로 볼 수 없다는 이유로 사도개설허가가 당연히 실효되는 것은 아니라고 한 사례.']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "input_text2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbuAAl4V1zpT",
        "outputId": "b0316219-bf2d-43ab-cd65-1b3aa61f87d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2006"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(input_text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SilT2k9W1zpZ"
      },
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append(\"/content/drive/MyDrive/인공지능/추출요약\")\n",
        "from SRC.train import new_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdbUAhYy1zpc",
        "outputId": "f6983c84-a74a-44f7-8b12-6a19185508e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function SRC.train.new_inference(input_data, test_from, encoder, visible_gpus, gpu_ranks, world_size)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "new_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhFkmy4I1zpf"
      },
      "outputs": [],
      "source": [
        "test_from = \"/content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer_result/model_step_50000.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69qfoMMD1zpi"
      },
      "outputs": [],
      "source": [
        "# test = new_inference(input_text2[0], test_from, \"transformer\", \"0\", \"0\",1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test)"
      ],
      "metadata": {
        "id": "eY2ok4IT95rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "for i in tqdm(range(len(input_text2))):\n",
        "    hypotheses.append(new_inference(input_text2[i], test_from, \"transformer\", \"0\", \"0\",1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeTtYfLNs7Q6",
        "outputId": "67f15b13-5b74-4cdf-e3b1-2ffa6dd0629a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2006/2006 [3:07:54<00:00,  5.62s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKYRegRK1zpk"
      },
      "source": [
        "## 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 한 문장 평가"
      ],
      "metadata": {
        "id": "5wScdRslvjW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def rouge_f_r_summary(hypotheses, references):\n",
        "#     rouge = Rouge()\n",
        "\n",
        "#     reference = ' '.join(references)\n",
        "#     hypothese = ' '.join(hypotheses)\n",
        "\n",
        "#     scores = rouge.get_scores(hypothese, reference, avg=True)\n",
        "#     rouge_f_1 = scores['rouge-1']['f']\n",
        "#     rouge_r_1 = scores['rouge-1']['r']\n",
        "#     rouge_f_2 = scores['rouge-2']['f']\n",
        "#     rouge_r_2 = scores['rouge-2']['r']\n",
        "#     rouge_f_L = scores['rouge-l']['f']\n",
        "#     rouge_r_L = scores['rouge-l']['r']\n",
        "#     return rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L"
      ],
      "metadata": {
        "id": "ze0P0aOkHndA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L= rouge_f_r_summary(test, selected_texts[0])\n",
        "# print(\"--------------------------Rouge-F---------------------------\")\n",
        "# print(\"Rouge-F_1:\", rouge_f_1)\n",
        "# print(\"Rouge-F_2:\", rouge_f_2)\n",
        "# print(\"Rouge-F_L:\", rouge_f_L)\n",
        "# print(\"\")\n",
        "# print(\"--------------------------Rouge-R---------------------------\")\n",
        "# print(\"Rouge-R_1:\", rouge_r_1)\n",
        "# print(\"Rouge-R_2:\", rouge_r_2)\n",
        "# print(\"Rouge-R_L:\", rouge_r_L)\n"
      ],
      "metadata": {
        "id": "sUtvXcJmIItk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전체 평가"
      ],
      "metadata": {
        "id": "mqtXz4rusiPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "references_list = []\n",
        "hypotheses_list = []\n",
        "\n",
        "for re, hy in tqdm(zip(selected_texts, hypotheses)):\n",
        "    references_list.append(' '.join(re))\n",
        "    hypotheses_list.append(' '.join(hy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUAB3sjksELs",
        "outputId": "289dc7b0-607d-4e53-8686-bf9575f2e92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2006it [00:00, 402572.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_f_r_summary(hypotheses, references):\n",
        "    rouge = Rouge()\n",
        "\n",
        "    scores = rouge.get_scores(hypotheses, references, avg=True)\n",
        "    rouge_f_1 = scores['rouge-1']['f']\n",
        "    rouge_r_1 = scores['rouge-1']['r']\n",
        "    rouge_f_2 = scores['rouge-2']['f']\n",
        "    rouge_r_2 = scores['rouge-2']['r']\n",
        "    rouge_f_L = scores['rouge-l']['f']\n",
        "    rouge_r_L = scores['rouge-l']['r']\n",
        "    return rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L\n",
        "\n",
        "rouge_f_1, rouge_f_L, rouge_f_2, rouge_r_1, rouge_r_2, rouge_r_L= rouge_f_r_summary(hypotheses_list, references_list)\n",
        "print(\"--------------------------Rouge-F---------------------------\")\n",
        "print(\"Rouge-F_1:\", rouge_f_1)\n",
        "print(\"Rouge-F_2:\", rouge_f_2)\n",
        "print(\"Rouge-F_L:\", rouge_f_L)\n",
        "print(\"\")\n",
        "print(\"--------------------------Rouge-R---------------------------\")\n",
        "print(\"Rouge-R_1:\", rouge_r_1)\n",
        "print(\"Rouge-R_2:\", rouge_r_2)\n",
        "print(\"Rouge-R_L:\", rouge_r_L)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClzH_71YujSA",
        "outputId": "bb0d703e-2240-4ccf-f557-7cbf2c0c8074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------Rouge-F---------------------------\n",
            "Rouge-F_1: 0.4774364113055629\n",
            "Rouge-F_2: 0.4314373358893575\n",
            "Rouge-F_L: 0.4745759762675957\n",
            "\n",
            "--------------------------Rouge-R---------------------------\n",
            "Rouge-R_1: 0.49247511414743644\n",
            "Rouge-R_2: 0.4450575426622147\n",
            "Rouge-R_L: 0.4895565404314038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(zip([rouge_f_1], [rouge_f_2] , [rouge_f_L], [rouge_r_1], [rouge_r_2], [rouge_r_L] ),\n",
        "                  columns=['rouge_f_1','rouge_f_L',  'rouge_f_2', 'rouge_r_1', 'rouge_r_2', 'rouge_r_L'])\n",
        "df.to_csv(\"/content/drive/MyDrive/인공지능/추출요약/rouge_scores/transformer_50000_score.csv\", mode='w', index = False)\n"
      ],
      "metadata": {
        "id": "uP0uA5m6wc_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8a617mFlkRNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0ac9e01a0f3ba97c7c17f2745398d74be6a324c8cce3f46dc15273729a55a213"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}