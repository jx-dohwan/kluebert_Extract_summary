{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1WQYN_92WMhuEKDj8DnhLUQwlsvYPyZTU",
      "authorship_tag": "ABX9TyMMo/BDG7WrbZZMwJpFJCRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jx-dohwan/kluebert_Extract_summary/blob/main/kluebert_Extract_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치"
      ],
      "metadata": {
        "id": "5ZBy3xvviYUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mecab"
      ],
      "metadata": {
        "id": "lUMFREYyiu_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install konlpy"
      ],
      "metadata": {
        "id": "Qvf7JdfuiaGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0105c0d5-5ad5-4f52-f92a-2276b1e3a3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "id": "vc1bORuWinRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0ae749-efde-4298-eda6-c6528586a4b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,970 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,386 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,131 kB]\n",
            "Fetched 6,844 kB in 5s (1,278 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install curl git"
      ],
      "metadata": {
        "id": "HEDJMAoriq3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127361f2-1724-44c8-d660-02c1a84a6e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.68.0-1ubuntu2.15).\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.10).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "id": "pvxxuf7PisWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85941e1b-40a3-4a5f-aa3b-edbf2c26b33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Install mecab-ko\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0   429k      0  0:00:03  0:00:03 --:--:-- 1200k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /usr/bin/grep\n",
            "checking for egrep... /usr/bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /usr/bin/sed\n",
            "checking for fgrep... /usr/bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld -m elf_x86_64\n",
            "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld -m elf_x86_64\n",
            "checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            "   30 | std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "\u001b[01m\u001b[Kchar_property.cpp:\u001b[m\u001b[K In static member function '\u001b[01m\u001b[Kstatic bool MeCab::CharProperty::compile(const char*, const char*, const char*)\u001b[m\u001b[K':\n",
            "\u001b[01m\u001b[Kchar_property.cpp:194:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kvoid* memset(void*, int, size_t)\u001b[m\u001b[K' clearing an object of non-trivial type '\u001b[01m\u001b[Kstruct MeCab::CharInfo\u001b[m\u001b[K'; use assignment or value-initialization instead [\u001b[01;35m\u001b[K-Wclass-memaccess\u001b[m\u001b[K]\n",
            "  194 |       std::memset(&c, 0, sizeof(c)\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "      |                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[Kchar_property.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kchar_property.h:16:8:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K'\u001b[01m\u001b[Kstruct MeCab::CharInfo\u001b[m\u001b[K' declared here\n",
            "   16 | struct \u001b[01;36m\u001b[KCharInfo\u001b[m\u001b[K {\n",
            "      |        \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            "   25 | char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "      |       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/9/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/9/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/9 -L/usr/lib/gcc/x86_64-linux-gnu/9/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/9/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/9/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/9/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/9/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /usr/bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /usr/bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /usr/bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /usr/bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /usr/bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /usr/bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /usr/bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  6868k      0  0:00:07  0:00:07 --:--:-- 10.6M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: https://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./XSN.csv ... 124\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./MM.csv ... 453\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./J.csv ... 416\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./NR.csv ... 482\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./VX.csv ... 125\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./EP.csv ... 51\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./NP.csv ... 342\n",
            "reading ./Person.csv ... 196459\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /usr/bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "Unpacking objects: 100% (17/17), 59.65 KiB | 1.75 MiB/s, done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /tmp/mecab-python-0.996\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp38-cp38-linux_x86_64.whl size=185152 sha256=37344a67116a68111e06004dcd9095a0ff5987be37efc7e2e44fd5fa5870a025\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/88/e7/a947778cce3c142d5721c0629e05db7b09979d3a973277ec2f\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\u001b[33m\n",
            "\u001b[0mFailed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "  Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiprocess"
      ],
      "metadata": {
        "id": "Kp1lfZ5GizTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install multiprocess"
      ],
      "metadata": {
        "id": "6Cxum78FitjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc21f16-b554-4ae6-860b-44d32457a801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from multiprocess) (0.3.6)\n",
            "Installing collected packages: multiprocess\n",
            "Successfully installed multiprocess-0.70.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers"
      ],
      "metadata": {
        "id": "4J2FY9u7i2tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "MXwPCEKRi1Fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7d107d-60bd-4666-fb48-740ba9b3023c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyRouge"
      ],
      "metadata": {
        "id": "LTMKtjw8i62a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path '/content/pyrouge/tools/ROUGE-1.5.5'"
      ],
      "metadata": {
        "id": "sey_OHqFi5JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dce83a8-36d1-4415-c80e-08de2860beb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyrouge\n",
            "  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191620 sha256=7d8f8d9904777feeb42fd5915bfa988413c2400415f5f97c473d8fda04d27a3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/85/fd/ccd28e53c9f6a691e6ea96050a0cad95f9a4a6361269d765ca\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "  Downloading https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m202.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.8/dist-packages (0.1.3)\n",
            "Name: pyrouge\n",
            "Version: 0.1.3\n",
            "Summary: A Python wrapper for the ROUGE summarization evaluation package.\n",
            "Home-page: https://github.com/noutenki/pyrouge\n",
            "Author: Benjamin Heinzerling, Anders Johannsen\n",
            "Author-email: benjamin.heinzerling@h-its.org\n",
            "License: LICENSE.txt\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "Cloning into 'pyrouge'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Total 393 (delta 0), reused 0 (delta 0), pack-reused 393\u001b[K\n",
            "Receiving objects: 100% (393/393), 298.74 KiB | 21.34 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "2023-02-19 11:53:24,046 [MainThread  ] [INFO ]  Set ROUGE home directory to /content/pyrouge/tools/ROUGE-1.5.5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libxml-parser-perl"
      ],
      "metadata": {
        "id": "pdXNcunLi9G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18efa57-d96c-4bb3-cebf-7150667bec9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libauthen-sasl-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl netbase\n",
            "  perl-openssl-defaults\n",
            "Suggested packages:\n",
            "  libdigest-hmac-perl libgssapi-perl libcrypt-ssleay-perl libauthen-ntlm-perl\n",
            "The following NEW packages will be installed:\n",
            "  libauthen-sasl-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl\n",
            "  libxml-parser-perl netbase perl-openssl-defaults\n",
            "0 upgraded, 30 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 1,695 kB of archives.\n",
            "After this operation, 5,550 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 netbase all 6.1 [13.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libdata-dump-perl all 1.23-1 [27.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libhttp-date-perl all 6.05-1 [9,920 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfile-listing-perl all 6.04-1 [9,774 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libfont-afm-perl all 1.20-2 [13.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libhtml-tagset-perl all 3.20-4 [12.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 liburi-perl all 1.76-2 [77.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libhtml-parser-perl amd64 3.72-5 [86.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 liblwp-mediatypes-perl all 6.04-1 [19.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libhttp-message-perl all 6.22-1 [76.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libhtml-form-perl all 6.07-1 [22.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 libhtml-tree-perl all 5.07-2 [200 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libhtml-format-perl all 2.12-1 [41.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 libhttp-cookies-perl all 6.08-1 [18.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libhttp-daemon-perl all 6.06-1ubuntu0.1 [22.0 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 libhttp-negotiate-perl all 6.01-1 [12.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 perl-openssl-defaults amd64 4 [7,192 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libnet-ssleay-perl amd64 1.88-2ubuntu1 [291 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal/main amd64 libio-socket-ssl-perl all 2.067-1 [176 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libnet-http-perl all 6.19-1 [22.8 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libtry-tiny-perl all 0.30-1 [20.5 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 libwww-robotrules-perl all 6.02-1 [12.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libwww-perl all 6.43-1 [140 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu focal/main amd64 liblwp-protocol-https-perl all 6.07-2ubuntu2 [8,560 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu focal/main amd64 libmailtools-perl all 2.21-1 [80.7 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu focal/main amd64 libxml-parser-perl amd64 2.46-1 [193 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu focal/main amd64 libauthen-sasl-perl all 2.1600-1 [48.7 kB]\n",
            "Fetched 1,695 kB in 6s (305 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 30.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package netbase.\n",
            "(Reading database ... 128126 files and directories currently installed.)\n",
            "Preparing to unpack .../00-netbase_6.1_all.deb ...\n",
            "Unpacking netbase (6.1) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../01-libdata-dump-perl_1.23-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.23-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../02-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../03-libhttp-date-perl_6.05-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.05-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../04-libfile-listing-perl_6.04-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.04-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../05-libfont-afm-perl_1.20-2_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-2) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../06-libhtml-tagset-perl_3.20-4_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-4) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../07-liburi-perl_1.76-2_all.deb ...\n",
            "Unpacking liburi-perl (1.76-2) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../08-libhtml-parser-perl_3.72-5_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-5) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../09-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../10-liblwp-mediatypes-perl_6.04-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../11-libhttp-message-perl_6.22-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.22-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../12-libhtml-form-perl_6.07-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.07-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../13-libhtml-tree-perl_5.07-2_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-2) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../14-libhtml-format-perl_2.12-1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../15-libhttp-cookies-perl_6.08-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.08-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../16-libhttp-daemon-perl_6.06-1ubuntu0.1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.06-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../17-libhttp-negotiate-perl_6.01-1_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.01-1) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../18-perl-openssl-defaults_4_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (4) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl.\n",
            "Preparing to unpack .../19-libnet-ssleay-perl_1.88-2ubuntu1_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl (1.88-2ubuntu1) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../20-libio-socket-ssl-perl_2.067-1_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.067-1) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../21-libnet-http-perl_6.19-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.19-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../22-libtry-tiny-perl_0.30-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.30-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../23-libwww-robotrules-perl_6.02-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.02-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../24-libwww-perl_6.43-1_all.deb ...\n",
            "Unpacking libwww-perl (6.43-1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../25-liblwp-protocol-https-perl_6.07-2ubuntu2_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.07-2ubuntu2) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../26-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../27-libmailtools-perl_2.21-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.21-1) ...\n",
            "Selecting previously unselected package libxml-parser-perl.\n",
            "Preparing to unpack .../28-libxml-parser-perl_2.46-1_amd64.deb ...\n",
            "Unpacking libxml-parser-perl (2.46-1) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../29-libauthen-sasl-perl_2.1600-1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up libhttp-date-perl (6.05-1) ...\n",
            "Setting up libfile-listing-perl (6.04-1) ...\n",
            "Setting up libfont-afm-perl (1.20-2) ...\n",
            "Setting up libhtml-tagset-perl (3.20-4) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.04-1) ...\n",
            "Setting up libtry-tiny-perl (0.30-1) ...\n",
            "Setting up perl-openssl-defaults:amd64 (4) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libdata-dump-perl (1.23-1) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up netbase (6.1) ...\n",
            "Setting up liburi-perl (1.76-2) ...\n",
            "Setting up libhttp-message-perl (6.22-1) ...\n",
            "Setting up libnet-ssleay-perl (1.88-2ubuntu1) ...\n",
            "Setting up libhttp-negotiate-perl (6.01-1) ...\n",
            "Setting up libhttp-cookies-perl (6.08-1) ...\n",
            "Setting up libnet-http-perl (6.19-1) ...\n",
            "Setting up libwww-robotrules-perl (6.02-1) ...\n",
            "Setting up libhttp-daemon-perl (6.06-1ubuntu0.1) ...\n",
            "Setting up libhtml-parser-perl (3.72-5) ...\n",
            "Setting up libio-socket-ssl-perl (2.067-1) ...\n",
            "Setting up libhtml-form-perl (6.07-1) ...\n",
            "Setting up libhtml-tree-perl (5.07-2) ...\n",
            "Setting up libhtml-format-perl (2.12-1) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libmailtools-perl (2.21-1) ...\n",
            "Setting up liblwp-protocol-https-perl (6.07-2ubuntu2) ...\n",
            "Setting up libwww-perl (6.43-1) ...\n",
            "Setting up libxml-parser-perl (2.46-1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd pyrouge/tools/ROUGE-1.5.5/data\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "cd WordNet-2.0-Exceptions\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "\n",
        "./buildExeptionDB.pl . exc WordNet-2.0.exc.db\n",
        "cd ../\n",
        "ln -s WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db"
      ],
      "metadata": {
        "id": "9r7wRNCEi-QZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d309fe-0579-4679-fb85-e04569b029c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'WordNet-2.0.exc.db': No such file or directory\n",
            "verb.exc\n",
            "abetted\n",
            "abetting\n",
            "abhorred\n",
            "abhorring\n",
            "abode\n",
            "abought\n",
            "about-shipped\n",
            "about-shipping\n",
            "abutted\n",
            "abutting\n",
            "abye\n",
            "accompanied\n",
            "acetified\n",
            "acidified\n",
            "acquitted\n",
            "acquitting\n",
            "ad-libbed\n",
            "ad-libbing\n",
            "addrest\n",
            "admitted\n",
            "admitting\n",
            "aerified\n",
            "air-dried\n",
            "airdropped\n",
            "airdropping\n",
            "alkalified\n",
            "allied\n",
            "allotted\n",
            "allotting\n",
            "allowed_for\n",
            "allowing_for\n",
            "allows_for\n",
            "am\n",
            "ammonified\n",
            "amnestied\n",
            "amplified\n",
            "anglified\n",
            "annulled\n",
            "annulling\n",
            "appalled\n",
            "appalling\n",
            "applied\n",
            "arcked\n",
            "arcking\n",
            "are\n",
            "argufied\n",
            "arisen\n",
            "arose\n",
            "ate\n",
            "atrophied\n",
            "averred\n",
            "averring\n",
            "awoke\n",
            "awoken\n",
            "babied\n",
            "baby-sat\n",
            "baby-sitting\n",
            "back-pedalled\n",
            "back-pedalling\n",
            "backbit\n",
            "backbitten\n",
            "backslid\n",
            "backslidden\n",
            "bade\n",
            "bagged\n",
            "bagging\n",
            "ballyragged\n",
            "ballyragging\n",
            "bandied\n",
            "banned\n",
            "banning\n",
            "barred\n",
            "barrelled\n",
            "barrelling\n",
            "barring\n",
            "basified\n",
            "batted\n",
            "batting\n",
            "bayonetted\n",
            "bayonetting\n",
            "beaten\n",
            "beatified\n",
            "beautified\n",
            "became\n",
            "became_known\n",
            "becomes_known\n",
            "bed\n",
            "bedded\n",
            "bedding\n",
            "bedevilled\n",
            "bedevilling\n",
            "bedimmed\n",
            "bedimming\n",
            "been\n",
            "befallen\n",
            "befell\n",
            "befitted\n",
            "befitting\n",
            "befogged\n",
            "befogging\n",
            "began\n",
            "begat\n",
            "begetting\n",
            "begged\n",
            "begging\n",
            "beginning\n",
            "begirt\n",
            "begot\n",
            "begotten\n",
            "begun\n",
            "beheld\n",
            "beholden\n",
            "bejewelled\n",
            "bejewelling\n",
            "bellied\n",
            "belly-flopped\n",
            "belly-flopping\n",
            "belying\n",
            "benefitted\n",
            "benefitting\n",
            "benempt\n",
            "bent\n",
            "berried\n",
            "besetting\n",
            "besought\n",
            "bespoke\n",
            "bespoken\n",
            "bestirred\n",
            "bestirring\n",
            "bestrewn\n",
            "bestrid\n",
            "bestridden\n",
            "bestrode\n",
            "betaken\n",
            "bethought\n",
            "betook\n",
            "betted\n",
            "betting\n",
            "bevelled\n",
            "bevelling\n",
            "biassed\n",
            "biassing\n",
            "bidden\n",
            "bidding\n",
            "bing\n",
            "binned\n",
            "binning\n",
            "bird-dogged\n",
            "bird-dogging\n",
            "bit\n",
            "bitted\n",
            "bitten\n",
            "bitting\n",
            "bivouacked\n",
            "bivouacking\n",
            "blabbed\n",
            "blabbing\n",
            "blackberried\n",
            "blacklegged\n",
            "blacklegging\n",
            "blatted\n",
            "blatting\n",
            "bled\n",
            "blest\n",
            "blew\n",
            "blew_one's_nose\n",
            "blipped\n",
            "blipping\n",
            "blobbed\n",
            "blobbing\n",
            "bloodied\n",
            "blotted\n",
            "blotting\n",
            "blowing_one's_nose\n",
            "blown\n",
            "blows_one's_nose\n",
            "blubbed\n",
            "blubbing\n",
            "blue-pencilled\n",
            "blue-pencilling\n",
            "blurred\n",
            "blurring\n",
            "bobbed\n",
            "bobbing\n",
            "bodied\n",
            "bogged-down\n",
            "bogged_down\n",
            "bogging-down\n",
            "bogging_down\n",
            "bogs-down\n",
            "bogs_down\n",
            "booby-trapped\n",
            "booby-trapping\n",
            "bootlegged\n",
            "bootlegging\n",
            "bopped\n",
            "bopping\n",
            "bore\n",
            "born\n",
            "borne\n",
            "bottle-fed\n",
            "bought\n",
            "bound\n",
            "bragged\n",
            "bragging\n",
            "breast-fed\n",
            "bred\n",
            "brevetted\n",
            "brevetting\n",
            "brimmed\n",
            "brimming\n",
            "broke\n",
            "broken\n",
            "brought\n",
            "browbeaten\n",
            "brutified\n",
            "budded\n",
            "budding\n",
            "bugged\n",
            "bugging\n",
            "built\n",
            "bulldogging\n",
            "bullied\n",
            "bullshitted\n",
            "bullshitting\n",
            "bullwhipped\n",
            "bullwhipping\n",
            "bullyragged\n",
            "bullyragging\n",
            "bummed\n",
            "bumming\n",
            "buried\n",
            "burnt\n",
            "burred\n",
            "burring\n",
            "bushelled\n",
            "bushelling\n",
            "busied\n",
            "bypast\n",
            "caballed\n",
            "caballing\n",
            "caddied\n",
            "caddies\n",
            "caddying\n",
            "calcified\n",
            "came\n",
            "canalled\n",
            "canalling\n",
            "cancelled\n",
            "cancelling\n",
            "candied\n",
            "canned\n",
            "canning\n",
            "canopied\n",
            "capped\n",
            "capping\n",
            "carburetted\n",
            "carburetting\n",
            "carillonned\n",
            "carillonning\n",
            "carnied\n",
            "carnified\n",
            "carolled\n",
            "carolling\n",
            "carried\n",
            "casefied\n",
            "catnapped\n",
            "catnapping\n",
            "catted\n",
            "catting\n",
            "caught\n",
            "cavilled\n",
            "cavilling\n",
            "certified\n",
            "channelled\n",
            "channelling\n",
            "chapped\n",
            "chapping\n",
            "charred\n",
            "charring\n",
            "chatted\n",
            "chatting\n",
            "chevied\n",
            "chevies\n",
            "chevying\n",
            "chid\n",
            "chidden\n",
            "chinned\n",
            "chinning\n",
            "chipped\n",
            "chipping\n",
            "chiselled\n",
            "chiselling\n",
            "chitchatted\n",
            "chitchatting\n",
            "chivied\n",
            "chivved\n",
            "chivvied\n",
            "chivvies\n",
            "chivving\n",
            "chivvying\n",
            "chondrified\n",
            "chopped\n",
            "chopping\n",
            "chose\n",
            "chosen\n",
            "chugged\n",
            "chugging\n",
            "chummed\n",
            "chumming\n",
            "citified\n",
            "clad\n",
            "cladding\n",
            "clammed\n",
            "clamming\n",
            "clapped\n",
            "clapping\n",
            "clarified\n",
            "classified\n",
            "cleft\n",
            "clemmed\n",
            "clemming\n",
            "clept\n",
            "clipped\n",
            "clipping\n",
            "clogged\n",
            "clogging\n",
            "clopped\n",
            "clopping\n",
            "clotted\n",
            "clotting\n",
            "clove\n",
            "cloven\n",
            "clubbed\n",
            "clubbing\n",
            "clung\n",
            "co-opted\n",
            "co-opting\n",
            "co-opts\n",
            "co-ordinate\n",
            "co-ordinated\n",
            "co-ordinates\n",
            "co-ordinating\n",
            "co-starred\n",
            "co-starring\n",
            "cockneyfied\n",
            "codded\n",
            "codding\n",
            "codified\n",
            "cogged\n",
            "cogging\n",
            "coiffed\n",
            "coiffing\n",
            "collied\n",
            "combatted\n",
            "combatting\n",
            "committed\n",
            "committing\n",
            "compelled\n",
            "compelling\n",
            "complied\n",
            "complotted\n",
            "complotting\n",
            "concurred\n",
            "concurring\n",
            "confabbed\n",
            "confabbing\n",
            "conferred\n",
            "conferring\n",
            "conned\n",
            "conning\n",
            "controlled\n",
            "controlling\n",
            "copied\n",
            "copped\n",
            "copping\n",
            "coquetted\n",
            "coquetting\n",
            "corralled\n",
            "corralling\n",
            "counselled\n",
            "counselling\n",
            "counterplotted\n",
            "counterplotting\n",
            "countersank\n",
            "countersunk\n",
            "court-martialled\n",
            "court-martialling\n",
            "crabbed\n",
            "crabbing\n",
            "crammed\n",
            "cramming\n",
            "crapped\n",
            "crapping\n",
            "crept\n",
            "cribbed\n",
            "cribbing\n",
            "cried\n",
            "cropped\n",
            "cropping\n",
            "crossbred\n",
            "crosscutting\n",
            "crucified\n",
            "cubbed\n",
            "cubbing\n",
            "cudgelled\n",
            "cudgelling\n",
            "cupelled\n",
            "cupelling\n",
            "cupped\n",
            "cupping\n",
            "curetted\n",
            "curettes\n",
            "curetting\n",
            "curried\n",
            "curst\n",
            "curtsied\n",
            "curvetted\n",
            "curvetting\n",
            "cutting\n",
            "dabbed\n",
            "dabbing\n",
            "dagged\n",
            "dagging\n",
            "dallied\n",
            "dammed\n",
            "damming\n",
            "damnified\n",
            "dandified\n",
            "dapped\n",
            "dapping\n",
            "dealt\n",
            "debarred\n",
            "debarring\n",
            "debugged\n",
            "debugging\n",
            "debussed\n",
            "debusses\n",
            "debussing\n",
            "decalcified\n",
            "declassified\n",
            "decontrolled\n",
            "decontrolling\n",
            "decried\n",
            "deep-freeze\n",
            "deep-freezed\n",
            "deep-freezes\n",
            "deep-fried\n",
            "deferred\n",
            "deferring\n",
            "defied\n",
            "degassed\n",
            "degasses\n",
            "degassing\n",
            "dehumidified\n",
            "deified\n",
            "demitted\n",
            "demitting\n",
            "demobbed\n",
            "demobbing\n",
            "demulsified\n",
            "demurred\n",
            "demurring\n",
            "demystified\n",
            "denazified\n",
            "denied\n",
            "denitrified\n",
            "denned\n",
            "denning\n",
            "descried\n",
            "deterred\n",
            "deterring\n",
            "detoxified\n",
            "devilled\n",
            "devilling\n",
            "devitrified\n",
            "diagrammed\n",
            "diagramming\n",
            "dialled\n",
            "dialling\n",
            "dibbed\n",
            "dibbing\n",
            "did\n",
            "digging\n",
            "dignified\n",
            "dilly-dallied\n",
            "dimmed\n",
            "dimming\n",
            "dinned\n",
            "dinning\n",
            "dipped\n",
            "dipping\n",
            "dirtied\n",
            "disannulled\n",
            "disannulling\n",
            "disbarred\n",
            "disbarring\n",
            "disbudded\n",
            "disbudding\n",
            "disembodied\n",
            "disembowelled\n",
            "disembowelling\n",
            "disenthralled\n",
            "disenthralling\n",
            "disenthralls\n",
            "disenthrals\n",
            "dishevelled\n",
            "dishevelling\n",
            "disinterred\n",
            "disinterring\n",
            "dispelled\n",
            "dispelling\n",
            "disqualified\n",
            "dissatisfied\n",
            "distilled\n",
            "distilling\n",
            "diversified\n",
            "divvied\n",
            "dizzied\n",
            "dogged\n",
            "dogging\n",
            "doglegged\n",
            "doglegging\n",
            "dollied\n",
            "done\n",
            "donned\n",
            "donning\n",
            "dotted\n",
            "dotting\n",
            "dought\n",
            "dove\n",
            "drabbed\n",
            "drabbing\n",
            "dragged\n",
            "dragging\n",
            "drank\n",
            "drawn\n",
            "dreamt\n",
            "drew\n",
            "dried\n",
            "dripped\n",
            "dripping\n",
            "drivelled\n",
            "drivelling\n",
            "driven\n",
            "dropped\n",
            "dropping\n",
            "drove\n",
            "drubbed\n",
            "drubbing\n",
            "drugged\n",
            "drugging\n",
            "drummed\n",
            "drumming\n",
            "drunk\n",
            "dubbed\n",
            "dubbing\n",
            "duelled\n",
            "duelling\n",
            "dug\n",
            "dulcified\n",
            "dummied\n",
            "dunned\n",
            "dunning\n",
            "dwelt\n",
            "dying\n",
            "easied\n",
            "eaten\n",
            "eavesdropped\n",
            "eavesdropping\n",
            "eddied\n",
            "edified\n",
            "ego-tripped\n",
            "ego-tripping\n",
            "electrified\n",
            "embedded\n",
            "embedding\n",
            "embodied\n",
            "embussed\n",
            "embusses\n",
            "embussing\n",
            "emitted\n",
            "emitting\n",
            "empanelled\n",
            "empanelling\n",
            "emptied\n",
            "emulsified\n",
            "enamelled\n",
            "enamelling\n",
            "englutted\n",
            "englutting\n",
            "enrolled\n",
            "enrolling\n",
            "enthralled\n",
            "enthralling\n",
            "entrammelled\n",
            "entrammelling\n",
            "entrapped\n",
            "entrapping\n",
            "envied\n",
            "enwound\n",
            "enwrapped\n",
            "enwrapping\n",
            "equalled\n",
            "equalling\n",
            "equipped\n",
            "equipping\n",
            "espied\n",
            "esterified\n",
            "estopped\n",
            "estopping\n",
            "etherified\n",
            "excelled\n",
            "excelling\n",
            "exemplified\n",
            "expelled\n",
            "expelling\n",
            "extolled\n",
            "extolling\n",
            "facetted\n",
            "facetting\n",
            "fagged\n",
            "fagging\n",
            "fallen\n",
            "falsified\n",
            "fancied\n",
            "fanned\n",
            "fanning\n",
            "fantasied\n",
            "fatted\n",
            "fatting\n",
            "featherbedded\n",
            "featherbedding\n",
            "fed\n",
            "feed\n",
            "fell\n",
            "felt\n",
            "ferried\n",
            "fibbed\n",
            "fibbing\n",
            "figged\n",
            "figging\n",
            "filled_up\n",
            "fine-drawn\n",
            "fine-drew\n",
            "finned\n",
            "finning\n",
            "fitted\n",
            "fitting\n",
            "flagged\n",
            "flagging\n",
            "flammed\n",
            "flamming\n",
            "flannelled\n",
            "flannelling\n",
            "flapped\n",
            "flapping\n",
            "flatted\n",
            "flatting\n",
            "fled\n",
            "flew\n",
            "flimflammed\n",
            "flimflamming\n",
            "flip-flopped\n",
            "flip-flopping\n",
            "flipped\n",
            "flipping\n",
            "flitted\n",
            "flitting\n",
            "flogged\n",
            "flogging\n",
            "floodlit\n",
            "flopped\n",
            "flopping\n",
            "flown\n",
            "flubbed\n",
            "flubbing\n",
            "flung\n",
            "flurried\n",
            "flyblew\n",
            "flyblown\n",
            "fobbed\n",
            "fobbing\n",
            "fogged\n",
            "fogging\n",
            "footslogged\n",
            "footslogging\n",
            "forbad\n",
            "forbade\n",
            "forbidden\n",
            "forbidding\n",
            "forbore\n",
            "forborne\n",
            "force-fed\n",
            "fordid\n",
            "fordone\n",
            "foredid\n",
            "foredone\n",
            "foregone\n",
            "foreknew\n",
            "foreknown\n",
            "foreran\n",
            "forerunning\n",
            "foresaw\n",
            "foreseen\n",
            "foreshown\n",
            "forespoke\n",
            "forespoken\n",
            "foretold\n",
            "forewent\n",
            "forgave\n",
            "forgetting\n",
            "forgiven\n",
            "forgone\n",
            "forgot\n",
            "forgotten\n",
            "formatted\n",
            "formatting\n",
            "forsaken\n",
            "forsook\n",
            "forspoke\n",
            "forspoken\n",
            "forswore\n",
            "forsworn\n",
            "fortified\n",
            "forwent\n",
            "fought\n",
            "found\n",
            "foxtrotted\n",
            "foxtrotting\n",
            "frapped\n",
            "frapping\n",
            "freeze-dried\n",
            "frenchified\n",
            "frenzied\n",
            "fretted\n",
            "fretting\n",
            "fried\n",
            "frigged\n",
            "frigging\n",
            "fritted\n",
            "fritting\n",
            "frivolled\n",
            "frivolling\n",
            "frogged\n",
            "frogging\n",
            "frolicked\n",
            "frolicking\n",
            "froze\n",
            "frozen\n",
            "fructified\n",
            "fuelled\n",
            "fuelling\n",
            "fulfilled\n",
            "fulfilling\n",
            "funned\n",
            "funnelled\n",
            "funnelling\n",
            "funning\n",
            "furred\n",
            "furring\n",
            "gadded\n",
            "gadding\n",
            "gagged\n",
            "gagging\n",
            "gainsaid\n",
            "gambolled\n",
            "gambolling\n",
            "gammed\n",
            "gamming\n",
            "gan\n",
            "ganned\n",
            "ganning\n",
            "gapped\n",
            "gapping\n",
            "gasified\n",
            "gassed\n",
            "gasses\n",
            "gassing\n",
            "gave\n",
            "gelled\n",
            "gelling\n",
            "gelt\n",
            "gemmed\n",
            "gemming\n",
            "genned-up\n",
            "genning-up\n",
            "gens-up\n",
            "gets_lost\n",
            "gets_started\n",
            "getting\n",
            "getting_lost\n",
            "getting_started\n",
            "ghostwritten\n",
            "ghostwrote\n",
            "gibbed\n",
            "gibbing\n",
            "giddied\n",
            "giftwrapped\n",
            "giftwrapping\n",
            "gigged\n",
            "gigging\n",
            "gilt\n",
            "ginned\n",
            "ginning\n",
            "gipped\n",
            "gipping\n",
            "girt\n",
            "given\n",
            "glommed\n",
            "glomming\n",
            "gloried\n",
            "glorified\n",
            "glutted\n",
            "glutting\n",
            "gnawn\n",
            "goes_deep\n",
            "going_deep\n",
            "gollied\n",
            "gone\n",
            "gone_deep\n",
            "goose-stepped\n",
            "goose-stepping\n",
            "got\n",
            "got_lost\n",
            "got_started\n",
            "gotten\n",
            "gotten_lost\n",
            "grabbed\n",
            "grabbing\n",
            "gratified\n",
            "gravelled\n",
            "gravelling\n",
            "graven\n",
            "grew\n",
            "grinned\n",
            "grinning\n",
            "gripped\n",
            "gripping\n",
            "gript\n",
            "gritted\n",
            "gritting\n",
            "ground\n",
            "grovelled\n",
            "grovelling\n",
            "grown\n",
            "grubbed\n",
            "grubbing\n",
            "guarantied\n",
            "gullied\n",
            "gummed\n",
            "gumming\n",
            "gunned\n",
            "gunning\n",
            "gypped\n",
            "gypping\n",
            "hacksawn\n",
            "had\n",
            "had_a_feeling\n",
            "had_left\n",
            "had_the_feeling\n",
            "hammed\n",
            "hamming\n",
            "hamstrung\n",
            "hand-knitted\n",
            "hand-knitting\n",
            "handfed\n",
            "handicapped\n",
            "handicapping\n",
            "handselled\n",
            "handselling\n",
            "harried\n",
            "has\n",
            "has_a_feeling\n",
            "has_left\n",
            "has_the_feeling\n",
            "hatchelled\n",
            "hatchelling\n",
            "hatted\n",
            "hatting\n",
            "having_a_feeling\n",
            "having_left\n",
            "having_the_feeling\n",
            "heard\n",
            "hedgehopped\n",
            "hedgehopping\n",
            "held\n",
            "hemmed\n",
            "hemming\n",
            "hewn\n",
            "hiccupped\n",
            "hiccupping\n",
            "hid\n",
            "hidden\n",
            "high-hatted\n",
            "high-hatting\n",
            "hinnied\n",
            "hitting\n",
            "hobbed\n",
            "hobbing\n",
            "hobnobbed\n",
            "hobnobbing\n",
            "hocus-pocussed\n",
            "hocus-pocussing\n",
            "hocussed\n",
            "hocussing\n",
            "hogged\n",
            "hogging\n",
            "hogtying\n",
            "honied\n",
            "hopped\n",
            "hopping\n",
            "horrified\n",
            "horsewhipped\n",
            "horsewhipping\n",
            "houselled\n",
            "houselling\n",
            "hove\n",
            "hovelled\n",
            "hovelling\n",
            "hugged\n",
            "hugging\n",
            "humbugged\n",
            "humbugging\n",
            "humidified\n",
            "hummed\n",
            "humming\n",
            "hung\n",
            "hurried\n",
            "hypertrophied\n",
            "identified\n",
            "imbedded\n",
            "imbedding\n",
            "impanelled\n",
            "impanelling\n",
            "impelled\n",
            "impelling\n",
            "implied\n",
            "inbred\n",
            "incurred\n",
            "incurring\n",
            "indemnified\n",
            "indwelt\n",
            "inferred\n",
            "inferring\n",
            "initialled\n",
            "initialling\n",
            "inlaid\n",
            "insetting\n",
            "inspanned\n",
            "inspanning\n",
            "installed\n",
            "installing\n",
            "intensified\n",
            "interbred\n",
            "intercropped\n",
            "intercropping\n",
            "intercutting\n",
            "interlaid\n",
            "interlapped\n",
            "interlapping\n",
            "intermarried\n",
            "intermitted\n",
            "intermitting\n",
            "interpled\n",
            "interred\n",
            "interring\n",
            "interstratified\n",
            "interwove\n",
            "interwoven\n",
            "intromitted\n",
            "intromitting\n",
            "inwove\n",
            "inwoven\n",
            "inwrapped\n",
            "inwrapping\n",
            "is\n",
            "jabbed\n",
            "jabbing\n",
            "jagged\n",
            "jagging\n",
            "jammed\n",
            "jamming\n",
            "japanned\n",
            "japanning\n",
            "jarred\n",
            "jarring\n",
            "jellied\n",
            "jellified\n",
            "jemmied\n",
            "jerry-built\n",
            "jetted\n",
            "jetting\n",
            "jewelled\n",
            "jewelling\n",
            "jibbed\n",
            "jibbing\n",
            "jigged\n",
            "jigging\n",
            "jimmied\n",
            "jitterbugged\n",
            "jitterbugging\n",
            "jobbed\n",
            "jobbing\n",
            "jog-trotted\n",
            "jog-trotting\n",
            "jogged\n",
            "jogging\n",
            "joined_battle\n",
            "joined_forces\n",
            "joining_battle\n",
            "joining_forces\n",
            "joins_battle\n",
            "joins_forces\n",
            "jollied\n",
            "jollified\n",
            "jotted\n",
            "jotting\n",
            "joy-ridden\n",
            "joy-rode\n",
            "joypopped\n",
            "joypopping\n",
            "jugged\n",
            "jugging\n",
            "jumped_off\n",
            "jumping_off\n",
            "jumps_off\n",
            "justified\n",
            "jutted\n",
            "jutting\n",
            "kenned\n",
            "kennelled\n",
            "kennelling\n",
            "kenning\n",
            "kent\n",
            "kept\n",
            "kernelled\n",
            "kernelling\n",
            "kidded\n",
            "kidding\n",
            "kidnapped\n",
            "kidnapping\n",
            "kipped\n",
            "kipping\n",
            "knapped\n",
            "knapping\n",
            "kneecapped\n",
            "kneecapping\n",
            "knelt\n",
            "knew\n",
            "knitted\n",
            "knitting\n",
            "knobbed\n",
            "knobbing\n",
            "knotted\n",
            "knotting\n",
            "known\n",
            "ko'd\n",
            "ko'ing\n",
            "ko's\n",
            "labelled\n",
            "labelling\n",
            "laden\n",
            "ladyfied\n",
            "ladyfies\n",
            "ladyfying\n",
            "lagged\n",
            "lagging\n",
            "laid\n",
            "lain\n",
            "lallygagged\n",
            "lallygagging\n",
            "lammed\n",
            "lamming\n",
            "lapidified\n",
            "lapped\n",
            "lapping\n",
            "laurelled\n",
            "laurelling\n",
            "lay\n",
            "layed_for\n",
            "laying_for\n",
            "lays_for\n",
            "leant\n",
            "leapfrogged\n",
            "leapfrogging\n",
            "leapt\n",
            "learnt\n",
            "leaves_undone\n",
            "leaving_undone\n",
            "led\n",
            "left\n",
            "left_undone\n",
            "lent\n",
            "letting\n",
            "levelled\n",
            "levelling\n",
            "levied\n",
            "libelled\n",
            "libelling\n",
            "lignified\n",
            "lipped\n",
            "lipping\n",
            "liquefied\n",
            "liquified\n",
            "lit\n",
            "lobbed\n",
            "lobbied\n",
            "lobbing\n",
            "logged\n",
            "logging\n",
            "looked_towards\n",
            "looking_towards\n",
            "looks_towards\n",
            "lopped\n",
            "lopping\n",
            "lost\n",
            "lotted\n",
            "lotting\n",
            "lugged\n",
            "lugging\n",
            "lullabied\n",
            "lying\n",
            "machine-gunned\n",
            "machine-gunning\n",
            "madded\n",
            "madding\n",
            "made\n",
            "magnified\n",
            "manned\n",
            "manning\n",
            "manumitted\n",
            "manumitting\n",
            "mapped\n",
            "mapping\n",
            "marcelled\n",
            "marcelling\n",
            "marred\n",
            "married\n",
            "marring\n",
            "marshalled\n",
            "marshalling\n",
            "marvelled\n",
            "marvelling\n",
            "matted\n",
            "matting\n",
            "meant\n",
            "medalled\n",
            "medalling\n",
            "met\n",
            "metalled\n",
            "metalling\n",
            "metrified\n",
            "might\n",
            "militated_against\n",
            "militates_against\n",
            "militating_against\n",
            "mimicked\n",
            "mimicking\n",
            "minified\n",
            "misapplied\n",
            "misbecame\n",
            "miscarried\n",
            "misdealt\n",
            "misfitted\n",
            "misfitting\n",
            "misgave\n",
            "misgiven\n",
            "mishitting\n",
            "mislaid\n",
            "misled\n",
            "mispled\n",
            "misspelt\n",
            "misspent\n",
            "mistaken\n",
            "mistook\n",
            "misunderstood\n",
            "mobbed\n",
            "mobbing\n",
            "modelled\n",
            "modelling\n",
            "modified\n",
            "mollified\n",
            "molten\n",
            "mopped\n",
            "mopping\n",
            "mortified\n",
            "mown\n",
            "mudded\n",
            "muddied\n",
            "mudding\n",
            "mugged\n",
            "mugging\n",
            "multiplied\n",
            "mummed\n",
            "mummified\n",
            "mumming\n",
            "mutinied\n",
            "mystified\n",
            "nabbed\n",
            "nabbing\n",
            "nagged\n",
            "nagging\n",
            "napped\n",
            "napping\n",
            "netted\n",
            "netting\n",
            "nibbed\n",
            "nibbing\n",
            "nickelled\n",
            "nickelling\n",
            "nid-nodded\n",
            "nid-nodding\n",
            "nidified\n",
            "nigrified\n",
            "nipped\n",
            "nipping\n",
            "nitrified\n",
            "nodded\n",
            "nodding\n",
            "non-prossed\n",
            "non-prosses\n",
            "non-prossing\n",
            "nonplussed\n",
            "nonplusses\n",
            "nonplussing\n",
            "notified\n",
            "nullified\n",
            "nutted\n",
            "nutting\n",
            "objectified\n",
            "occupied\n",
            "occurred\n",
            "occurring\n",
            "offsetting\n",
            "omitted\n",
            "omitting\n",
            "ossified\n",
            "outbidden\n",
            "outbidding\n",
            "outbred\n",
            "outcried\n",
            "outcropped\n",
            "outcropping\n",
            "outdid\n",
            "outdone\n",
            "outdrawn\n",
            "outdrew\n",
            "outfitted\n",
            "outfitting\n",
            "outfought\n",
            "outgassed\n",
            "outgasses\n",
            "outgassing\n",
            "outgeneralled\n",
            "outgeneralling\n",
            "outgone\n",
            "outgrew\n",
            "outgrown\n",
            "outlaid\n",
            "outmanned\n",
            "outmanning\n",
            "outputted\n",
            "outputting\n",
            "outran\n",
            "outridden\n",
            "outrode\n",
            "outrunning\n",
            "outshone\n",
            "outshot\n",
            "outsold\n",
            "outspanned\n",
            "outspanning\n",
            "outstood\n",
            "outstripped\n",
            "outstripping\n",
            "outthought\n",
            "outwent\n",
            "outwitted\n",
            "outwitting\n",
            "outwore\n",
            "outworn\n",
            "overbidden\n",
            "overbidding\n",
            "overblew\n",
            "overblown\n",
            "overbore\n",
            "overborne\n",
            "overbuilt\n",
            "overcame\n",
            "overcropped\n",
            "overcropping\n",
            "overdid\n",
            "overdone\n",
            "overdrawn\n",
            "overdrew\n",
            "overdriven\n",
            "overdrove\n",
            "overflew\n",
            "overflown\n",
            "overgrew\n",
            "overgrown\n",
            "overheard\n",
            "overhung\n",
            "overlaid\n",
            "overlain\n",
            "overlapped\n",
            "overlapping\n",
            "overlay\n",
            "overlying\n",
            "overmanned\n",
            "overmanning\n",
            "overpaid\n",
            "overpast\n",
            "overran\n",
            "overridden\n",
            "overrode\n",
            "overrunning\n",
            "oversaw\n",
            "overseen\n",
            "oversetting\n",
            "oversewn\n",
            "overshot\n",
            "oversimplified\n",
            "overslept\n",
            "oversold\n",
            "overspent\n",
            "overspilt\n",
            "overstepped\n",
            "overstepping\n",
            "overtaken\n",
            "overthrew\n",
            "overthrown\n",
            "overtook\n",
            "overtopped\n",
            "overtopping\n",
            "overwound\n",
            "overwritten\n",
            "overwrote\n",
            "pacified\n",
            "padded\n",
            "padding\n",
            "paid\n",
            "palled\n",
            "palling\n",
            "palsied\n",
            "pandied\n",
            "panelled\n",
            "panelling\n",
            "panicked\n",
            "panicking\n",
            "panned\n",
            "panning\n",
            "parallelled\n",
            "parallelling\n",
            "parcelled\n",
            "parcelling\n",
            "parodied\n",
            "parried\n",
            "partaken\n",
            "partook\n",
            "pasquil\n",
            "pasquilled\n",
            "pasquilling\n",
            "pasquils\n",
            "patrolled\n",
            "patrolling\n",
            "patted\n",
            "patting\n",
            "pedalled\n",
            "pedalling\n",
            "pegged\n",
            "pegging\n",
            "pencilled\n",
            "pencilling\n",
            "penned\n",
            "penning\n",
            "pent\n",
            "pepped\n",
            "pepping\n",
            "permitted\n",
            "permitting\n",
            "personified\n",
            "petrified\n",
            "petted\n",
            "pettifogged\n",
            "pettifogging\n",
            "petting\n",
            "phantasied\n",
            "photocopied\n",
            "photomapped\n",
            "photomapping\n",
            "photosetting\n",
            "physicked\n",
            "physicking\n",
            "picnicked\n",
            "picnicking\n",
            "pigged\n",
            "pigging\n",
            "pilloried\n",
            "pinch-hitting\n",
            "pinned\n",
            "pinning\n",
            "pipped\n",
            "pipping\n",
            "pistol-whipped\n",
            "pistol-whipping\n",
            "pistolled\n",
            "pistolling\n",
            "pitapatted\n",
            "pitapatting\n",
            "pitied\n",
            "pitted\n",
            "pitting\n",
            "planned\n",
            "planning\n",
            "platted\n",
            "platting\n",
            "played_a_part\n",
            "playing_a_part\n",
            "plays_a_part\n",
            "pled\n",
            "plied\n",
            "plodded\n",
            "plodding\n",
            "plopped\n",
            "plopping\n",
            "plotted\n",
            "plotting\n",
            "plugged\n",
            "plugging\n",
            "podded\n",
            "podding\n",
            "pommelled\n",
            "pommelling\n",
            "popes\n",
            "popped\n",
            "popping\n",
            "potted\n",
            "potting\n",
            "preachified\n",
            "precancelled\n",
            "precancelling\n",
            "preferred\n",
            "preferring\n",
            "preoccupied\n",
            "prepaid\n",
            "presignified\n",
            "pretermitted\n",
            "pretermitting\n",
            "prettied\n",
            "prettified\n",
            "pried\n",
            "prigged\n",
            "prigging\n",
            "primmed\n",
            "primming\n",
            "prodded\n",
            "prodding\n",
            "programmed\n",
            "programmes\n",
            "programming\n",
            "prologed\n",
            "prologing\n",
            "prologs\n",
            "propelled\n",
            "propelling\n",
            "prophesied\n",
            "propped\n",
            "propping\n",
            "proven\n",
            "pubbed\n",
            "pubbing\n",
            "pugged\n",
            "pugging\n",
            "pummelled\n",
            "pummelling\n",
            "punned\n",
            "punning\n",
            "pupped\n",
            "pupping\n",
            "purified\n",
            "put-putted\n",
            "put-putting\n",
            "putrefied\n",
            "puttied\n",
            "putting\n",
            "qualified\n",
            "quantified\n",
            "quarrelled\n",
            "quarrelling\n",
            "quarried\n",
            "quartersawn\n",
            "queried\n",
            "quick-froze\n",
            "quick-frozen\n",
            "quickstepped\n",
            "quickstepping\n",
            "quipped\n",
            "quipping\n",
            "quitted\n",
            "quitting\n",
            "quizzed\n",
            "quizzes\n",
            "quizzing\n",
            "ragged\n",
            "ragging\n",
            "rallied\n",
            "ramified\n",
            "rammed\n",
            "ramming\n",
            "ran\n",
            "rang\n",
            "rapped\n",
            "rappelled\n",
            "rappelling\n",
            "rapping\n",
            "rarefied\n",
            "ratified\n",
            "ratted\n",
            "ratting\n",
            "ravelled\n",
            "ravelling\n",
            "razor-cutting\n",
            "re-trod\n",
            "re-trodden\n",
            "rebelled\n",
            "rebelling\n",
            "rebuilt\n",
            "rebutted\n",
            "rebutting\n",
            "recapped\n",
            "recapping\n",
            "reclassified\n",
            "recommitted\n",
            "recommitting\n",
            "recopied\n",
            "rectified\n",
            "recurred\n",
            "recurring\n",
            "red\n",
            "red-pencilled\n",
            "red-pencilling\n",
            "redded\n",
            "redding\n",
            "redid\n",
            "redone\n",
            "referred\n",
            "referring\n",
            "refitted\n",
            "refitting\n",
            "reft\n",
            "refuelled\n",
            "refuelling\n",
            "regretted\n",
            "regretting\n",
            "reheard\n",
            "reified\n",
            "relied\n",
            "remade\n",
            "remarried\n",
            "remitted\n",
            "remitting\n",
            "rent\n",
            "repaid\n",
            "repelled\n",
            "repelling\n",
            "replevied\n",
            "replied\n",
            "repotted\n",
            "repotting\n",
            "reran\n",
            "rerunning\n",
            "resat\n",
            "resetting\n",
            "resewn\n",
            "resitting\n",
            "retaken\n",
            "rethought\n",
            "retold\n",
            "retook\n",
            "retransmitted\n",
            "retransmitting\n",
            "retried\n",
            "retrofitted\n",
            "retrofitting\n",
            "retted\n",
            "retting\n",
            "reunified\n",
            "revelled\n",
            "revelling\n",
            "revetted\n",
            "revetting\n",
            "revivified\n",
            "revved\n",
            "revving\n",
            "rewound\n",
            "rewritten\n",
            "rewrote\n",
            "ribbed\n",
            "ribbing\n",
            "ricochetted\n",
            "ricochetting\n",
            "ridded\n",
            "ridden\n",
            "ridding\n",
            "rigged\n",
            "rigging\n",
            "rigidified\n",
            "rimmed\n",
            "rimming\n",
            "ripped\n",
            "ripping\n",
            "risen\n",
            "rivalled\n",
            "rivalling\n",
            "riven\n",
            "robbed\n",
            "robbing\n",
            "rode\n",
            "rose\n",
            "rotted\n",
            "rotting\n",
            "rough-dried\n",
            "rough-hewn\n",
            "rove\n",
            "rowelled\n",
            "rowelling\n",
            "rubbed\n",
            "rubbing\n",
            "rung\n",
            "running\n",
            "rutted\n",
            "rutting\n",
            "saccharified\n",
            "sagged\n",
            "sagging\n",
            "said\n",
            "salaried\n",
            "salified\n",
            "sallied\n",
            "sanctified\n",
            "sandbagged\n",
            "sandbagging\n",
            "sang\n",
            "sank\n",
            "saponified\n",
            "sapped\n",
            "sapping\n",
            "sat\n",
            "satisfied\n",
            "savvied\n",
            "saw\n",
            "sawn\n",
            "scagged\n",
            "scagging\n",
            "scanned\n",
            "scanning\n",
            "scarified\n",
            "scarred\n",
            "scarring\n",
            "scatted\n",
            "scatting\n",
            "scorified\n",
            "scragged\n",
            "scragging\n",
            "scrammed\n",
            "scramming\n",
            "scrapped\n",
            "scrapping\n",
            "scried\n",
            "scrubbed\n",
            "scrubbing\n",
            "scrummed\n",
            "scrumming\n",
            "scudded\n",
            "scudding\n",
            "scummed\n",
            "scumming\n",
            "scurried\n",
            "seed\n",
            "seen\n",
            "sent\n",
            "setting\n",
            "sewn\n",
            "shagged\n",
            "shagging\n",
            "shaken\n",
            "shaken_hands\n",
            "shakes_hands\n",
            "shaking_hands\n",
            "shammed\n",
            "shamming\n",
            "sharecropped\n",
            "sharecropping\n",
            "shat\n",
            "shaven\n",
            "shed\n",
            "shedding\n",
            "shellacked\n",
            "shellacking\n",
            "shent\n",
            "shewn\n",
            "shied\n",
            "shikarred\n",
            "shikarring\n",
            "shillyshallied\n",
            "shimmed\n",
            "shimmied\n",
            "shimming\n",
            "shinned\n",
            "shinning\n",
            "shipped\n",
            "shipping\n",
            "shitted\n",
            "shitting\n",
            "shod\n",
            "shone\n",
            "shook\n",
            "shook_hands\n",
            "shopped\n",
            "shopping\n",
            "shot\n",
            "shotgunned\n",
            "shotgunning\n",
            "shotted\n",
            "shotting\n",
            "shovelled\n",
            "shovelling\n",
            "shown\n",
            "shrank\n",
            "shredded\n",
            "shredding\n",
            "shrink-wrapped\n",
            "shrink-wrapping\n",
            "shrivelled\n",
            "shrivelling\n",
            "shriven\n",
            "shrove\n",
            "shrugged\n",
            "shrugging\n",
            "shrunk\n",
            "shrunken\n",
            "shunned\n",
            "shunning\n",
            "shutting\n",
            "sicked\n",
            "sicking\n",
            "sideslipped\n",
            "sideslipping\n",
            "sidestepped\n",
            "sidestepping\n",
            "sightsaw\n",
            "sightseen\n",
            "signalled\n",
            "signalling\n",
            "signified\n",
            "silicified\n",
            "simplified\n",
            "singing\n",
            "single-stepped\n",
            "single-stepping\n",
            "sinned\n",
            "sinning\n",
            "sipped\n",
            "sipping\n",
            "sitting\n",
            "skellied\n",
            "skenned\n",
            "skenning\n",
            "sketted\n",
            "sketting\n",
            "ski'd\n",
            "skidded\n",
            "skidding\n",
            "skimmed\n",
            "skimming\n",
            "skin-popped\n",
            "skin-popping\n",
            "skinned\n",
            "skinning\n",
            "skinny-dipped\n",
            "skinny-dipping\n",
            "skipped\n",
            "skipping\n",
            "skivvied\n",
            "skydove\n",
            "slabbed\n",
            "slabbing\n",
            "slagged\n",
            "slagging\n",
            "slain\n",
            "slammed\n",
            "slamming\n",
            "slapped\n",
            "slapping\n",
            "slatted\n",
            "slatting\n",
            "sledding\n",
            "slept\n",
            "slew\n",
            "slid\n",
            "slidden\n",
            "slipped\n",
            "slipping\n",
            "slitting\n",
            "slogged\n",
            "slogging\n",
            "slopped\n",
            "slopping\n",
            "slotted\n",
            "slotting\n",
            "slugged\n",
            "slugging\n",
            "slummed\n",
            "slumming\n",
            "slung\n",
            "slunk\n",
            "slurred\n",
            "slurring\n",
            "smelt\n",
            "smit\n",
            "smitten\n",
            "smote\n",
            "smutted\n",
            "smutting\n",
            "snagged\n",
            "snagging\n",
            "snapped\n",
            "snapping\n",
            "snedded\n",
            "snedding\n",
            "snipped\n",
            "snipping\n",
            "snivelled\n",
            "snivelling\n",
            "snogged\n",
            "snogging\n",
            "snubbed\n",
            "snubbing\n",
            "snuck\n",
            "snugged\n",
            "snugging\n",
            "sobbed\n",
            "sobbing\n",
            "sodded\n",
            "sodding\n",
            "soft-pedalled\n",
            "soft-pedalling\n",
            "sold\n",
            "solemnified\n",
            "solidified\n",
            "soothsaid\n",
            "sopped\n",
            "sopping\n",
            "sought\n",
            "sown\n",
            "spagged\n",
            "spagging\n",
            "spancelled\n",
            "spancelling\n",
            "spanned\n",
            "spanning\n",
            "sparred\n",
            "sparring\n",
            "spat\n",
            "spatted\n",
            "spatting\n",
            "specified\n",
            "sped\n",
            "speechified\n",
            "spellbound\n",
            "spelt\n",
            "spent\n",
            "spied\n",
            "spilt\n",
            "spin-dried\n",
            "spinning\n",
            "spiralled\n",
            "spiralling\n",
            "spitted\n",
            "spitting\n",
            "splitting\n",
            "spoilt\n",
            "spoke\n",
            "spoken\n",
            "spoon-fed\n",
            "spotlit\n",
            "spotted\n",
            "spotting\n",
            "sprang\n",
            "sprigged\n",
            "sprigging\n",
            "sprung\n",
            "spudded\n",
            "spudding\n",
            "spun\n",
            "spurred\n",
            "spurring\n",
            "squatted\n",
            "squatting\n",
            "squibbed\n",
            "squibbing\n",
            "squidded\n",
            "squidding\n",
            "squilgee\n",
            "stabbed\n",
            "stabbing\n",
            "stall-fed\n",
            "stank\n",
            "starred\n",
            "starring\n",
            "steadied\n",
            "stellified\n",
            "stemmed\n",
            "stemming\n",
            "stems_from\n",
            "stencilled\n",
            "stencilling\n",
            "stepped\n",
            "stepping\n",
            "stetted\n",
            "stetting\n",
            "stied\n",
            "stilettoeing\n",
            "stirred\n",
            "stirring\n",
            "stole\n",
            "stolen\n",
            "stood\n",
            "stopped\n",
            "stopping\n",
            "storied\n",
            "stotted\n",
            "stotting\n",
            "stove\n",
            "strapped\n",
            "strapping\n",
            "stratified\n",
            "strewn\n",
            "stridden\n",
            "stripped\n",
            "stripping\n",
            "striven\n",
            "strode\n",
            "stropped\n",
            "stropping\n",
            "strove\n",
            "strown\n",
            "struck\n",
            "strummed\n",
            "strumming\n",
            "strung\n",
            "strutted\n",
            "strutting\n",
            "stubbed\n",
            "stubbing\n",
            "stuck\n",
            "studded\n",
            "studding\n",
            "studied\n",
            "stultified\n",
            "stummed\n",
            "stumming\n",
            "stung\n",
            "stunk\n",
            "stunned\n",
            "stunning\n",
            "stupefied\n",
            "stymying\n",
            "subbed\n",
            "subbing\n",
            "subjectified\n",
            "subletting\n",
            "submitted\n",
            "submitting\n",
            "subtotalled\n",
            "subtotalling\n",
            "sullied\n",
            "sulphuretted\n",
            "sulphuretting\n",
            "summed\n",
            "summing\n",
            "sung\n",
            "sunk\n",
            "sunken\n",
            "sunned\n",
            "sunning\n",
            "supped\n",
            "supping\n",
            "supplied\n",
            "swabbed\n",
            "swabbing\n",
            "swagged\n",
            "swagging\n",
            "swam\n",
            "swapped\n",
            "swapping\n",
            "swatted\n",
            "swatting\n",
            "swept\n",
            "swigged\n",
            "swigging\n",
            "swimming\n",
            "swivelled\n",
            "swivelling\n",
            "swollen\n",
            "swopped\n",
            "swopping\n",
            "swops\n",
            "swore\n",
            "sworn\n",
            "swotted\n",
            "swotting\n",
            "swum\n",
            "swung\n",
            "syllabified\n",
            "symbolled\n",
            "symbolling\n",
            "tabbed\n",
            "tabbing\n",
            "tagged\n",
            "tagging\n",
            "taken\n",
            "taken_a_side\n",
            "taken_pains\n",
            "taken_steps\n",
            "takes_a_side\n",
            "takes_pains\n",
            "takes_steps\n",
            "taking_a_side\n",
            "taking_pains\n",
            "taking_steps\n",
            "talcked\n",
            "talcking\n",
            "tallied\n",
            "tally-ho'd\n",
            "tammied\n",
            "tanned\n",
            "tanning\n",
            "tapped\n",
            "tapping\n",
            "tarred\n",
            "tarried\n",
            "tarring\n",
            "tasselled\n",
            "tasselling\n",
            "tatted\n",
            "tatting\n",
            "taught\n",
            "taxis\n",
            "taxying\n",
            "teaselled\n",
            "teaselling\n",
            "tedded\n",
            "tedding\n",
            "tepefied\n",
            "terrified\n",
            "testes\n",
            "testified\n",
            "thinking_the_world_of\n",
            "thinks_the_world_of\n",
            "thinned\n",
            "thinning\n",
            "thought\n",
            "thought_the_world_of\n",
            "threw\n",
            "threw_out\n",
            "thriven\n",
            "throbbed\n",
            "throbbing\n",
            "throve\n",
            "throwing_out\n",
            "thrown\n",
            "thrown_out\n",
            "throws_out\n",
            "thrummed\n",
            "thrumming\n",
            "thudded\n",
            "thudding\n",
            "tidied\n",
            "tinned\n",
            "tinning\n",
            "tinselled\n",
            "tinselling\n",
            "tipped\n",
            "tipping\n",
            "tittupped\n",
            "tittupping\n",
            "toadied\n",
            "togged\n",
            "togging\n",
            "told\n",
            "took\n",
            "took_a_side\n",
            "took_pains\n",
            "took_steps\n",
            "topped\n",
            "topping\n",
            "tore\n",
            "torn\n",
            "torrefied\n",
            "torrify\n",
            "totalled\n",
            "totalling\n",
            "totted\n",
            "totting\n",
            "towelled\n",
            "towelling\n",
            "trafficked\n",
            "trafficking\n",
            "trameled\n",
            "trameling\n",
            "tramelled\n",
            "tramelling\n",
            "tramels\n",
            "trammed\n",
            "tramming\n",
            "transferred\n",
            "transferring\n",
            "transfixt\n",
            "tranship\n",
            "transhipped\n",
            "transhipping\n",
            "transmitted\n",
            "transmitting\n",
            "transmogrified\n",
            "transshipped\n",
            "transshipping\n",
            "trapanned\n",
            "trapanning\n",
            "trapped\n",
            "trapping\n",
            "travelled\n",
            "travelling\n",
            "travestied\n",
            "trekked\n",
            "trekking\n",
            "trepanned\n",
            "trepanning\n",
            "tried\n",
            "trigged\n",
            "trigging\n",
            "trimmed\n",
            "trimming\n",
            "tripped\n",
            "tripping\n",
            "trod\n",
            "trodden\n",
            "trogged\n",
            "trogging\n",
            "trotted\n",
            "trotting\n",
            "trowelled\n",
            "trowelling\n",
            "tugged\n",
            "tugging\n",
            "tumefied\n",
            "tunned\n",
            "tunnelled\n",
            "tunnelling\n",
            "tunning\n",
            "tupped\n",
            "tupping\n",
            "tut-tutted\n",
            "tut-tutting\n",
            "twigged\n",
            "twigging\n",
            "twinned\n",
            "twinning\n",
            "twitted\n",
            "twitting\n",
            "tying\n",
            "typesetting\n",
            "typewritten\n",
            "typewrote\n",
            "typified\n",
            "uglified\n",
            "unbarred\n",
            "unbarring\n",
            "unbent\n",
            "unbound\n",
            "uncapped\n",
            "uncapping\n",
            "unclad\n",
            "unclogged\n",
            "unclogging\n",
            "underbidding\n",
            "underbought\n",
            "undercutting\n",
            "underfed\n",
            "undergirt\n",
            "undergone\n",
            "underlaid\n",
            "underlain\n",
            "underlay\n",
            "underletting\n",
            "underlying\n",
            "underpaid\n",
            "underpinned\n",
            "underpinning\n",
            "underpropped\n",
            "underpropping\n",
            "undersetting\n",
            "undershot\n",
            "undersold\n",
            "understood\n",
            "understudied\n",
            "undertaken\n",
            "undertook\n",
            "underwent\n",
            "underwritten\n",
            "underwrote\n",
            "undid\n",
            "undone\n",
            "unfitted\n",
            "unfitting\n",
            "unfroze\n",
            "unfrozen\n",
            "unified\n",
            "unkennelled\n",
            "unkennelling\n",
            "unknitted\n",
            "unknitting\n",
            "unlaid\n",
            "unlearnt\n",
            "unmade\n",
            "unmanned\n",
            "unmanning\n",
            "unpegged\n",
            "unpegging\n",
            "unpinned\n",
            "unpinning\n",
            "unplugged\n",
            "unplugging\n",
            "unravelled\n",
            "unravelling\n",
            "unrigged\n",
            "unrigging\n",
            "unripped\n",
            "unripping\n",
            "unrove\n",
            "unsaid\n",
            "unshipped\n",
            "unshipping\n",
            "unslung\n",
            "unsnapped\n",
            "unsnapping\n",
            "unspoke\n",
            "unspoken\n",
            "unsteadied\n",
            "unstepped\n",
            "unstepping\n",
            "unstopped\n",
            "unstopping\n",
            "unstrung\n",
            "unstuck\n",
            "unswore\n",
            "unsworn\n",
            "untaught\n",
            "unthought\n",
            "untidied\n",
            "untrod\n",
            "untrodden\n",
            "untying\n",
            "unwound\n",
            "unwrapped\n",
            "unwrapping\n",
            "unzipped\n",
            "unzipping\n",
            "upbuilt\n",
            "upheld\n",
            "uphove\n",
            "upped\n",
            "uppercutting\n",
            "upping\n",
            "uprisen\n",
            "uprose\n",
            "upsetting\n",
            "upsprang\n",
            "upsprung\n",
            "upswept\n",
            "upswollen\n",
            "upswung\n",
            "vagged\n",
            "vagging\n",
            "varied\n",
            "vatted\n",
            "vatting\n",
            "verbified\n",
            "verified\n",
            "versified\n",
            "vetted\n",
            "vetting\n",
            "victualled\n",
            "victualling\n",
            "vilified\n",
            "vitrified\n",
            "vitriolled\n",
            "vitriolling\n",
            "vivified\n",
            "vying\n",
            "wadded\n",
            "waddied\n",
            "wadding\n",
            "wadsetted\n",
            "wadsetting\n",
            "wagged\n",
            "wagging\n",
            "wanned\n",
            "wanning\n",
            "warred\n",
            "warring\n",
            "was\n",
            "water-ski'd\n",
            "waylaid\n",
            "wearied\n",
            "weatherstripped\n",
            "weatherstripping\n",
            "webbed\n",
            "webbing\n",
            "wedded\n",
            "wedding\n",
            "weed\n",
            "went\n",
            "went_deep\n",
            "wept\n",
            "were\n",
            "wetted\n",
            "wetting\n",
            "whammed\n",
            "whamming\n",
            "whapped\n",
            "whapping\n",
            "whetted\n",
            "whetting\n",
            "whinnied\n",
            "whipped\n",
            "whipping\n",
            "whipsawn\n",
            "whirred\n",
            "whirring\n",
            "whistle-stopped\n",
            "whistle-stopping\n",
            "whizzed\n",
            "whizzes\n",
            "whizzing\n",
            "whopped\n",
            "whopping\n",
            "wigged\n",
            "wigging\n",
            "wigwagged\n",
            "wigwagging\n",
            "wildcatted\n",
            "wildcatting\n",
            "window-shopped\n",
            "window-shopping\n",
            "winning\n",
            "winterfed\n",
            "wiredrawn\n",
            "wiredrew\n",
            "withdrawn\n",
            "withdrew\n",
            "withheld\n",
            "withstood\n",
            "woke\n",
            "woken\n",
            "won\n",
            "wonned\n",
            "wonning\n",
            "wore\n",
            "worn\n",
            "worried\n",
            "worshipped\n",
            "worshipping\n",
            "wound\n",
            "wove\n",
            "woven\n",
            "wrapped\n",
            "wrapping\n",
            "wried\n",
            "written\n",
            "wrote\n",
            "wrought\n",
            "wrung\n",
            "yakked\n",
            "yakking\n",
            "yapped\n",
            "yapping\n",
            "ycleped\n",
            "yclept\n",
            "yenned\n",
            "yenning\n",
            "yodelled\n",
            "yodelling\n",
            "zapped\n",
            "zapping\n",
            "zigzagged\n",
            "zigzagging\n",
            "zipped\n",
            "zipping\n",
            "adv.exc\n",
            "best\n",
            "better\n",
            "deeper\n",
            "farther\n",
            "further\n",
            "harder\n",
            "hardest\n",
            "noun.exc\n",
            "aardwolves\n",
            "abaci\n",
            "aboideaux\n",
            "aboiteaux\n",
            "abscissae\n",
            "acanthi\n",
            "acari\n",
            "acciaccature\n",
            "acetabula\n",
            "achaemenidae\n",
            "achaemenides\n",
            "acicula\n",
            "aciculae\n",
            "acini\n",
            "acre-feet\n",
            "acromia\n",
            "actiniae\n",
            "actinozoa\n",
            "addenda\n",
            "adenocarcinomata\n",
            "adenomata\n",
            "adieux\n",
            "adyta\n",
            "aecia\n",
            "aecidia\n",
            "aerobia\n",
            "agents-general\n",
            "aggiornamenti\n",
            "agnomina\n",
            "agones\n",
            "agorae\n",
            "agouties\n",
            "aides-de-camp\n",
            "aides-memoire\n",
            "aids-de-camp\n",
            "alae\n",
            "alewives\n",
            "alkalies\n",
            "allodia\n",
            "alluvia\n",
            "alodia\n",
            "alto-relievos\n",
            "altocumuli\n",
            "altostrati\n",
            "alulae\n",
            "alumnae\n",
            "alumni\n",
            "alveoli\n",
            "amanuenses\n",
            "ambulacra\n",
            "amebae\n",
            "amici_curiae\n",
            "amnia\n",
            "amniocenteses\n",
            "amoebae\n",
            "amoebiases\n",
            "amoraim\n",
            "amoretti\n",
            "amorini\n",
            "amphiarthroses\n",
            "amphicia\n",
            "amphimixes\n",
            "amphioxi\n",
            "amphisbaenae\n",
            "amphorae\n",
            "ampullae\n",
            "amygdalae\n",
            "anabases\n",
            "anacolutha\n",
            "anacruses\n",
            "anaerobia\n",
            "anagnorises\n",
            "analemmata\n",
            "analyses\n",
            "anamneses\n",
            "anamorphoses\n",
            "anastomoses\n",
            "anatyxes\n",
            "ancones\n",
            "androclinia\n",
            "androecia\n",
            "androsphinges\n",
            "andtheridia\n",
            "angelfishes\n",
            "angiomata\n",
            "animalcula\n",
            "anlagen\n",
            "annattos\n",
            "annuli\n",
            "antae\n",
            "antalkalies\n",
            "antefixa\n",
            "antennae\n",
            "antependia\n",
            "anthelia\n",
            "anthelices\n",
            "anthemia\n",
            "antheridia\n",
            "anthodia\n",
            "anthozoa\n",
            "anthraces\n",
            "anticlinoria\n",
            "antihelices\n",
            "antiheroes\n",
            "antisera\n",
            "antitheses\n",
            "antitragi\n",
            "antra\n",
            "anus\n",
            "aortae\n",
            "aphelia\n",
            "aphides\n",
            "apices\n",
            "apodoses\n",
            "apomixes\n",
            "aponeuroses\n",
            "apophyses\n",
            "aposiopeses\n",
            "apothecia\n",
            "apotheoses\n",
            "apparatus\n",
            "appendices\n",
            "appoggiature\n",
            "apsides\n",
            "aquae\n",
            "aquaria\n",
            "araglis\n",
            "arboreta\n",
            "arcana\n",
            "archegonia\n",
            "archerfishes\n",
            "archesporia\n",
            "archipelagoes\n",
            "arcs-boutants\n",
            "areolae\n",
            "argali\n",
            "argumenta\n",
            "ariette\n",
            "aristae\n",
            "armamentaria\n",
            "arses\n",
            "artal\n",
            "artel\n",
            "arterioscleroses\n",
            "aruspices\n",
            "asceses\n",
            "asci\n",
            "ascidia\n",
            "ascogonia\n",
            "ashkenazim\n",
            "aspergilla\n",
            "aspergilli\n",
            "aspergilloses\n",
            "aspersoria\n",
            "assegais\n",
            "astragali\n",
            "asyndeta\n",
            "atheromata\n",
            "atheroscleroses\n",
            "atmolyses\n",
            "atria\n",
            "attorneys-at-law\n",
            "auditoria\n",
            "aurae\n",
            "aurar\n",
            "aurei\n",
            "auriculae\n",
            "aurorae\n",
            "auspices\n",
            "autocatalyses\n",
            "autochthones\n",
            "automata\n",
            "autos-da-fe\n",
            "avitaminoses\n",
            "axes\n",
            "axillae\n",
            "bacchantes\n",
            "bacchii\n",
            "bacilli\n",
            "bacteriostases\n",
            "bacula\n",
            "bains-marie\n",
            "bains_marie\n",
            "ballistae\n",
            "bambini\n",
            "bandeaux\n",
            "banditti\n",
            "bani\n",
            "banjoes\n",
            "barklice\n",
            "barramundies\n",
            "bases\n",
            "bases-on-balls\n",
            "bases_on_balls\n",
            "basidia\n",
            "basileis\n",
            "bassi\n",
            "bastinadoes\n",
            "bateaux\n",
            "batfishes\n",
            "beadsmen\n",
            "beaux\n",
            "beches-de-mer\n",
            "beeves\n",
            "behooves\n",
            "bersaglieri\n",
            "bhishties\n",
            "bibliothecae\n",
            "bicennaries\n",
            "bijoux\n",
            "bilboes\n",
            "billets-doux\n",
            "billfishes\n",
            "bimboes\n",
            "bisectrices\n",
            "blackfeet\n",
            "blackfishes\n",
            "blastemata\n",
            "blastulae\n",
            "blindfishes\n",
            "blowfishes\n",
            "bluefishes\n",
            "boarfishes\n",
            "bok\n",
            "boleti\n",
            "bolivares\n",
            "bolsheviki\n",
            "bonefishes\n",
            "bongoes\n",
            "bonitoes\n",
            "booklice\n",
            "bookshelves\n",
            "boraces\n",
            "borborygmi\n",
            "bordereaux\n",
            "botargoes\n",
            "box-kodaks\n",
            "boxfishes\n",
            "brachia\n",
            "brainchildren\n",
            "branchiae\n",
            "brants\n",
            "bravadoes\n",
            "bravoes\n",
            "bregmata\n",
            "brethren\n",
            "broadcast_media\n",
            "broadleaves\n",
            "bronchi\n",
            "brothers-in-law\n",
            "bryozoa\n",
            "buboes\n",
            "buckoes\n",
            "buckteeth\n",
            "buffaloes\n",
            "bullae\n",
            "bunde\n",
            "bureaux\n",
            "bureaux_de_change\n",
            "bursae\n",
            "bushbok\n",
            "bushboks\n",
            "busses\n",
            "butterfishes\n",
            "byssi\n",
            "cacti\n",
            "caducei\n",
            "caeca\n",
            "caesurae\n",
            "calami\n",
            "calathi\n",
            "calcanei\n",
            "calces\n",
            "calculi\n",
            "caldaria\n",
            "calices\n",
            "calicoes\n",
            "calli\n",
            "calves\n",
            "calyces\n",
            "cambia\n",
            "camerae\n",
            "canaliculi\n",
            "candelabra\n",
            "candlefishes\n",
            "canthi\n",
            "canulae\n",
            "canzoni\n",
            "capita\n",
            "capitula\n",
            "capricci\n",
            "carabinieri\n",
            "carbonadoes\n",
            "carcinomata\n",
            "cargoes\n",
            "carides\n",
            "carinae\n",
            "caroli\n",
            "carpi\n",
            "carpogonia\n",
            "carryings-on\n",
            "caryopses\n",
            "caryopsides\n",
            "castrati\n",
            "catabases\n",
            "cataclases\n",
            "cataloes\n",
            "catalyses\n",
            "catenae\n",
            "catfishes\n",
            "cathari\n",
            "cathexes\n",
            "cattaloes\n",
            "caudices\n",
            "caules\n",
            "cavatine\n",
            "cavefishes\n",
            "cavetti\n",
            "cavo-rilievi\n",
            "ceca\n",
            "cellae\n",
            "cembali\n",
            "centesimi\n",
            "centra\n",
            "cephalothoraces\n",
            "cercariae\n",
            "cercariiae\n",
            "cerci\n",
            "cerebella\n",
            "cerebra\n",
            "cervices\n",
            "cestuses\n",
            "cesurae\n",
            "chadarim\n",
            "chaetae\n",
            "chaises_longues\n",
            "chalazae\n",
            "challoth\n",
            "chalutzim\n",
            "chapaties\n",
            "chapatties\n",
            "chapeaux\n",
            "chasidim\n",
            "chassidim\n",
            "chateaux\n",
            "chazanim\n",
            "chedarim\n",
            "chefs-d'ouvre\n",
            "chelae\n",
            "chelicerae\n",
            "cherubim\n",
            "chevaux-de-frise\n",
            "chiasmata\n",
            "chiasmi\n",
            "children\n",
            "chillies\n",
            "chinese_eddoes\n",
            "chitarroni\n",
            "chlamydes\n",
            "chlamyses\n",
            "chondromata\n",
            "choragi\n",
            "choriambi\n",
            "choux\n",
            "chromonemata\n",
            "chrysalides\n",
            "chuvashes\n",
            "ciboria\n",
            "cicadae\n",
            "cicale\n",
            "cicatrices\n",
            "ciceroni\n",
            "cicisbei\n",
            "cilia\n",
            "cimices\n",
            "cineraria\n",
            "cingula\n",
            "cirri\n",
            "cirrocumuli\n",
            "cirrostrati\n",
            "ciscoes\n",
            "cisternae\n",
            "clani\n",
            "clanos\n",
            "claroes\n",
            "clepsydrae\n",
            "clinandria\n",
            "clingfishes\n",
            "clitella\n",
            "cloacae\n",
            "clostridia\n",
            "cloverleaves\n",
            "clypei\n",
            "coagula\n",
            "coalfishes\n",
            "cocci\n",
            "coccyges\n",
            "cochleae\n",
            "codfishes\n",
            "codices\n",
            "coelentera\n",
            "coenuri\n",
            "cognomina\n",
            "cola\n",
            "coleorhizae\n",
            "collegia\n",
            "colloquia\n",
            "colluvia\n",
            "collyria\n",
            "colones\n",
            "colossi\n",
            "columbaria\n",
            "columellae\n",
            "comae\n",
            "comatulae\n",
            "comedones\n",
            "comics\n",
            "commandoes\n",
            "concertanti\n",
            "concerti\n",
            "concerti_grossi\n",
            "concertini\n",
            "conchae\n",
            "condottieri\n",
            "condylomata\n",
            "confervae\n",
            "congii\n",
            "conidia\n",
            "conjunctivae\n",
            "conquistadores\n",
            "consortia\n",
            "contagia\n",
            "continua\n",
            "contralti\n",
            "conversazioni\n",
            "convolvuli\n",
            "cooks-general\n",
            "copulae\n",
            "corbiculae\n",
            "coria\n",
            "corneae\n",
            "cornua\n",
            "coronae\n",
            "corpora\n",
            "corpora_lutea\n",
            "corpora_striata\n",
            "corrigenda\n",
            "cortices\n",
            "cortinae\n",
            "corybantes\n",
            "coryphaei\n",
            "costae\n",
            "cothurni\n",
            "courts_martial\n",
            "couteaux\n",
            "cowfishes\n",
            "coxae\n",
            "cramboes\n",
            "crania\n",
            "crases\n",
            "crawfishes\n",
            "crayfishes\n",
            "credenda\n",
            "crematoria\n",
            "crescendi\n",
            "cribella\n",
            "crises\n",
            "crissa\n",
            "cristae\n",
            "criteria\n",
            "cruces\n",
            "crura\n",
            "crusadoes\n",
            "cruzadoes\n",
            "crying\n",
            "cryings\n",
            "ctenidia\n",
            "cubicula\n",
            "culices\n",
            "culpae\n",
            "culs-de-sac\n",
            "culti\n",
            "cumuli\n",
            "cumulonimbi\n",
            "cumulostrati\n",
            "curiae\n",
            "curricula\n",
            "custodes\n",
            "cutes\n",
            "cuticulae\n",
            "cuttlefishes\n",
            "cyclopes\n",
            "cycloses\n",
            "cylices\n",
            "cylikes\n",
            "cymae\n",
            "cymatia\n",
            "cypselae\n",
            "cysticerci\n",
            "dadoes\n",
            "dagoes\n",
            "damselfishes\n",
            "data\n",
            "daughters-in-law\n",
            "daymio\n",
            "daymios\n",
            "dealfishes\n",
            "decemviri\n",
            "decennia\n",
            "deciduae\n",
            "definienda\n",
            "definientia\n",
            "delphinia\n",
            "denarii\n",
            "dentalia\n",
            "dermatoses\n",
            "desiderata\n",
            "desperadoes\n",
            "devilfishes\n",
            "diaereses\n",
            "diaerses\n",
            "diagnoses\n",
            "dialyses\n",
            "diaphyses\n",
            "diapophyses\n",
            "diarthroses\n",
            "diastalses\n",
            "diastases\n",
            "diastemata\n",
            "diathses\n",
            "diazoes\n",
            "dibbukkim\n",
            "dichasia\n",
            "dicta\n",
            "didoes\n",
            "diereses\n",
            "dieses\n",
            "differentiae\n",
            "dilettanti\n",
            "diluvia\n",
            "dingoes\n",
            "diplococci\n",
            "directors-general\n",
            "disci\n",
            "discoboli\n",
            "dive\n",
            "diverticula\n",
            "divertimenti\n",
            "djinn\n",
            "dodoes\n",
            "dogfishes\n",
            "dogmata\n",
            "dogteeth\n",
            "dollarfishes\n",
            "domatia\n",
            "dominoes\n",
            "dormice\n",
            "dorsa\n",
            "drachmae\n",
            "drawknives\n",
            "drosophilae\n",
            "drumfishes\n",
            "dryades\n",
            "dui\n",
            "duona\n",
            "duonas\n",
            "dupondii\n",
            "duumviri\n",
            "dwarves\n",
            "dybbukkim\n",
            "ecchymoses\n",
            "ecclesiae\n",
            "ecdyses\n",
            "echidnae\n",
            "echini\n",
            "echinococci\n",
            "echoes\n",
            "ectozoa\n",
            "eddoes\n",
            "edemata\n",
            "effluvia\n",
            "eidola\n",
            "eisegeses\n",
            "eisteddfodau\n",
            "elenchi\n",
            "ellipses\n",
            "eluvia\n",
            "elves\n",
            "elytra\n",
            "embargoes\n",
            "emboli\n",
            "emphases\n",
            "emporia\n",
            "enarthroses\n",
            "encephala\n",
            "encephalitides\n",
            "encephalomata\n",
            "enchiridia\n",
            "enchondromata\n",
            "encomia\n",
            "endamebae\n",
            "endamoebae\n",
            "endocardia\n",
            "endocrania\n",
            "endometria\n",
            "endostea\n",
            "endostoses\n",
            "endothecia\n",
            "endothelia\n",
            "endotheliomata\n",
            "endozoa\n",
            "enemata\n",
            "enneahedra\n",
            "entamebae\n",
            "entamoebae\n",
            "entases\n",
            "entera\n",
            "entia\n",
            "entozoa\n",
            "epencephala\n",
            "epentheses\n",
            "epexegeses\n",
            "ephemera\n",
            "ephemerae\n",
            "ephemerides\n",
            "ephori\n",
            "epicalyces\n",
            "epicanthi\n",
            "epicardia\n",
            "epicedia\n",
            "epicleses\n",
            "epididymides\n",
            "epigastria\n",
            "epiglottides\n",
            "epimysia\n",
            "epiphenomena\n",
            "epiphyses\n",
            "episterna\n",
            "epithalamia\n",
            "epithelia\n",
            "epitheliomata\n",
            "epizoa\n",
            "epyllia\n",
            "equilibria\n",
            "equiseta\n",
            "eringoes\n",
            "errata\n",
            "eryngoes\n",
            "esophagi\n",
            "etyma\n",
            "eucalypti\n",
            "eupatridae\n",
            "euripi\n",
            "exanthemata\n",
            "executrices\n",
            "exegeses\n",
            "exempla\n",
            "exordia\n",
            "exostoses\n",
            "extrema\n",
            "eyeteeth\n",
            "fabliaux\n",
            "faciae\n",
            "faculae\n",
            "faeroese\n",
            "fallfishes\n",
            "famuli\n",
            "farmers-general\n",
            "faroese\n",
            "farragoes\n",
            "fasciae\n",
            "fasciculi\n",
            "fathers-in-law\n",
            "fatsoes\n",
            "faunae\n",
            "feculae\n",
            "fedayeen\n",
            "feet\n",
            "fellaheen\n",
            "fellahin\n",
            "felones_de_se\n",
            "felos_de_se\n",
            "femora\n",
            "fenestellae\n",
            "fenestrae\n",
            "feriae\n",
            "fermate\n",
            "ferulae\n",
            "festschriften\n",
            "fetiales\n",
            "fezzes\n",
            "fiascoes\n",
            "fibrillae\n",
            "fibromata\n",
            "fibulae\n",
            "ficoes\n",
            "fideicommissa\n",
            "fieldmice\n",
            "figs.\n",
            "fila\n",
            "filariiae\n",
            "filefishes\n",
            "fimbriae\n",
            "fishes\n",
            "fishwives\n",
            "fistulae\n",
            "flabella\n",
            "flagella\n",
            "flagstaves\n",
            "flambeaux\n",
            "flamines\n",
            "flamingoes\n",
            "flatfeet\n",
            "flatfishes\n",
            "fleurs-de-lis\n",
            "fleurs-de-lys\n",
            "flights_of_stairs\n",
            "flittermice\n",
            "flocci\n",
            "flocculi\n",
            "florae\n",
            "floreant.\n",
            "florilegia\n",
            "flowers-de-luce\n",
            "flyleaves\n",
            "foci\n",
            "folia\n",
            "fora\n",
            "foramina\n",
            "forceps\n",
            "forefeet\n",
            "foreteeth\n",
            "formicaria\n",
            "formulae\n",
            "fornices\n",
            "fortes\n",
            "fossae\n",
            "foveae\n",
            "foveolae\n",
            "fractocumuli\n",
            "fractostrati\n",
            "fraena\n",
            "frauen\n",
            "frena\n",
            "frenula\n",
            "frescoes\n",
            "fricandeaux\n",
            "fricandoes\n",
            "frijoles\n",
            "frogfishes\n",
            "frontes\n",
            "frusta\n",
            "fuci\n",
            "fulcra\n",
            "fumatoria\n",
            "fundi\n",
            "fungi\n",
            "funiculi\n",
            "furcula\n",
            "furculae\n",
            "furfures\n",
            "galeae\n",
            "gambadoes\n",
            "gametangia\n",
            "gametoecia\n",
            "gammadia\n",
            "ganglia\n",
            "garfishes\n",
            "gas\n",
            "gasses\n",
            "gastrulae\n",
            "gateaux\n",
            "gazeboes\n",
            "geckoes\n",
            "geese\n",
            "gelsemia\n",
            "gemboks\n",
            "gembucks\n",
            "gemeinschaften\n",
            "gemmae\n",
            "genera\n",
            "generatrices\n",
            "geneses\n",
            "genii\n",
            "gentes\n",
            "gentlemen-at-arms\n",
            "gentlemen-farmers\n",
            "genua\n",
            "genus\n",
            "germina\n",
            "gesellschaften\n",
            "gestalten\n",
            "ghettoes\n",
            "gingivae\n",
            "gingkoes\n",
            "ginglymi\n",
            "ginkgoes\n",
            "gippoes\n",
            "glabellae\n",
            "gladioli\n",
            "glandes\n",
            "gliomata\n",
            "glissandi\n",
            "globefishes\n",
            "globigerinae\n",
            "glochidcia\n",
            "glochidia\n",
            "glomeruli\n",
            "glossae\n",
            "glottides\n",
            "glutaei\n",
            "glutei\n",
            "gnoses\n",
            "goatfishes\n",
            "goboes\n",
            "godchildren\n",
            "goes\n",
            "goings-over\n",
            "goldfishes\n",
            "gomphoses\n",
            "gonia\n",
            "gonidia\n",
            "gonococci\n",
            "goodwives\n",
            "goosefishes\n",
            "gorgoneia\n",
            "gospopoda\n",
            "governors_general\n",
            "goyim\n",
            "grafen\n",
            "graffiti\n",
            "grandchildren\n",
            "grants-in-aid\n",
            "granulomata\n",
            "gravamina\n",
            "grig-gris\n",
            "groszy\n",
            "grottoes\n",
            "guilder\n",
            "guilders\n",
            "guitarfishes\n",
            "gummata\n",
            "gurnard\n",
            "gurnards\n",
            "guttae\n",
            "gymnasia\n",
            "gynaecea\n",
            "gynaecia\n",
            "gynecea\n",
            "gynecia\n",
            "gynoecea\n",
            "gynoecia\n",
            "gyri\n",
            "hadarim\n",
            "hadjes\n",
            "haematolyses\n",
            "haematomata\n",
            "haematozoa\n",
            "haemodialyses\n",
            "haemolyses\n",
            "haemoptyses\n",
            "haeredes\n",
            "haftaroth\n",
            "hagfishes\n",
            "haggadas\n",
            "haggadoth\n",
            "hajjes\n",
            "haleru\n",
            "hallot\n",
            "halloth\n",
            "halluces\n",
            "haloes\n",
            "halteres\n",
            "halves\n",
            "hamuli\n",
            "hangers-on\n",
            "haphtaroth\n",
            "haredim\n",
            "haruspices\n",
            "hasidim\n",
            "hassidim\n",
            "haustella\n",
            "haustoria\n",
            "hazzanim\n",
            "hectocotyli\n",
            "heirs-at-law\n",
            "heldentenore\n",
            "helices\n",
            "heliozoa\n",
            "hematolyses\n",
            "hematomata\n",
            "hematozoa\n",
            "hemelytra\n",
            "hemielytra\n",
            "hemodialyses\n",
            "hemolyses\n",
            "hemoptyses\n",
            "hendecahedra\n",
            "hens-and-chickens\n",
            "heraclidae\n",
            "heraklidae\n",
            "herbaria\n",
            "hermae\n",
            "hermai\n",
            "herniae\n",
            "heroes\n",
            "herren\n",
            "hetaerae\n",
            "hetairai\n",
            "hibernacula\n",
            "hieracosphinges\n",
            "hila\n",
            "hili\n",
            "himatia\n",
            "hippocampi\n",
            "hippopotami\n",
            "his\n",
            "hoboes\n",
            "hogfishes\n",
            "homunculi\n",
            "honoraria\n",
            "hooves\n",
            "horologia\n",
            "housewives\n",
            "humeri\n",
            "hydrae\n",
            "hydromedusae\n",
            "hydrozoa\n",
            "hymenoptera\n",
            "hynia\n",
            "hyniums\n",
            "hypanthia\n",
            "hyperostoses\n",
            "hyphae\n",
            "hypnoses\n",
            "hypochondria\n",
            "hypogastria\n",
            "hypogea\n",
            "hypophyses\n",
            "hypostases\n",
            "hypothalami\n",
            "hypotheses\n",
            "hyraces\n",
            "iambi\n",
            "ibices\n",
            "ibo\n",
            "ichthyosauri\n",
            "ichthyosauruses\n",
            "iconostases\n",
            "icosahedra\n",
            "ideata\n",
            "igorrorote\n",
            "ilia\n",
            "imagines\n",
            "imagoes\n",
            "imperia\n",
            "impies\n",
            "incubi\n",
            "incudes\n",
            "indices\n",
            "indigoes\n",
            "indumenta\n",
            "indusia\n",
            "infundibula\n",
            "ingushes\n",
            "innuendoes\n",
            "inocula\n",
            "inquisitors-general\n",
            "insectaria\n",
            "insulae\n",
            "intagli\n",
            "interleaves\n",
            "intermezzi\n",
            "interreges\n",
            "interregna\n",
            "intimae\n",
            "involucella\n",
            "involucra\n",
            "involucra\n",
            "irides\n",
            "irs\n",
            "is\n",
            "ischia\n",
            "isthmi\n",
            "jackeroos\n",
            "jackfishes\n",
            "jackknives\n",
            "jacks-in-the-box\n",
            "jambeaux\n",
            "jellyfishes\n",
            "jewelfishes\n",
            "jewfishes\n",
            "jingoes\n",
            "jinn\n",
            "joes\n",
            "judge_advocates_general\n",
            "jura\n",
            "kaddishim\n",
            "kalmuck\n",
            "kalmucks\n",
            "katabases\n",
            "keeshonden\n",
            "kibbutzim\n",
            "killifishes\n",
            "kingfishes\n",
            "kings-of-arms\n",
            "knights_bachelor\n",
            "knights_bachelors\n",
            "knights_templar\n",
            "knights_templars\n",
            "knives\n",
            "kohlrabies\n",
            "kronen\n",
            "kroner\n",
            "kronur\n",
            "krooni\n",
            "kylikes\n",
            "labara\n",
            "labella\n",
            "labia\n",
            "labra\n",
            "lactobacilli\n",
            "lacunae\n",
            "lacunaria\n",
            "ladies-in-waiting\n",
            "lamellae\n",
            "lamiae\n",
            "laminae\n",
            "lapilli\n",
            "lapithae\n",
            "larvae\n",
            "larynges\n",
            "lassoes\n",
            "lati\n",
            "latices\n",
            "latifundia\n",
            "latu\n",
            "lavaboes\n",
            "leaves\n",
            "lecythi\n",
            "leges\n",
            "lei\n",
            "lemmata\n",
            "lemnisci\n",
            "lenes\n",
            "lentigines\n",
            "leonides\n",
            "lepidoptera\n",
            "leprosaria\n",
            "lepta\n",
            "leptocephali\n",
            "leucocytozoa\n",
            "leva\n",
            "librae\n",
            "libretti\n",
            "lice\n",
            "lieder\n",
            "ligulae\n",
            "limbi\n",
            "limina\n",
            "limites\n",
            "limuli\n",
            "lingoes\n",
            "linguae\n",
            "linguae_francae\n",
            "lionfishes\n",
            "lipomata\n",
            "lire\n",
            "liriodendra\n",
            "listente\n",
            "litai\n",
            "litu\n",
            "lives\n",
            "lixivia\n",
            "loaves\n",
            "loci\n",
            "loculi\n",
            "loggie\n",
            "logia\n",
            "lomenta\n",
            "longobardi\n",
            "loricae\n",
            "luba\n",
            "lubritoria\n",
            "lumbus\n",
            "lumina\n",
            "lumpfishes\n",
            "lungfishes\n",
            "lunulae\n",
            "lures\n",
            "lustra\n",
            "lyings-in\n",
            "lymphangitides\n",
            "lymphomata\n",
            "lymphopoieses\n",
            "lyses\n",
            "lyttae\n",
            "maare\n",
            "macaronies\n",
            "maccaronies\n",
            "machzorim\n",
            "macronuclei\n",
            "macrosporangia\n",
            "maculae\n",
            "madornos\n",
            "maestri\n",
            "mafiosi\n",
            "magi\n",
            "magmata\n",
            "magnificoes\n",
            "mahzorim\n",
            "major-axes\n",
            "major_axes\n",
            "makuta\n",
            "mallei\n",
            "malleoli\n",
            "maloti\n",
            "mamillae\n",
            "mammae\n",
            "mammillae\n",
            "mandingoes\n",
            "mangoes\n",
            "manifestoes\n",
            "manteaux\n",
            "mantes\n",
            "manubria\n",
            "marchese\n",
            "marchesi\n",
            "maremme\n",
            "markkaa\n",
            "marsupia\n",
            "marvels-of-peru\n",
            "mass_media\n",
            "masses\n",
            "masters-at-arms\n",
            "matrices\n",
            "matzoth\n",
            "mausolea\n",
            "maxillae\n",
            "maxima\n",
            "media\n",
            "mediae\n",
            "mediastina\n",
            "medullae\n",
            "medullae_oblongatae\n",
            "medusae\n",
            "megara\n",
            "megasporangia\n",
            "megilloth\n",
            "meioses\n",
            "melanomata\n",
            "melismata\n",
            "mementoes\n",
            "memoranda\n",
            "men\n",
            "men-at-arms\n",
            "men-o'-war\n",
            "men-of-war\n",
            "men_of_letters\n",
            "menisci\n",
            "menservants\n",
            "menstrua\n",
            "mesdames\n",
            "mesdemoiselles\n",
            "mesentera\n",
            "mesothoraces\n",
            "messeigneurs\n",
            "messieurs\n",
            "mestizoes\n",
            "metacarpi\n",
            "metamorphoses\n",
            "metanephroi\n",
            "metastases\n",
            "metatarsi\n",
            "metatheses\n",
            "metathoraces\n",
            "metazoa\n",
            "metempsychoses\n",
            "metencephala\n",
            "mezuzoth\n",
            "miasmata\n",
            "mice\n",
            "microanalyses\n",
            "micrococci\n",
            "micronuclei\n",
            "microsporangia\n",
            "midrashim\n",
            "midwives\n",
            "milia\n",
            "milieux\n",
            "militated_against\n",
            "milkfishes\n",
            "millennia\n",
            "minae\n",
            "minima\n",
            "ministeria\n",
            "minutiae\n",
            "minyanim\n",
            "mioses\n",
            "miracidia\n",
            "miri\n",
            "mishnayoth\n",
            "mitochondria\n",
            "mitzvoth\n",
            "modioli\n",
            "moduli\n",
            "momenta\n",
            "moments_of_truth\n",
            "momi\n",
            "monades\n",
            "monkfishes\n",
            "monochasia\n",
            "monopodia\n",
            "monoptera\n",
            "monopteroi\n",
            "monsignori\n",
            "monts-de-piete\n",
            "mooncalves\n",
            "moonfishes\n",
            "morae\n",
            "moratoria\n",
            "morceaux\n",
            "morescoes\n",
            "moriscoes\n",
            "morphallaxes\n",
            "morphoses\n",
            "morulae\n",
            "mosasauri\n",
            "moshavim\n",
            "moslim\n",
            "moslims\n",
            "mosquitoes\n",
            "mothers-in-law\n",
            "mothers_superior\n",
            "mottoes\n",
            "movers_and_shakers\n",
            "mucosae\n",
            "mucrones\n",
            "mudejares\n",
            "mudfishes\n",
            "mulattoes\n",
            "multiparae\n",
            "murices\n",
            "muskallunge\n",
            "mycelia\n",
            "mycetomata\n",
            "mycobacteria\n",
            "mycorrhizae\n",
            "myelencephala\n",
            "myiases\n",
            "myocardia\n",
            "myofibrillae\n",
            "myomata\n",
            "myoses\n",
            "myrmidones\n",
            "mythoi\n",
            "myxomata\n",
            "naevi\n",
            "naiades\n",
            "naoi\n",
            "narcissi\n",
            "nares\n",
            "nasopharynges\n",
            "natatoria\n",
            "naumachiae\n",
            "nauplii\n",
            "nautili\n",
            "navahoes\n",
            "navajoes\n",
            "nebulae\n",
            "necropoleis\n",
            "needlefishes\n",
            "negrilloes\n",
            "negritoes\n",
            "negroes\n",
            "nemeses\n",
            "nephridia\n",
            "nereides\n",
            "neurohypophyses\n",
            "neuromata\n",
            "neuroptera\n",
            "neuroses\n",
            "nevi\n",
            "nibelungen\n",
            "nidi\n",
            "nielli\n",
            "nilgai\n",
            "nimbi\n",
            "nimbostrati\n",
            "noctilucae\n",
            "nodi\n",
            "noes\n",
            "nomina\n",
            "nota\n",
            "noumena\n",
            "novae\n",
            "novelle\n",
            "novenae\n",
            "nubeculae\n",
            "nucelli\n",
            "nuchae\n",
            "nuclei\n",
            "nucleoli\n",
            "nulliparae\n",
            "numbfishes\n",
            "numina\n",
            "nymphae\n",
            "oarfishes\n",
            "oases\n",
            "obeli\n",
            "objets_d'art\n",
            "obligati\n",
            "oboli\n",
            "occipita\n",
            "oceanaria\n",
            "oceanides\n",
            "ocelli\n",
            "ochreae\n",
            "ocreae\n",
            "octahedra\n",
            "octopi\n",
            "oculi\n",
            "odea\n",
            "oedemata\n",
            "oesophagi\n",
            "oldwives\n",
            "olea\n",
            "omasa\n",
            "omayyades\n",
            "omenta\n",
            "ommatidia\n",
            "ommiades\n",
            "onagri\n",
            "oogonia\n",
            "oothecae\n",
            "operas_seria\n",
            "opercula\n",
            "optima\n",
            "ora\n",
            "organa\n",
            "organums\n",
            "orthoptera\n",
            "osar\n",
            "oscula\n",
            "ossa\n",
            "osteomata\n",
            "ostia\n",
            "ottomans\n",
            "ova\n",
            "ovoli\n",
            "ovotestes\n",
            "oxen\n",
            "oxymora\n",
            "paddlefishes\n",
            "paise\n",
            "paleae\n",
            "palestrae\n",
            "palingeneses\n",
            "pallia\n",
            "palmettoes\n",
            "palpi\n",
            "pancratia\n",
            "panettoni\n",
            "paparazzi\n",
            "paperknives\n",
            "papillae\n",
            "papillomata\n",
            "pappi\n",
            "papulae\n",
            "papyri\n",
            "parabases\n",
            "paraleipses\n",
            "paralyses\n",
            "paramecia\n",
            "paramenta\n",
            "paraphyses\n",
            "parapodia\n",
            "parapraxes\n",
            "paraselenae\n",
            "parashoth\n",
            "parasyntheta\n",
            "parazoa\n",
            "parentheses\n",
            "parerga\n",
            "parhelia\n",
            "parietes\n",
            "paris-mutuels\n",
            "parrotfishes\n",
            "parulides\n",
            "pasos_dobles\n",
            "passers-by\n",
            "pastorali\n",
            "patagia\n",
            "patellae\n",
            "patinae\n",
            "patresfamilias\n",
            "pease\n",
            "peccadilloes\n",
            "pectines\n",
            "pedaloes\n",
            "pedes\n",
            "pekingese\n",
            "pelves\n",
            "pence\n",
            "penes\n",
            "penetralium\n",
            "penicillia\n",
            "penknives\n",
            "pennae\n",
            "pennia\n",
            "pentahedra\n",
            "pentimenti\n",
            "penumbrae\n",
            "pepla\n",
            "pericardia\n",
            "perichondria\n",
            "pericrania\n",
            "peridia\n",
            "perigonia\n",
            "perihelia\n",
            "perinea\n",
            "perinephria\n",
            "perionychia\n",
            "periostea\n",
            "periphrases\n",
            "peristalses\n",
            "perithecia\n",
            "peritonea\n",
            "personae\n",
            "petechiae\n",
            "pfennige\n",
            "phalanges\n",
            "phalli\n",
            "pharynges\n",
            "phenomena\n",
            "phi-phenomena\n",
            "philodendra\n",
            "phlyctenae\n",
            "phyla\n",
            "phylae\n",
            "phyllotaxes\n",
            "phylloxerae\n",
            "phylogeneses\n",
            "pieds-a-terre\n",
            "pigfishes\n",
            "pilea\n",
            "pilei\n",
            "pineta\n",
            "pinfishes\n",
            "pinkoes\n",
            "pinnae\n",
            "pinnulae\n",
            "pipefishes\n",
            "pirogi\n",
            "piscinae\n",
            "pithecanthropi\n",
            "pithoi\n",
            "placeboes\n",
            "placentae\n",
            "planetaria\n",
            "planulae\n",
            "plasmodesmata\n",
            "plasmodia\n",
            "plateaux\n",
            "plectra\n",
            "plena\n",
            "pleura\n",
            "pleurae\n",
            "plicae\n",
            "ploughmen\n",
            "pneumobacilli\n",
            "pneumococci\n",
            "pocketknives\n",
            "podetia\n",
            "podia\n",
            "poleis\n",
            "pollices\n",
            "pollinia\n",
            "polychasia\n",
            "polyhedra\n",
            "polyparia\n",
            "polypi\n",
            "polyzoa\n",
            "polyzoaria\n",
            "pontes\n",
            "pontifices\n",
            "portamenti\n",
            "porticoes\n",
            "portmanteaux\n",
            "postliminia\n",
            "potatoes\n",
            "praenomina\n",
            "praxes\n",
            "predelle\n",
            "premaxillae\n",
            "prenomina\n",
            "prese\n",
            "primi\n",
            "primigravidae\n",
            "primiparae\n",
            "primordia\n",
            "principia\n",
            "proboscides\n",
            "proces-verbaux\n",
            "proglottides\n",
            "prognoses\n",
            "prolegomena\n",
            "prolepses\n",
            "promycelia\n",
            "pronephra\n",
            "pronephroi\n",
            "pronuclei\n",
            "propositi\n",
            "proptoses\n",
            "propyla\n",
            "propylaea\n",
            "proscenia\n",
            "prosencephala\n",
            "prostheses\n",
            "prostomia\n",
            "protases\n",
            "prothalamia\n",
            "prothalli\n",
            "prothallia\n",
            "prothoraces\n",
            "protonemata\n",
            "protozoa\n",
            "proventriculi\n",
            "provisoes\n",
            "prytanea\n",
            "psalteria\n",
            "pseudopodia\n",
            "psychoneuroses\n",
            "psychoses\n",
            "pterygia\n",
            "pterylae\n",
            "ptoses\n",
            "pubes\n",
            "pudenda\n",
            "puli\n",
            "pulvilli\n",
            "pulvini\n",
            "punchinelloes\n",
            "pupae\n",
            "puparia\n",
            "putamina\n",
            "putti\n",
            "pycnidia\n",
            "pygidia\n",
            "pylori\n",
            "pyxides\n",
            "pyxidia\n",
            "qaddishim\n",
            "quadrennia\n",
            "quadrigae\n",
            "qualia\n",
            "quanta\n",
            "quarterstaves\n",
            "quezales\n",
            "quinquennia\n",
            "quizzes\n",
            "rabatos\n",
            "rabbitfishes\n",
            "rachides\n",
            "radices\n",
            "radii\n",
            "radulae\n",
            "ramenta\n",
            "rami\n",
            "ranulae\n",
            "ranunculi\n",
            "raphae\n",
            "raphides\n",
            "ratfishes\n",
            "reales\n",
            "rearmice\n",
            "recta\n",
            "recti\n",
            "rectrices\n",
            "redfishes\n",
            "rediae\n",
            "referenda\n",
            "refugia\n",
            "reguli\n",
            "reis\n",
            "relata\n",
            "remiges\n",
            "reremice\n",
            "reseaux\n",
            "residua\n",
            "responsa\n",
            "retia\n",
            "retiarii\n",
            "reticula\n",
            "retinacula\n",
            "retinae\n",
            "rhabdomyomata\n",
            "rhachides\n",
            "rhachises\n",
            "rhinencephala\n",
            "rhizobia\n",
            "rhombi\n",
            "rhonchi\n",
            "rhyta\n",
            "ribbonfishes\n",
            "ricercacari\n",
            "ricercari\n",
            "rickettsiae\n",
            "rilievi\n",
            "rimae\n",
            "robes-de-chambre\n",
            "rockfishes\n",
            "roma\n",
            "romans-fleuves\n",
            "rondeaux\n",
            "rosaria\n",
            "rosefishes\n",
            "rostella\n",
            "rostra\n",
            "rouleaux\n",
            "rugae\n",
            "rumina\n",
            "runners-up\n",
            "sacra\n",
            "sacraria\n",
            "saguaros\n",
            "sailfishes\n",
            "salespeople\n",
            "salmonellae\n",
            "salpae\n",
            "salpinges\n",
            "saltarelli\n",
            "salvoes\n",
            "sancta\n",
            "sanitaria\n",
            "santimi\n",
            "saphenae\n",
            "sarcophagi\n",
            "sartorii\n",
            "sassanidae\n",
            "sawfishes\n",
            "scaldfishes\n",
            "scaleni\n",
            "scapulae\n",
            "scarabaei\n",
            "scarves\n",
            "schatchonim\n",
            "schemata\n",
            "scherzandi\n",
            "scherzi\n",
            "schmoes\n",
            "scholia\n",
            "schuln\n",
            "schutzstaffeln\n",
            "scirrhi\n",
            "scleromata\n",
            "scleroses\n",
            "sclerotia\n",
            "scoleces\n",
            "scolices\n",
            "scopulae\n",
            "scoriae\n",
            "scotomata\n",
            "scriptoria\n",
            "scrota\n",
            "scudi\n",
            "scuta\n",
            "scutella\n",
            "scyphi\n",
            "scyphistomae\n",
            "scyphozoa\n",
            "secondi\n",
            "secretaries-general\n",
            "segni\n",
            "seleucidae\n",
            "selves\n",
            "senores\n",
            "sensilla\n",
            "senti\n",
            "senussis\n",
            "separatrices\n",
            "sephardim\n",
            "septa\n",
            "septaria\n",
            "septennia\n",
            "sequelae\n",
            "sequestra\n",
            "sera\n",
            "seraphim\n",
            "sestertia\n",
            "setae\n",
            "sgraffiti\n",
            "shabbasim\n",
            "shabbatim\n",
            "shackoes\n",
            "shadchanim\n",
            "shadchans\n",
            "shakoes\n",
            "shammosim\n",
            "sheatfishes\n",
            "sheaves\n",
            "shellfishes\n",
            "shelves\n",
            "shinleaves\n",
            "shittim\n",
            "shmoes\n",
            "shofroth\n",
            "shophroth\n",
            "shrewmice\n",
            "shuln\n",
            "siddurim\n",
            "sigloi\n",
            "signore\n",
            "signori\n",
            "signorine\n",
            "siliquae\n",
            "silvae\n",
            "silverfishes\n",
            "simulacra\n",
            "sincipita\n",
            "sinfonie\n",
            "sisters-in-law\n",
            "sistra\n",
            "situlae\n",
            "smalti\n",
            "snaggleteeth\n",
            "snailfishes\n",
            "snipefishes\n",
            "socmen\n",
            "sola\n",
            "solaria\n",
            "solatia\n",
            "soldi\n",
            "soles\n",
            "solfeggi\n",
            "soli\n",
            "solidi\n",
            "somata\n",
            "sons-in-law\n",
            "soprani\n",
            "sordini\n",
            "sori\n",
            "soroses\n",
            "sovkhozy\n",
            "spadefishes\n",
            "spadices\n",
            "spearfishes\n",
            "spectra\n",
            "specula\n",
            "spermatia\n",
            "spermatogonia\n",
            "spermatozoa\n",
            "spermogonia\n",
            "sphinges\n",
            "spicae\n",
            "spicula\n",
            "spirilla\n",
            "splayfeet\n",
            "splenii\n",
            "sporangia\n",
            "sporogonia\n",
            "sporozoa\n",
            "springhase\n",
            "spumoni\n",
            "sputa\n",
            "squamae\n",
            "squashes\n",
            "squillae\n",
            "squirrelfishes\n",
            "squizzes\n",
            "stadia\n",
            "stamina\n",
            "staminodia\n",
            "stapedes\n",
            "staphylococci\n",
            "starfishes\n",
            "startsy\n",
            "stelae\n",
            "stemmata\n",
            "stenoses\n",
            "stepchildren\n",
            "sterna\n",
            "stigmata\n",
            "stimuli\n",
            "stipites\n",
            "stirpes\n",
            "stoae\n",
            "stockfishes\n",
            "stomata\n",
            "stomodaea\n",
            "stomodea\n",
            "stonefishes\n",
            "stotinki\n",
            "stotkini\n",
            "strappadoes\n",
            "strata\n",
            "strati\n",
            "stratocumuli\n",
            "street_children\n",
            "streptococci\n",
            "stretti\n",
            "striae\n",
            "strobili\n",
            "stromata\n",
            "strumae\n",
            "stuccoes\n",
            "styli\n",
            "stylopes\n",
            "stylopodia\n",
            "subcortices\n",
            "subdeliria\n",
            "subgenera\n",
            "subindices\n",
            "submucosae\n",
            "subphyla\n",
            "substrasta\n",
            "succedanea\n",
            "succubi\n",
            "suckerfishes\n",
            "suckfishes\n",
            "sudaria\n",
            "sudatoria\n",
            "sulci\n",
            "summae\n",
            "sunfishes\n",
            "supercargoes\n",
            "superheroes\n",
            "supernovae\n",
            "superstrata\n",
            "surgeonfishes\n",
            "swamies\n",
            "sweetiewives\n",
            "swellfishes\n",
            "swordfishes\n",
            "syconia\n",
            "syllabi\n",
            "syllepses\n",
            "symphyses\n",
            "sympodia\n",
            "symposia\n",
            "synapses\n",
            "synarthroses\n",
            "synclinoria\n",
            "syncytia\n",
            "syndesmoses\n",
            "synopses\n",
            "syntagmata\n",
            "syntheses\n",
            "syphilomata\n",
            "syringes\n",
            "syssarcoses\n",
            "tableaux\n",
            "taeniae\n",
            "tali\n",
            "tallaisim\n",
            "tallithes\n",
            "tallitoth\n",
            "tapeta\n",
            "tarantulae\n",
            "tarsi\n",
            "tarsometatarsi\n",
            "taxa\n",
            "taxes\n",
            "taxies\n",
            "tectrices\n",
            "teeth\n",
            "tegmina\n",
            "telae\n",
            "telamones\n",
            "telangiectases\n",
            "telia\n",
            "tempi\n",
            "tenacula\n",
            "tenderfeet\n",
            "teniae\n",
            "tenues\n",
            "teraphim\n",
            "terata\n",
            "teredines\n",
            "terga\n",
            "termini\n",
            "terraria\n",
            "terzetti\n",
            "tesserae\n",
            "testae\n",
            "testes\n",
            "testudines\n",
            "tetrahedra\n",
            "tetraskelia\n",
            "thalamencephala\n",
            "thalami\n",
            "thalli\n",
            "theatres-in-the-round\n",
            "thecae\n",
            "therses\n",
            "thesauri\n",
            "theses\n",
            "thickleaves\n",
            "thieves\n",
            "tholoi\n",
            "thoraces\n",
            "thrombi\n",
            "thymi\n",
            "thyrsi\n",
            "tibiae\n",
            "tilefishes\n",
            "tintinnabula\n",
            "titmice\n",
            "toadfishes\n",
            "tobaccoes\n",
            "tomatoes\n",
            "tomenta\n",
            "tondi\n",
            "tonneaux\n",
            "tophi\n",
            "topoi\n",
            "tori\n",
            "tornadoes\n",
            "torpedoes\n",
            "torsi\n",
            "touracos\n",
            "trabeculae\n",
            "tracheae\n",
            "traditores\n",
            "tragi\n",
            "trapezia\n",
            "trapezohedra\n",
            "traumata\n",
            "treponemata\n",
            "trichinae\n",
            "triclinia\n",
            "triennia\n",
            "triforia\n",
            "triggerfishes\n",
            "trihedra\n",
            "triskelia\n",
            "trisoctahedra\n",
            "triumviri\n",
            "trivia\n",
            "trochleae\n",
            "tropaeola\n",
            "trous-de-loup\n",
            "trousseaux\n",
            "trunkfishes\n",
            "trymata\n",
            "tubae\n",
            "turves\n",
            "tympana\n",
            "tyros\n",
            "ubermenschen\n",
            "uglies\n",
            "uigurs\n",
            "ulnae\n",
            "ultimata\n",
            "umbilici\n",
            "umbones\n",
            "umbrae\n",
            "unci\n",
            "uncidia\n",
            "uredines\n",
            "uredinia\n",
            "uredosori\n",
            "urethrae\n",
            "urinalyses\n",
            "uteri\n",
            "utriculi\n",
            "uvulae\n",
            "vacua\n",
            "vagi\n",
            "vaginae\n",
            "valleculae\n",
            "vaporetti\n",
            "varices\n",
            "vasa\n",
            "vascula\n",
            "vela\n",
            "velamina\n",
            "velaria\n",
            "venae\n",
            "venae_cavae\n",
            "ventriculi\n",
            "vermes\n",
            "verrucae\n",
            "vertebrae\n",
            "vertices\n",
            "vertigines\n",
            "vertigoes\n",
            "vesicae\n",
            "vetoes\n",
            "vexilla\n",
            "viatica\n",
            "viatores\n",
            "vibracula\n",
            "vibrissae\n",
            "vice-chairman\n",
            "villi\n",
            "vimina\n",
            "vincula\n",
            "viragoes\n",
            "vires\n",
            "virtuosi\n",
            "vitae\n",
            "vitelli\n",
            "vittae\n",
            "vivaria\n",
            "voces\n",
            "volcanoes\n",
            "volkslieder\n",
            "volte\n",
            "volvae\n",
            "vorticellae\n",
            "vortices\n",
            "vulvae\n",
            "wagons-lits\n",
            "wahhabis\n",
            "wanderjahre\n",
            "weakfishes\n",
            "werewolves\n",
            "wharves\n",
            "whippers-in\n",
            "whitefishes\n",
            "wives\n",
            "wolffishes\n",
            "wolves\n",
            "woodlice\n",
            "wreckfishes\n",
            "wunderkinder\n",
            "xiphisterna\n",
            "yeshivahs\n",
            "yeshivoth\n",
            "yogin\n",
            "yourselves\n",
            "zamindaris\n",
            "zecchini\n",
            "zeroes\n",
            "zoa\n",
            "zoaeae\n",
            "zoeae\n",
            "zoeas\n",
            "zoonoses\n",
            "zoosporangia\n",
            "adj.exc\n",
            "acer\n",
            "after\n",
            "airier\n",
            "airiest\n",
            "all-arounder\n",
            "angrier\n",
            "angriest\n",
            "archer\n",
            "artier\n",
            "artiest\n",
            "ashier\n",
            "ashiest\n",
            "assaulter\n",
            "attacker\n",
            "backer\n",
            "baggier\n",
            "baggiest\n",
            "balkier\n",
            "balkiest\n",
            "balmier\n",
            "balmiest\n",
            "bandier\n",
            "bandiest\n",
            "bargainer\n",
            "barmier\n",
            "barmiest\n",
            "battier\n",
            "battiest\n",
            "baulkier\n",
            "baulkiest\n",
            "bawdier\n",
            "bawdiest\n",
            "bayer\n",
            "beadier\n",
            "beadiest\n",
            "beastlier\n",
            "beastliest\n",
            "beater\n",
            "beefier\n",
            "beefiest\n",
            "beerier\n",
            "beeriest\n",
            "bendier\n",
            "bendiest\n",
            "best\n",
            "better\n",
            "bigger\n",
            "biggest\n",
            "bitchier\n",
            "bitchiest\n",
            "biter\n",
            "bittier\n",
            "bittiest\n",
            "blearier\n",
            "bleariest\n",
            "bloodier\n",
            "bloodiest\n",
            "bloodthirstier\n",
            "bloodthirstiest\n",
            "blowier\n",
            "blowiest\n",
            "blowsier\n",
            "blowsiest\n",
            "blowzier\n",
            "blowziest\n",
            "bluer\n",
            "bluest\n",
            "boner\n",
            "bonier\n",
            "boniest\n",
            "bonnier\n",
            "bonniest\n",
            "boozier\n",
            "booziest\n",
            "boskier\n",
            "boskiest\n",
            "bossier\n",
            "bossiest\n",
            "botchier\n",
            "botchiest\n",
            "bother\n",
            "bouncier\n",
            "bounciest\n",
            "bounder\n",
            "bower\n",
            "brainier\n",
            "brainiest\n",
            "brashier\n",
            "brashiest\n",
            "brassier\n",
            "brassiest\n",
            "brawnier\n",
            "brawniest\n",
            "breathier\n",
            "breathiest\n",
            "breezier\n",
            "breeziest\n",
            "brinier\n",
            "briniest\n",
            "britisher\n",
            "broadcaster\n",
            "brooder\n",
            "broodier\n",
            "broodiest\n",
            "bubblier\n",
            "bubbliest\n",
            "buggier\n",
            "buggiest\n",
            "bulkier\n",
            "bulkiest\n",
            "bumpier\n",
            "bumpiest\n",
            "bunchier\n",
            "bunchiest\n",
            "burlier\n",
            "burliest\n",
            "burrier\n",
            "burriest\n",
            "burster\n",
            "bushier\n",
            "bushiest\n",
            "busier\n",
            "busiest\n",
            "buster\n",
            "bustier\n",
            "bustiest\n",
            "cagier\n",
            "cagiest\n",
            "camper\n",
            "cannier\n",
            "canniest\n",
            "canter\n",
            "cantier\n",
            "cantiest\n",
            "caster\n",
            "catchier\n",
            "catchiest\n",
            "cattier\n",
            "cattiest\n",
            "cer\n",
            "chancier\n",
            "chanciest\n",
            "charier\n",
            "chariest\n",
            "chattier\n",
            "chattiest\n",
            "cheekier\n",
            "cheekiest\n",
            "cheerier\n",
            "cheeriest\n",
            "cheesier\n",
            "cheesiest\n",
            "chestier\n",
            "chestiest\n",
            "chewier\n",
            "chewiest\n",
            "chillier\n",
            "chilliest\n",
            "chintzier\n",
            "chintziest\n",
            "chippier\n",
            "chippiest\n",
            "choosier\n",
            "choosiest\n",
            "choppier\n",
            "choppiest\n",
            "chubbier\n",
            "chubbiest\n",
            "chuffier\n",
            "chuffiest\n",
            "chummier\n",
            "chummiest\n",
            "chunkier\n",
            "chunkiest\n",
            "churchier\n",
            "churchiest\n",
            "clammier\n",
            "clammiest\n",
            "classier\n",
            "classiest\n",
            "cleanlier\n",
            "cleanliest\n",
            "clerklier\n",
            "clerkliest\n",
            "cloudier\n",
            "cloudiest\n",
            "clubbier\n",
            "clubbiest\n",
            "clumsier\n",
            "clumsiest\n",
            "cockier\n",
            "cockiest\n",
            "coder\n",
            "collier\n",
            "colliest\n",
            "comelier\n",
            "comeliest\n",
            "comfier\n",
            "comfiest\n",
            "cornier\n",
            "corniest\n",
            "cosier\n",
            "cosiest\n",
            "costlier\n",
            "costliest\n",
            "costumer\n",
            "counterfeiter\n",
            "courtlier\n",
            "courtliest\n",
            "cozier\n",
            "coziest\n",
            "crabbier\n",
            "crabbiest\n",
            "cracker\n",
            "craftier\n",
            "craftiest\n",
            "craggier\n",
            "craggiest\n",
            "crankier\n",
            "crankiest\n",
            "crasher\n",
            "crawlier\n",
            "crawliest\n",
            "crazier\n",
            "craziest\n",
            "creamer\n",
            "creamier\n",
            "creamiest\n",
            "creepier\n",
            "creepiest\n",
            "crispier\n",
            "crispiest\n",
            "crumbier\n",
            "crumbiest\n",
            "crumblier\n",
            "crumbliest\n",
            "crummier\n",
            "crummiest\n",
            "crustier\n",
            "crustiest\n",
            "curlier\n",
            "curliest\n",
            "customer\n",
            "cuter\n",
            "daffier\n",
            "daffiest\n",
            "daintier\n",
            "daintiest\n",
            "dandier\n",
            "dandiest\n",
            "deadlier\n",
            "deadliest\n",
            "dealer\n",
            "deserter\n",
            "dewier\n",
            "dewiest\n",
            "dicier\n",
            "diciest\n",
            "dimer\n",
            "dimmer\n",
            "dimmest\n",
            "dingier\n",
            "dingiest\n",
            "dinkier\n",
            "dinkiest\n",
            "dippier\n",
            "dippiest\n",
            "dirtier\n",
            "dirtiest\n",
            "dishier\n",
            "dishiest\n",
            "dizzier\n",
            "dizziest\n",
            "dodgier\n",
            "dodgiest\n",
            "dopier\n",
            "dopiest\n",
            "dottier\n",
            "dottiest\n",
            "doughier\n",
            "doughiest\n",
            "doughtier\n",
            "doughtiest\n",
            "dowdier\n",
            "dowdiest\n",
            "dowier\n",
            "dowiest\n",
            "downer\n",
            "downier\n",
            "downiest\n",
            "dozier\n",
            "doziest\n",
            "drabber\n",
            "drabbest\n",
            "draftier\n",
            "draftiest\n",
            "draggier\n",
            "draggiest\n",
            "draughtier\n",
            "draughtiest\n",
            "dreamier\n",
            "dreamiest\n",
            "drearier\n",
            "dreariest\n",
            "dreggier\n",
            "dreggiest\n",
            "dresser\n",
            "dressier\n",
            "dressiest\n",
            "drier\n",
            "driest\n",
            "drippier\n",
            "drippiest\n",
            "drowsier\n",
            "drowsiest\n",
            "dryer\n",
            "dryest\n",
            "dumpier\n",
            "dumpiest\n",
            "dunner\n",
            "dunnest\n",
            "duskier\n",
            "duskiest\n",
            "dustier\n",
            "dustiest\n",
            "earlier\n",
            "earliest\n",
            "earthier\n",
            "earthiest\n",
            "earthlier\n",
            "earthliest\n",
            "easier\n",
            "easiest\n",
            "easter\n",
            "eastsider\n",
            "edger\n",
            "edgier\n",
            "edgiest\n",
            "eerier\n",
            "eeriest\n",
            "emptier\n",
            "emptiest\n",
            "faker\n",
            "fancier\n",
            "fanciest\n",
            "fatter\n",
            "fattest\n",
            "fattier\n",
            "fattiest\n",
            "faultier\n",
            "faultiest\n",
            "feistier\n",
            "feistiest\n",
            "feller\n",
            "fiddlier\n",
            "fiddliest\n",
            "filmier\n",
            "filmiest\n",
            "filthier\n",
            "filthiest\n",
            "finnier\n",
            "finniest\n",
            "first-rater\n",
            "first-stringer\n",
            "fishier\n",
            "fishiest\n",
            "fitter\n",
            "fittest\n",
            "flabbier\n",
            "flabbiest\n",
            "flaggier\n",
            "flaggiest\n",
            "flakier\n",
            "flakiest\n",
            "flasher\n",
            "flashier\n",
            "flashiest\n",
            "flatter\n",
            "flattest\n",
            "flauntier\n",
            "flauntiest\n",
            "fledgier\n",
            "fledgiest\n",
            "fleecier\n",
            "fleeciest\n",
            "fleshier\n",
            "fleshiest\n",
            "fleshlier\n",
            "fleshliest\n",
            "flightier\n",
            "flightiest\n",
            "flimsier\n",
            "flimsiest\n",
            "flintier\n",
            "flintiest\n",
            "floatier\n",
            "floatiest\n",
            "floppier\n",
            "floppiest\n",
            "flossier\n",
            "flossiest\n",
            "fluffier\n",
            "fluffiest\n",
            "flukier\n",
            "flukiest\n",
            "foamier\n",
            "foamiest\n",
            "foggier\n",
            "foggiest\n",
            "folder\n",
            "folksier\n",
            "folksiest\n",
            "foolhardier\n",
            "foolhardiest\n",
            "fore-and-after\n",
            "foreigner\n",
            "forest\n",
            "founder\n",
            "foxier\n",
            "foxiest\n",
            "fratchier\n",
            "fratchiest\n",
            "freakier\n",
            "freakiest\n",
            "freer\n",
            "freest\n",
            "frenchier\n",
            "frenchiest\n",
            "friendlier\n",
            "friendliest\n",
            "friskier\n",
            "friskiest\n",
            "frizzier\n",
            "frizziest\n",
            "frizzlier\n",
            "frizzliest\n",
            "frostier\n",
            "frostiest\n",
            "frouzier\n",
            "frouziest\n",
            "frowsier\n",
            "frowsiest\n",
            "frowzier\n",
            "frowziest\n",
            "fruitier\n",
            "fruitiest\n",
            "funkier\n",
            "funkiest\n",
            "funnier\n",
            "funniest\n",
            "furrier\n",
            "furriest\n",
            "fussier\n",
            "fussiest\n",
            "fustier\n",
            "fustiest\n",
            "fuzzier\n",
            "fuzziest\n",
            "gabbier\n",
            "gabbiest\n",
            "gamier\n",
            "gamiest\n",
            "gammier\n",
            "gammiest\n",
            "gassier\n",
            "gassiest\n",
            "gaudier\n",
            "gaudiest\n",
            "gauzier\n",
            "gauziest\n",
            "gawkier\n",
            "gawkiest\n",
            "ghastlier\n",
            "ghastliest\n",
            "ghostlier\n",
            "ghostliest\n",
            "giddier\n",
            "giddiest\n",
            "gladder\n",
            "gladdest\n",
            "glassier\n",
            "glassiest\n",
            "glibber\n",
            "glibbest\n",
            "gloomier\n",
            "gloomiest\n",
            "glossier\n",
            "glossiest\n",
            "glummer\n",
            "glummest\n",
            "godlier\n",
            "godliest\n",
            "goer\n",
            "goner\n",
            "goodlier\n",
            "goodliest\n",
            "goofier\n",
            "goofiest\n",
            "gooier\n",
            "gooiest\n",
            "goosier\n",
            "goosiest\n",
            "gorier\n",
            "goriest\n",
            "gradelier\n",
            "gradeliest\n",
            "grader\n",
            "grainier\n",
            "grainiest\n",
            "grassier\n",
            "grassiest\n",
            "greasier\n",
            "greasiest\n",
            "greedier\n",
            "greediest\n",
            "grimmer\n",
            "grimmest\n",
            "grislier\n",
            "grisliest\n",
            "grittier\n",
            "grittiest\n",
            "grizzlier\n",
            "grizzliest\n",
            "groggier\n",
            "groggiest\n",
            "groovier\n",
            "grooviest\n",
            "grottier\n",
            "grottiest\n",
            "grounder\n",
            "grouper\n",
            "groutier\n",
            "groutiest\n",
            "grubbier\n",
            "grubbiest\n",
            "grumpier\n",
            "grumpiest\n",
            "guest\n",
            "guiltier\n",
            "guiltiest\n",
            "gummier\n",
            "gummiest\n",
            "gushier\n",
            "gushiest\n",
            "gustier\n",
            "gustiest\n",
            "gutsier\n",
            "gutsiest\n",
            "hairier\n",
            "hairiest\n",
            "halfways\n",
            "halter\n",
            "hammier\n",
            "hammiest\n",
            "handier\n",
            "handiest\n",
            "happier\n",
            "happiest\n",
            "hardier\n",
            "hardiest\n",
            "hastier\n",
            "hastiest\n",
            "haughtier\n",
            "haughtiest\n",
            "hazier\n",
            "haziest\n",
            "header\n",
            "headier\n",
            "headiest\n",
            "healthier\n",
            "healthiest\n",
            "heartier\n",
            "heartiest\n",
            "heavier\n",
            "heaviest\n",
            "heftier\n",
            "heftiest\n",
            "hepper\n",
            "heppest\n",
            "herbier\n",
            "herbiest\n",
            "hinder\n",
            "hipper\n",
            "hippest\n",
            "hippier\n",
            "hippiest\n",
            "hoarier\n",
            "hoariest\n",
            "holier\n",
            "holiest\n",
            "homelier\n",
            "homeliest\n",
            "homer\n",
            "homier\n",
            "homiest\n",
            "hornier\n",
            "horniest\n",
            "horsier\n",
            "horsiest\n",
            "hotter\n",
            "hottest\n",
            "humpier\n",
            "humpiest\n",
            "hunger\n",
            "hungrier\n",
            "hungriest\n",
            "huskier\n",
            "huskiest\n",
            "icier\n",
            "iciest\n",
            "inkier\n",
            "inkiest\n",
            "insider\n",
            "interest\n",
            "jaggier\n",
            "jaggiest\n",
            "jammier\n",
            "jammiest\n",
            "jauntier\n",
            "jauntiest\n",
            "jazzier\n",
            "jazziest\n",
            "jerkier\n",
            "jerkiest\n",
            "jointer\n",
            "jollier\n",
            "jolliest\n",
            "juicier\n",
            "juiciest\n",
            "jumpier\n",
            "jumpiest\n",
            "kindlier\n",
            "kindliest\n",
            "kinkier\n",
            "kinkiest\n",
            "knottier\n",
            "knottiest\n",
            "knurlier\n",
            "knurliest\n",
            "kookier\n",
            "kookiest\n",
            "lacier\n",
            "laciest\n",
            "lairier\n",
            "lairiest\n",
            "lakier\n",
            "lakiest\n",
            "lander\n",
            "lankier\n",
            "lankiest\n",
            "lathier\n",
            "lathiest\n",
            "layer\n",
            "lazier\n",
            "laziest\n",
            "leafier\n",
            "leafiest\n",
            "leakier\n",
            "leakiest\n",
            "learier\n",
            "leariest\n",
            "leer\n",
            "leerier\n",
            "leeriest\n",
            "left-hander\n",
            "left-winger\n",
            "leggier\n",
            "leggiest\n",
            "lengthier\n",
            "lengthiest\n",
            "ler\n",
            "leveler\n",
            "limier\n",
            "limiest\n",
            "lippier\n",
            "lippiest\n",
            "liter\n",
            "livelier\n",
            "liveliest\n",
            "liver\n",
            "loather\n",
            "loftier\n",
            "loftiest\n",
            "logier\n",
            "logiest\n",
            "lonelier\n",
            "loneliest\n",
            "loner\n",
            "loonier\n",
            "looniest\n",
            "loopier\n",
            "loopiest\n",
            "lordlier\n",
            "lordliest\n",
            "lousier\n",
            "lousiest\n",
            "lovelier\n",
            "loveliest\n",
            "lowlander\n",
            "lowlier\n",
            "lowliest\n",
            "luckier\n",
            "luckiest\n",
            "lumpier\n",
            "lumpiest\n",
            "lunier\n",
            "luniest\n",
            "lustier\n",
            "lustiest\n",
            "madder\n",
            "maddest\n",
            "mainer\n",
            "maligner\n",
            "maltier\n",
            "maltiest\n",
            "mangier\n",
            "mangiest\n",
            "mankier\n",
            "mankiest\n",
            "manlier\n",
            "manliest\n",
            "mariner\n",
            "marshier\n",
            "marshiest\n",
            "massier\n",
            "massiest\n",
            "matter\n",
            "maungier\n",
            "maungiest\n",
            "mazier\n",
            "maziest\n",
            "mealier\n",
            "mealiest\n",
            "measlier\n",
            "measliest\n",
            "meatier\n",
            "meatiest\n",
            "meeter\n",
            "merrier\n",
            "merriest\n",
            "messier\n",
            "messiest\n",
            "miffier\n",
            "miffiest\n",
            "mightier\n",
            "mightiest\n",
            "milcher\n",
            "milker\n",
            "milkier\n",
            "milkiest\n",
            "mingier\n",
            "mingiest\n",
            "minter\n",
            "mirkier\n",
            "mirkiest\n",
            "miser\n",
            "mistier\n",
            "mistiest\n",
            "mocker\n",
            "modeler\n",
            "modest\n",
            "moldier\n",
            "moldiest\n",
            "moodier\n",
            "moodiest\n",
            "moonier\n",
            "mooniest\n",
            "mothier\n",
            "mothiest\n",
            "mouldier\n",
            "mouldiest\n",
            "mousier\n",
            "mousiest\n",
            "mouthier\n",
            "mouthiest\n",
            "muckier\n",
            "muckiest\n",
            "muddier\n",
            "muddiest\n",
            "muggier\n",
            "muggiest\n",
            "multiplexer\n",
            "murkier\n",
            "murkiest\n",
            "mushier\n",
            "mushiest\n",
            "muskier\n",
            "muskiest\n",
            "muster\n",
            "mustier\n",
            "mustiest\n",
            "muzzier\n",
            "muzziest\n",
            "nappier\n",
            "nappiest\n",
            "nastier\n",
            "nastiest\n",
            "nattier\n",
            "nattiest\n",
            "naughtier\n",
            "naughtiest\n",
            "needier\n",
            "neediest\n",
            "nervier\n",
            "nerviest\n",
            "newsier\n",
            "newsiest\n",
            "niftier\n",
            "niftiest\n",
            "nippier\n",
            "nippiest\n",
            "nittier\n",
            "nittiest\n",
            "noisier\n",
            "noisiest\n",
            "northeasterner\n",
            "norther\n",
            "northerner\n",
            "nosier\n",
            "nosiest\n",
            "number\n",
            "nuttier\n",
            "nuttiest\n",
            "offer\n",
            "offer\n",
            "oilier\n",
            "oiliest\n",
            "old-timer\n",
            "oliver\n",
            "oozier\n",
            "ooziest\n",
            "opener\n",
            "outsider\n",
            "overcomer\n",
            "overnighter\n",
            "owner\n",
            "pallier\n",
            "palliest\n",
            "palmier\n",
            "palmiest\n",
            "paltrier\n",
            "paltriest\n",
            "pappier\n",
            "pappiest\n",
            "parkier\n",
            "parkiest\n",
            "part-timer\n",
            "passer\n",
            "paster\n",
            "pastier\n",
            "pastiest\n",
            "patchier\n",
            "patchiest\n",
            "pater\n",
            "pawkier\n",
            "pawkiest\n",
            "peachier\n",
            "peachiest\n",
            "pearler\n",
            "pearlier\n",
            "pearliest\n",
            "pedaler\n",
            "peppier\n",
            "peppiest\n",
            "perkier\n",
            "perkiest\n",
            "peskier\n",
            "peskiest\n",
            "peter\n",
            "pettier\n",
            "pettiest\n",
            "phonier\n",
            "phoniest\n",
            "pickier\n",
            "pickiest\n",
            "piggier\n",
            "piggiest\n",
            "pinier\n",
            "piniest\n",
            "pitchier\n",
            "pitchiest\n",
            "pithier\n",
            "pithiest\n",
            "planer\n",
            "plashier\n",
            "plashiest\n",
            "platier\n",
            "platiest\n",
            "player\n",
            "pluckier\n",
            "pluckiest\n",
            "plumber\n",
            "plumier\n",
            "plumiest\n",
            "plummier\n",
            "plummiest\n",
            "podgier\n",
            "podgiest\n",
            "pokier\n",
            "pokiest\n",
            "polisher\n",
            "porkier\n",
            "porkiest\n",
            "porter\n",
            "portlier\n",
            "portliest\n",
            "poster\n",
            "pottier\n",
            "pottiest\n",
            "preachier\n",
            "preachiest\n",
            "presenter\n",
            "pretender\n",
            "prettier\n",
            "prettiest\n",
            "pricier\n",
            "priciest\n",
            "pricklier\n",
            "prickliest\n",
            "priestlier\n",
            "priestliest\n",
            "primer\n",
            "primmer\n",
            "primmest\n",
            "princelier\n",
            "princeliest\n",
            "printer\n",
            "prissier\n",
            "prissiest\n",
            "privateer\n",
            "privier\n",
            "priviest\n",
            "prompter\n",
            "prosier\n",
            "prosiest\n",
            "pudgier\n",
            "pudgiest\n",
            "puffer\n",
            "puffier\n",
            "puffiest\n",
            "pulpier\n",
            "pulpiest\n",
            "punchier\n",
            "punchiest\n",
            "punier\n",
            "puniest\n",
            "pushier\n",
            "pushiest\n",
            "pussier\n",
            "pussiest\n",
            "quaggier\n",
            "quaggiest\n",
            "quakier\n",
            "quakiest\n",
            "queasier\n",
            "queasiest\n",
            "queenlier\n",
            "queenliest\n",
            "racier\n",
            "raciest\n",
            "rainier\n",
            "rainiest\n",
            "randier\n",
            "randiest\n",
            "rangier\n",
            "rangiest\n",
            "ranker\n",
            "rattier\n",
            "rattiest\n",
            "rattlier\n",
            "rattliest\n",
            "raunchier\n",
            "raunchiest\n",
            "readier\n",
            "readiest\n",
            "recorder\n",
            "redder\n",
            "reddest\n",
            "reedier\n",
            "reediest\n",
            "renter\n",
            "retailer\n",
            "right-hander\n",
            "right-winger\n",
            "rimier\n",
            "rimiest\n",
            "riskier\n",
            "riskiest\n",
            "ritzier\n",
            "ritziest\n",
            "roaster\n",
            "rockier\n",
            "rockiest\n",
            "roilier\n",
            "roiliest\n",
            "rookier\n",
            "rookiest\n",
            "roomier\n",
            "roomiest\n",
            "ropier\n",
            "ropiest\n",
            "rosier\n",
            "rosiest\n",
            "rowdier\n",
            "rowdiest\n",
            "ruddier\n",
            "ruddiest\n",
            "runnier\n",
            "runniest\n",
            "rusher\n",
            "rushier\n",
            "rushiest\n",
            "rustier\n",
            "rustiest\n",
            "ruttier\n",
            "ruttiest\n",
            "sadder\n",
            "saddest\n",
            "salter\n",
            "saltier\n",
            "saltiest\n",
            "sampler\n",
            "sandier\n",
            "sandiest\n",
            "sappier\n",
            "sappiest\n",
            "sassier\n",
            "sassiest\n",
            "saucier\n",
            "sauciest\n",
            "savvier\n",
            "savviest\n",
            "scabbier\n",
            "scabbiest\n",
            "scalier\n",
            "scaliest\n",
            "scantier\n",
            "scantiest\n",
            "scarier\n",
            "scariest\n",
            "scraggier\n",
            "scraggiest\n",
            "scragglier\n",
            "scraggliest\n",
            "scraper\n",
            "scrappier\n",
            "scrappiest\n",
            "scrawnier\n",
            "scrawniest\n",
            "screwier\n",
            "screwiest\n",
            "scrubbier\n",
            "scrubbiest\n",
            "scruffier\n",
            "scruffiest\n",
            "scungier\n",
            "scungiest\n",
            "scurvier\n",
            "scurviest\n",
            "seamier\n",
            "seamiest\n",
            "second-rater\n",
            "seconder\n",
            "seedier\n",
            "seediest\n",
            "seemlier\n",
            "seemliest\n",
            "serer\n",
            "sexier\n",
            "sexiest\n",
            "shabbier\n",
            "shabbiest\n",
            "shadier\n",
            "shadiest\n",
            "shaggier\n",
            "shaggiest\n",
            "shakier\n",
            "shakiest\n",
            "shapelier\n",
            "shapeliest\n",
            "shier\n",
            "shiest\n",
            "shiftier\n",
            "shiftiest\n",
            "shinier\n",
            "shiniest\n",
            "shirtier\n",
            "shirtiest\n",
            "shoddier\n",
            "shoddiest\n",
            "showier\n",
            "showiest\n",
            "shrubbier\n",
            "shrubbiest\n",
            "shyer\n",
            "shyest\n",
            "sicklier\n",
            "sickliest\n",
            "sightlier\n",
            "sightliest\n",
            "signaler\n",
            "signer\n",
            "silkier\n",
            "silkiest\n",
            "sillier\n",
            "silliest\n",
            "sketchier\n",
            "sketchiest\n",
            "skewer\n",
            "skimpier\n",
            "skimpiest\n",
            "skinnier\n",
            "skinniest\n",
            "slaphappier\n",
            "slaphappiest\n",
            "slatier\n",
            "slatiest\n",
            "slaver\n",
            "sleazier\n",
            "sleaziest\n",
            "sleepier\n",
            "sleepiest\n",
            "slier\n",
            "sliest\n",
            "slimier\n",
            "slimiest\n",
            "slimmer\n",
            "slimmest\n",
            "slimsier\n",
            "slimsiest\n",
            "slinkier\n",
            "slinkiest\n",
            "slippier\n",
            "slippiest\n",
            "sloppier\n",
            "sloppiest\n",
            "slyer\n",
            "slyest\n",
            "smarmier\n",
            "smarmiest\n",
            "smellier\n",
            "smelliest\n",
            "smokier\n",
            "smokiest\n",
            "smugger\n",
            "smuggest\n",
            "snakier\n",
            "snakiest\n",
            "snappier\n",
            "snappiest\n",
            "snatchier\n",
            "snatchiest\n",
            "snazzier\n",
            "snazziest\n",
            "sneaker\n",
            "sniffier\n",
            "sniffiest\n",
            "snootier\n",
            "snootiest\n",
            "snottier\n",
            "snottiest\n",
            "snowier\n",
            "snowiest\n",
            "snuffer\n",
            "snuffier\n",
            "snuffiest\n",
            "snugger\n",
            "snuggest\n",
            "soapier\n",
            "soapiest\n",
            "soggier\n",
            "soggiest\n",
            "solder\n",
            "sonsier\n",
            "sonsiest\n",
            "sootier\n",
            "sootiest\n",
            "soppier\n",
            "soppiest\n",
            "sorrier\n",
            "sorriest\n",
            "soupier\n",
            "soupiest\n",
            "souther\n",
            "southerner\n",
            "speedier\n",
            "speediest\n",
            "spicier\n",
            "spiciest\n",
            "spiffier\n",
            "spiffiest\n",
            "spikier\n",
            "spikiest\n",
            "spindlier\n",
            "spindliest\n",
            "spinier\n",
            "spiniest\n",
            "splashier\n",
            "splashiest\n",
            "spongier\n",
            "spongiest\n",
            "spookier\n",
            "spookiest\n",
            "spoonier\n",
            "spooniest\n",
            "sportier\n",
            "sportiest\n",
            "spottier\n",
            "spottiest\n",
            "spreader\n",
            "sprier\n",
            "spriest\n",
            "sprightlier\n",
            "sprightliest\n",
            "springer\n",
            "springier\n",
            "springiest\n",
            "squashier\n",
            "squashiest\n",
            "squatter\n",
            "squattest\n",
            "squattier\n",
            "squattiest\n",
            "squiffier\n",
            "squiffiest\n",
            "stagier\n",
            "stagiest\n",
            "stalkier\n",
            "stalkiest\n",
            "stapler\n",
            "starchier\n",
            "starchiest\n",
            "starer\n",
            "starest\n",
            "starrier\n",
            "starriest\n",
            "statelier\n",
            "stateliest\n",
            "steadier\n",
            "steadiest\n",
            "stealthier\n",
            "stealthiest\n",
            "steamier\n",
            "steamiest\n",
            "stingier\n",
            "stingiest\n",
            "stiper\n",
            "stocker\n",
            "stockier\n",
            "stockiest\n",
            "stodgier\n",
            "stodgiest\n",
            "stonier\n",
            "stoniest\n",
            "stormier\n",
            "stormiest\n",
            "streakier\n",
            "streakiest\n",
            "streamier\n",
            "streamiest\n",
            "stretcher\n",
            "stretchier\n",
            "stretchiest\n",
            "stringier\n",
            "stringiest\n",
            "stripier\n",
            "stripiest\n",
            "stronger\n",
            "strongest\n",
            "stroppier\n",
            "stroppiest\n",
            "stuffier\n",
            "stuffiest\n",
            "stumpier\n",
            "stumpiest\n",
            "sturdier\n",
            "sturdiest\n",
            "submariner\n",
            "sulkier\n",
            "sulkiest\n",
            "sultrier\n",
            "sultriest\n",
            "sunnier\n",
            "sunniest\n",
            "surlier\n",
            "surliest\n",
            "swagger\n",
            "swankier\n",
            "swankiest\n",
            "swarthier\n",
            "swarthiest\n",
            "sweatier\n",
            "sweatiest\n",
            "tackier\n",
            "tackiest\n",
            "talkier\n",
            "talkiest\n",
            "tangier\n",
            "tangiest\n",
            "tanner\n",
            "tannest\n",
            "tardier\n",
            "tardiest\n",
            "tastier\n",
            "tastiest\n",
            "tattier\n",
            "tattiest\n",
            "tawdrier\n",
            "tawdriest\n",
            "techier\n",
            "techiest\n",
            "teenager\n",
            "teenier\n",
            "teeniest\n",
            "teetotaler\n",
            "tester\n",
            "testier\n",
            "testiest\n",
            "tetchier\n",
            "tetchiest\n",
            "thinner\n",
            "thinnest\n",
            "third-rater\n",
            "thirstier\n",
            "thirstiest\n",
            "thornier\n",
            "thorniest\n",
            "threadier\n",
            "threadiest\n",
            "thriftier\n",
            "thriftiest\n",
            "throatier\n",
            "throatiest\n",
            "tidier\n",
            "tidiest\n",
            "timelier\n",
            "timeliest\n",
            "tinier\n",
            "tiniest\n",
            "tinnier\n",
            "tinniest\n",
            "tipsier\n",
            "tipsiest\n",
            "tonier\n",
            "toniest\n",
            "toothier\n",
            "toothiest\n",
            "toper\n",
            "touchier\n",
            "touchiest\n",
            "trader\n",
            "trashier\n",
            "trashiest\n",
            "trendier\n",
            "trendiest\n",
            "trickier\n",
            "trickiest\n",
            "tricksier\n",
            "tricksiest\n",
            "trimer\n",
            "trimmer\n",
            "trimmest\n",
            "truer\n",
            "truest\n",
            "trustier\n",
            "trustiest\n",
            "tubbier\n",
            "tubbiest\n",
            "turfier\n",
            "turfiest\n",
            "tweedier\n",
            "tweediest\n",
            "twiggier\n",
            "twiggiest\n",
            "uglier\n",
            "ugliest\n",
            "unfriendlier\n",
            "unfriendliest\n",
            "ungainlier\n",
            "ungainliest\n",
            "ungodlier\n",
            "ungodliest\n",
            "unhappier\n",
            "unhappiest\n",
            "unhealthier\n",
            "unhealthiest\n",
            "unholier\n",
            "unholiest\n",
            "unrulier\n",
            "unruliest\n",
            "untidier\n",
            "untidiest\n",
            "vastier\n",
            "vastiest\n",
            "vest\n",
            "viewier\n",
            "viewiest\n",
            "wackier\n",
            "wackiest\n",
            "wanner\n",
            "wannest\n",
            "warier\n",
            "wariest\n",
            "washier\n",
            "washiest\n",
            "waster\n",
            "wavier\n",
            "waviest\n",
            "waxier\n",
            "waxiest\n",
            "weaklier\n",
            "weakliest\n",
            "wealthier\n",
            "wealthiest\n",
            "wearier\n",
            "weariest\n",
            "webbier\n",
            "webbiest\n",
            "weedier\n",
            "weediest\n",
            "weenier\n",
            "weeniest\n",
            "weensier\n",
            "weensiest\n",
            "weepier\n",
            "weepiest\n",
            "weightier\n",
            "weightiest\n",
            "welsher\n",
            "wetter\n",
            "wettest\n",
            "whackier\n",
            "whackiest\n",
            "whimsier\n",
            "whimsiest\n",
            "wholesaler\n",
            "wieldier\n",
            "wieldiest\n",
            "wilier\n",
            "wiliest\n",
            "windier\n",
            "windiest\n",
            "winier\n",
            "winiest\n",
            "winterier\n",
            "winteriest\n",
            "wintrier\n",
            "wintriest\n",
            "wirier\n",
            "wiriest\n",
            "wispier\n",
            "wispiest\n",
            "wittier\n",
            "wittiest\n",
            "wonkier\n",
            "wonkiest\n",
            "woodier\n",
            "woodiest\n",
            "woodsier\n",
            "woodsiest\n",
            "woollier\n",
            "woolliest\n",
            "woozier\n",
            "wooziest\n",
            "wordier\n",
            "wordiest\n",
            "worldlier\n",
            "worldliest\n",
            "wormier\n",
            "wormiest\n",
            "worse\n",
            "worst\n",
            "worthier\n",
            "worthiest\n",
            "wrier\n",
            "wriest\n",
            "wryer\n",
            "wryest\n",
            "yarer\n",
            "yarest\n",
            "yeastier\n",
            "yeastiest\n",
            "younger\n",
            "youngest\n",
            "yummier\n",
            "yummiest\n",
            "zanier\n",
            "zaniest\n",
            "zippier\n",
            "zippiest\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorboardX"
      ],
      "metadata": {
        "id": "asPxLctOjCi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorboardX"
      ],
      "metadata": {
        "id": "uo3fZ0CUjAIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359d0e16-eaa8-47c3-b79d-1bc85c1286ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Source Codes"
      ],
      "metadata": {
        "id": "lspwNGu7jLzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Fast_Campus/ExSum/SRC ."
      ],
      "metadata": {
        "id": "V9ksOpSnjEhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8208b213-c2a1-4232-c54d-2933a7c36a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/Fast_Campus/ExSum/SRC': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 Import "
      ],
      "metadata": {
        "id": "GkXfgw6JjPjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import easydict"
      ],
      "metadata": {
        "id": "pRAwyKjJjN3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터\n",
        "\n",
        "\n",
        "###원본 데이터 탐색\n",
        "- 데이터 구성\n",
        "  - 원문 데이터 40만 건 (신문기사 30만 건, 기고문 6만 건, 잡지기사 1만 건, 법원 판결문 3만 건)을 활용하여 각각 추출요약 40만 건, 생성요약 40만 건, 총 80만 건의 요약문 도출\n",
        "  - 원문으로부터 변형 없이 그대로 선택된 3개 문장으로 추출요약문 생성\n",
        "  - 원문의 내용을 바탕으로 재작성된 생성요약문 생성"
      ],
      "metadata": {
        "id": "oyUWdh3CnSei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4aLJuzSjShA",
        "outputId": "a7b5a2cf-3e1c-4f22-cd0d-b670470da042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original_law.json',\n",
              " 'train_original_news.json',\n",
              " 'train_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = filenames[0]\n",
        "filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "with open(filelocation, 'r') as json_file:\n",
        "  data = json.load(json_file) ['documents']"
      ],
      "metadata": {
        "id": "Gq0TJ2fFnzdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmQwzvMgoBS8",
        "outputId": "5e977be2-765d-4e5c-db6e-e0008d372eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '100004',\n",
              " 'category': '일반행정',\n",
              " 'size': 'small',\n",
              " 'char_count': 377,\n",
              " 'publish_date': '19841226',\n",
              " 'title': '부당노동행위구제재심판정취소',\n",
              " 'text': [[{'index': 0,\n",
              "    'sentence': '원고가 소속회사의 노동조합에서 분규가 발생하자 노조활동을 구실로 정상적인 근무를 해태하고,',\n",
              "    'highlight_indices': ''},\n",
              "   {'index': 1, 'sentence': '노조조합장이 사임한 경우,', 'highlight_indices': ''},\n",
              "   {'index': 2,\n",
              "    'sentence': '노동조합규약에 동 조합장의 직무를 대행할 자를 규정해 두고 있음에도 원고 자신이 주동하여 노조자치수습대책위원회를 구성하여 그 위원장으로 피선되어 근무시간중에도 노조활동을 벌여 운수업체인 소속회사의 업무에 지장을 초래하고',\n",
              "    'highlight_indices': '8,9;68,69'},\n",
              "   {'index': 3,\n",
              "    'sentence': '종업원들에게도 나쁜 영향을 끼쳐 소속회사가 취업규칙을 위반하고',\n",
              "    'highlight_indices': ''},\n",
              "   {'index': 4,\n",
              "    'sentence': '고의로 회사업무능률을 저해하였으며 회사업무상의 지휘명령에 위반하였음을 이유로 원고를 징계해고 하였다면,',\n",
              "    'highlight_indices': '0,3'},\n",
              "   {'index': 5,\n",
              "    'sentence': '이는 원고의 노동조합 활동과는 관계없이 회사취업규칙에 의하여 사내질서를 유지하기 위한 사용자 고유의 징계권에 기하여 이루어진 정당한 징계권의 행사로 보아야 한다.',\n",
              "    'highlight_indices': '17,21'}]],\n",
              " 'annotator_id': 3783,\n",
              " 'document_quality_scores': {'readable': 3,\n",
              "  'accurate': 3,\n",
              "  'informative': 3,\n",
              "  'trustworthy': 3},\n",
              " 'extractive': [5, 4, 2],\n",
              " 'abstractive': ['원고가  주동하여 회사업무능률을 저해하고 회사업무상의 지휘명령에 위반하였다면 이에 따른 징계해고는 사내질서를 유지하기 위한 사용자 고유의 정당한 징계권의 행사로 보아야 한다.']}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원본 데이터에서 필요한 값 추출\n",
        "- text와 extractive 추출\n",
        "  - text : 정규식을 이용해 sentence - highlight_indices 사이의 문장 추출한 후 리스트로 저장\n",
        "  - extracive : 3줄 요약에 해당하는 문장 index 3개가 저장된 리스트\n",
        "- 신문기사, 기고문, 법원 판결분 3개로 나누어져 잇는 파일을 하나로 합침\n",
        "  - train, valid 각각에 대해 수행"
      ],
      "metadata": {
        "id": "fZLg_iNCrBEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train 데이터"
      ],
      "metadata": {
        "id": "Bt6iHAncr59u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOkgAtAoEGM",
        "outputId": "4577af8a-8c40-41aa-f0b2-bfe52c97e6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original_law.json',\n",
              " 'train_original_news.json',\n",
              " 'train_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list_dic = []\n",
        "\n",
        "# for file in filenames:\n",
        "#   filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "#   with open(filelocation, 'r') as json_file:\n",
        "#     data = json.load(json_file)['documents']\n",
        "\n",
        "#     for x in tqdm (range(len(data))):\n",
        "#       text = data[x]['text']\n",
        "#       text = str(text).replace('\"', \"'\")\n",
        "\n",
        "#       extractive = data[x]['extractive']\n",
        "#       for index, value in enumerate(extractive):\n",
        "#         if value == None:\n",
        "#           extractive[index] = 0\n",
        "\n",
        "#       p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "#       texts = p.findall(text)\n",
        "\n",
        "#       sentences = []\n",
        "#       for t in texts:\n",
        "#         sentence = t[:-3]\n",
        "#         sentences.append(sentence)\n",
        "\n",
        "#       mydict = {}\n",
        "#       mydict['text'] = sentences\n",
        "#       mydict['extractive'] = extractive\n",
        "#       list_dic.append(mydict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEFekWp5sLEc",
        "outputId": "5264eeb4-593e-4c90-d7d0-eeef109fa95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24329/24329 [00:01<00:00, 16558.77it/s]\n",
            "100%|██████████| 243983/243983 [00:20<00:00, 11715.99it/s]\n",
            "100%|██████████| 56760/56760 [00:07<00:00, 8017.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_dic)"
      ],
      "metadata": {
        "id": "mmg7GrQSu971"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train.json\", 'w') as fh:\n",
        "#   json.dump(list_dic, fh)"
      ],
      "metadata": {
        "id": "evjSqF9jukmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def list_chunk(lst, n):\n",
        "#     return [lst[i:i+n] for i in range(0, len(lst), n)]\n",
        "\n",
        "# data_chunked = list_chunk(data, 32507) ## 전체 데이터를 10개로 분할\n",
        "\n",
        "# for i, d in enumerate(data_chunked):\n",
        "#   with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train.{}.json\".format(i), 'w') as fh:\n",
        "#     json.dump(d, fh)"
      ],
      "metadata": {
        "id": "LrxQT1E4ttHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### val "
      ],
      "metadata": {
        "id": "K5ML9zfXv70C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/valid'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22bBuDvuc-X",
        "outputId": "3e659831-15b8-41c4-b0e5-604d0225d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valid_original_law.json',\n",
              " 'valid_original_news.json',\n",
              " 'valid_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list_dic = []\n",
        "\n",
        "# for file in filenames:\n",
        "#   filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "#   with open(filelocation, 'r') as json_file:\n",
        "#     data = json.load(json_file)['documents']\n",
        "\n",
        "#     for x in tqdm (range(len(data))):\n",
        "#       text = data[x]['text']\n",
        "#       text = str(text).replace('\"', \"'\")\n",
        "\n",
        "#       extractive = data[x]['extractive']\n",
        "#       for index, value in enumerate(extractive):\n",
        "#         if value == None:\n",
        "#           extractive[index] = 0\n",
        "\n",
        "#       p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "#       texts = p.findall(text)\n",
        "\n",
        "#       sentences = []\n",
        "#       for t in texts:\n",
        "#         sentence = t[:-3]\n",
        "#         sentences.append(sentence)\n",
        "\n",
        "#       mydict = {}\n",
        "#       mydict['text'] = sentences\n",
        "#       mydict['extractive'] = extractive\n",
        "#       list_dic.append(mydict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCjZwdn5wSBY",
        "outputId": "d2cf47dd-e125-4e0a-d209-967b97b1b946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3004/3004 [00:00<00:00, 22788.49it/s]\n",
            "100%|██████████| 30122/30122 [00:02<00:00, 10430.85it/s]\n",
            "100%|██████████| 7008/7008 [00:00<00:00, 10395.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/valid.json\", 'w') as fh:\n",
        "#   json.dump(list_dic, fh)"
      ],
      "metadata": {
        "id": "0c6lPYLLwT-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습가능한 형태로 데이터 변환\n",
        "### Tokenizing 후 .json 파일로 저장\n",
        "- Source 및 Target 설정\n",
        "  - Source; 원본 데이터의 'text'에 해당\n",
        "  - Target; 원본 데이터의 'extractive' 리스트의 index에 해당하는 문장을 source에서 추출\n",
        "- Source 및 Target 을 Tokenizing\n",
        "  - Tokenizer; MeCab + BertTokenizer\n",
        "    - 한국어 데이터이므로 MeCab으로 형태소 분석 후 BertTokenizer 사용\n",
        "  - Tokenizing 후 token 단위로 source 및 target 저장"
      ],
      "metadata": {
        "id": "kHaeFzYESibG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "1fvadQTwwe61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train 데이터"
      ],
      "metadata": {
        "id": "WMgT7eFESyfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if 'train' in x and x.endswith('json')]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykscWhbtSxvo",
        "outputId": "4d3e4eb8-3d2e-4374-94da-96a25551a4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.json']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocess(set_name):\n",
        "  with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/{}.json\".format(set_name), 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "    list_dic = []\n",
        "    for x in tqdm(range(len(data))):\n",
        "      text = data[x]['text']\n",
        "      extractive = data[x]['extractive']\n",
        "\n",
        "      sentences = []\n",
        "      for sentence in text:\n",
        "        sentence_morph = ' '.join(mecab.morphs(sentence))\n",
        "        sentences.append(sentence_morph)\n",
        "\n",
        "      extractives = []\n",
        "      for e in extractive:\n",
        "        extractives.append(sentences[e])\n",
        "\n",
        "      src = [i.split(' ') for i in sentences]\n",
        "      tgt = [i.split(' ') for i in extractives]\n",
        "\n",
        "      mydict = {}\n",
        "      mydict['src'] = src\n",
        "      mydict['tgt'] = tgt\n",
        "      list_dic.append(mydict)\n",
        "\n",
        "    jsonfilelocation = '/content/drive/MyDrive/인공지능/추출요약/data/json_data/' + set_name\n",
        "    os.makedirs(jsonfilelocation, exist_ok=True)\n",
        "\n",
        "    temp = []\n",
        "    DATA_PER_FILE = 50\n",
        "\n",
        "    for i,a in enumerate(tqdm(list_dic)):\n",
        "      if (i+1)%DATA_PER_FILE!=0:\n",
        "        temp.append(a)\n",
        "      else:\n",
        "        temp.append(a)\n",
        "        filename = 'korean.'+ set_name + '.' + str(i//DATA_PER_FILE)+'.json'\n",
        "        with open(os.path.join(jsonfilelocation, filename), \"w\", encoding='utf-8') as json_file:\n",
        "          json.dump(temp, json_file, ensure_ascii=False)\n",
        "          temp = []\n",
        "\n",
        "      #마지막에 남은 데이터 있으면 추가로 append\n",
        "      if len(temp) != 0:\n",
        "        filename = 'korean.'+ set_name + '.' + str(i//DATA_PER_FILE + 1)+'.json'\n",
        "        with open(os.path.join(jsonfilelocation, filename), \"w\", encoding='utf-8') as json_file:\n",
        "          json.dump(temp, json_file, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "EAVq7h0HfCfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_preprocess('train')\n",
        "# data_preprocess('valid')"
      ],
      "metadata": {
        "id": "jmrfu8AkfiN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee03cf4-f492-412c-ee42-31ba547da199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 325072/325072 [14:08<00:00, 383.21it/s]\n",
            "100%|██████████| 325072/325072 [1:12:42<00:00, 74.51it/s]\n",
            "100%|██████████| 40134/40134 [01:42<00:00, 392.35it/s]\n",
            "100%|██████████| 40134/40134 [08:44<00:00, 76.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT feature 생성 후 .pt 파일로 저장\n",
        "- format_to_bert 함수 이용\n",
        "- prepro > data_builder.py\n",
        "  - BertData() 클래스에서 tokenizer 설정\n",
        "  - BertTokenizer.from_pretrained('klue/bert-base', strip_accents=False, do_lower_case=False)"
      ],
      "metadata": {
        "id": "Ck0zkvbjedLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from os.path import join as pjoin\n",
        "import sys\n",
        "\n",
        "from multiprocess import Pool\n",
        "sys.path.append('/content/drive/MyDrive/인공지능/추출요약')\n",
        "from SRC.prepro.data_builder import _format_to_bert\n",
        "\n",
        "def format_to_bert(args):\n",
        "    if (args.dataset != ''):\n",
        "        datasets = args.dataset\n",
        "    else:\n",
        "        datasets = ['train', 'valid', 'test']\n",
        "    for corpus_type in datasets:\n",
        "        a_lst = []\n",
        "        for json_f in glob.glob(pjoin(args.raw_path, corpus_type, '*' + corpus_type + '.*.json')):\n",
        "            real_name = json_f.split('/')[-1]\n",
        "            a_lst.append((json_f, args, pjoin(args.save_path, real_name.replace('json', 'bert.pt'))))\n",
        "        # print(a_lst)\n",
        "        pool = Pool(args.n_cpus)\n",
        "        for d in pool.imap(_format_to_bert, a_lst):\n",
        "            pass\n",
        "\n",
        "        pool.close()\n",
        "        pool.join()"
      ],
      "metadata": {
        "id": "60Aczq2geW08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'train'\n",
        "\n",
        "bertfilelocation = '/content/drive/MyDrive/인공지능/추출요약/data/bert_data/' + set_name\n",
        "os.makedirs(bertfilelocation, exist_ok=True)\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "  \"dataset\": [set_name], \n",
        "  \"raw_path\": \"/content/drive/MyDrive/인공지능/추출요약/data/json_data/\",\n",
        "  \"save_path\": bertfilelocation,\n",
        "  \"n_cpus\":4,\n",
        "  \"oracle_mode\": \"greedy\",\n",
        "  \"min_src_ntokens\": 5,\n",
        "  \"max_src_ntokens\": 200,\n",
        "  \"min_nsents\": 3,\n",
        "  \"max_nsents\": 100,\n",
        "}) \n",
        "\n",
        "format_to_bert(args)"
      ],
      "metadata": {
        "id": "GuIuOhireIoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'valid'\n",
        "\n",
        "bertfilelocation = '/content/drive/MyDrive/인공지능/추출요약/data/bert_data/' + set_name\n",
        "os.makedirs(bertfilelocation, exist_ok=True)\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "  \"dataset\": [set_name], \n",
        "  \"raw_path\": \"/content/drive/MyDrive/인공지능/추출요약/data/json_data/\",\n",
        "  \"save_path\": bertfilelocation,\n",
        "  \"n_cpus\":4,\n",
        "  \"oracle_mode\": \"greedy\",\n",
        "  \"min_src_ntokens\": 5,\n",
        "  \"max_src_ntokens\": 200,\n",
        "  \"min_nsents\": 3,\n",
        "  \"max_nsents\": 100,\n",
        "})\n",
        "\n",
        "format_to_bert(args)"
      ],
      "metadata": {
        "id": "xwU6Jd8xesUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "### 1. 사전 학습 모델 로딩\n",
        "- models > model_builder.py\n",
        "  - `Bert()` 클래스에서 model 설정\n",
        "  - `BertModel.from_pretrained('klue/bert-base')`\n",
        "- train.py\n",
        "  - `validate`와 `test` 함수에서 config 설정\n",
        "  - `BertConfig.from_pretrained('klue/bert-base')`\n",
        "\n",
        "### 2. 인코더 설정\n",
        "- models > encoder.py\n",
        "  - `Classifier()` 클래스\n",
        "  - `TransformerInterEncoder()` 클래스\n",
        "  - `RNNEncoder()` 클래스\n",
        "- models > model_builder.py\n",
        "  - `Summarizer()` 클래스에서 encoder 설정"
      ],
      "metadata": {
        "id": "8kYR6o2vY_Hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "### 1. 학습 loss 함수 설정\n",
        "- models > trainer.py\n",
        "  - `__init__` 함수에서 loss 설정\n",
        "  - `torch.nn.BCELoss(reduction='none')`\n",
        "\n",
        "### 2. 하이퍼파라미터 설정\n",
        "- 경로 관련 하이퍼파라미터\n",
        "  - model_path (Path): Fine-tuning한 모델이 저장되는 경로\n",
        "  - result_path (Path): 평가 시 추론 결과(candidate)와 정답(gold)이 저장되는 경로\n",
        "  - temp_dir (Path): 평가 시 ROUGE SCORE 결과가 저장되는 경로\n",
        "  - log_file (Path): 로그 파일이 저장되는 경로\n",
        "  - train_from (Path): 학습하고자 하는 체크포인트(pt)가 있을 경우 설정하는 경로\n",
        "  - bert_data_path (Path): 학습에 사용할 Bert Data(.pt)를 설정하는 경로\n",
        "\n",
        "- 모델 관련 하이퍼파라미터\n",
        "  - batch_size (int): A Batch Size (default=1000)\n",
        "  - use_interval (bool): 학습 시 문서 내에서 여러 문장을 구별하기 위해 Interval Segment Embeddings를 사용하는 지의 여부 (default=True)\n",
        "  - hidden_size (int): Transformer Hidden Size (default=128)\n",
        "  - ff_size (int): Feed-forward Filter Size (default=2048)\n",
        "  - heads (int): Transformer Head 개수 (default=8)\n",
        "  - inter_layers (int): Transformer Inter Layer 개수 (default=2)\n",
        "  - rnn_size (int): Encoder RNN RNN Size(default=512)\n",
        "  - train_steps(int): 학습할 Step 수\n",
        "\n",
        "- Optimizer 관련 하이퍼파라미터\n",
        "  - param_init (float): (default=0)\n",
        "  - param_init_glorot (bool): (default=True)\n",
        "  - dropout (float): Dropout (default=0.1)\n",
        "  - optim (str): Optimizer (default='adam')\n",
        "  - lr (float): Learning Rate (default=2e-3)\n",
        "  - beta1 (float): Adam Optimizer 관련 Hyper Parameter (default= 0.9)\n",
        "  - beta2 (float): Adam Optimizer 관련 Hyper Parameter (default=0.999)\n",
        "  - decay_method (str): Weight Decay (default='noam')\n",
        "  - warmup_steps (int): Warm-up Steps (default=6000)\n",
        "  - max_grad_norm (float): Max Gradient Noam (default=0)\n",
        "\n",
        "- 모델 저장 관련 하이퍼파라미터\n",
        "  - save_checkpoint steps (int): 모델 저장 주기\n",
        "\n",
        "- Multi-GPU 관련 하이퍼파라미터\n",
        "  - world_size (int): GPU 개수\n",
        "  - visible_gpus (str): GPU 번호\n",
        "  - gpu_ranks (str): GPU 번호\n",
        "  - seed (int): (default=666)\n",
        "\n",
        "- 기타 하이퍼파라미터\n",
        "  - accum_count (int): (default=2)\n",
        "  - report_every (int): (default=50)\n",
        "  - recall_eval (bool): (default=false)\n",
        "  - report_rouge (bool): (default=false)\n",
        "  - block_trigram (bool): (default=true)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0Jw9lw6vZKIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Multi-GPU 설정\n",
        "- train.py\n",
        "  - `multi_main` 과 `run` 함수 참조\n",
        "  - multiprocessing 중 spawn 사용\n",
        "\n",
        "```\n",
        "if(args.world_size>1):\n",
        "  multi_main(args)\n",
        "```\n",
        "- distributed.py\n",
        "  - `multi_init` 함수 참조\n",
        "  - 분산학습 사용\n",
        "- Colab 은 Multi-GPU를 지원하지 않으므로, 개인 장비에서 가능하다면 실행 추천\n"
      ],
      "metadata": {
        "id": "GLi08adjZT9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. ROUGE 설정\n",
        "- models > trainer.py\n",
        "  - `Trainer()` 클래스의 `test` 함수 참조\n",
        "- others > utils.py\n",
        "  - `test_rouge`, `rouge_results_to_str` 함수 사용"
      ],
      "metadata": {
        "id": "eIVd5emBZXPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 최종 학습 코드\n",
        "- train.py에서 mode를 train으로 선택"
      ],
      "metadata": {
        "id": "oqEZaXzhYLOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "j0KTYK5MuMK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a45904-48a9-46f3-be30-9fc0d9bd779f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 16 12:49:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier - 논문에는 5만 step"
      ],
      "metadata": {
        "id": "ihb_9J30Ykqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = '/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "!python /content/drive/MyDrive/인공지능/추출요약/SRC/train.py \\\n",
        "    -mode train \\\n",
        "    -encoder classifier \\\n",
        "    -dropout 0.1 \\\n",
        "    -bert_data_path /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean \\\n",
        "    -model_path /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier \\\n",
        "    -lr 2e-3 \\\n",
        "    -visible_gpus 0 \\\n",
        "    -gpu_ranks 0 \\\n",
        "    -world_size 1 \\\n",
        "    -report_every 1000\\\n",
        "    -save_checkpoint_steps 100 \\\n",
        "    -batch_size 1000 \\\n",
        "    -decay_method noam \\\n",
        "    -train_steps 1000 \\\n",
        "    -accum_count 2 \\\n",
        "    -log_file /content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_classifier.txt \\\n",
        "    -use_interval true \\\n",
        "    -warmup_steps 200\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZN5OL58YjnG",
        "outputId": "843abda9-8412-4399-f82d-77c22ab564eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-16 12:50:45.214298: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 12:50:45.214389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 12:50:45.214405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[2023-02-16 12:50:47,241 INFO] Device ID 0\n",
            "[2023-02-16 12:50:47,242 INFO] Device cuda\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-02-16 12:50:51,137 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Classifier(\n",
            "    (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2023-02-16 12:50:51,177 INFO] * number of parameters: 110618113\n",
            "[2023-02-16 12:50:51,177 INFO] Start training...\n",
            "[2023-02-16 12:50:51,311 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1061.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:50:56,676 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4507.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:50:58,916 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5969.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:01,499 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3086.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:03,586 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4782.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:05,239 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_100.pt\n",
            "[2023-02-16 12:51:08,358 INFO] Training Loss 3.081251\n",
            "[2023-02-16 12:51:08,956 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1399.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:11,145 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4626.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:13,418 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1833.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:15,659 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1130.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:18,089 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4328.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:19,678 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_200.pt\n",
            "[2023-02-16 12:51:22,945 INFO] Training Loss 2.618893\n",
            "[2023-02-16 12:51:23,847 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5416.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:26,823 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.839.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:29,360 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.752.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:31,461 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4215.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:33,872 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.231.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:35,227 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_300.pt\n",
            "[2023-02-16 12:51:38,318 INFO] Training Loss 2.393829\n",
            "[2023-02-16 12:51:38,913 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2574.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:41,343 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6223.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:43,992 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5560.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:46,664 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3663.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:49,187 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3623.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:49,904 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_400.pt\n",
            "[2023-02-16 12:51:53,084 INFO] Training Loss 2.205525\n",
            "[2023-02-16 12:51:54,843 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1651.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:57,292 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2533.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:51:59,704 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4147.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:01,930 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2617.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:04,120 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_500.pt\n",
            "[2023-02-16 12:52:07,184 INFO] Training Loss 2.117506\n",
            "[2023-02-16 12:52:07,473 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4177.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:09,682 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6313.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:12,138 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5009.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:14,736 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6444.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:17,562 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6045.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:19,032 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_600.pt\n",
            "[2023-02-16 12:52:22,121 INFO] Training Loss 2.030086\n",
            "[2023-02-16 12:52:23,545 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4785.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:25,959 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3520.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:28,218 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5979.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:31,106 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1132.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:33,474 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6491.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:33,945 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_700.pt\n",
            "[2023-02-16 12:52:37,062 INFO] Training Loss 1.958028\n",
            "[2023-02-16 12:52:39,467 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3266.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:41,820 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5664.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:44,547 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1162.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:46,992 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5334.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:48,443 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_800.pt\n",
            "[2023-02-16 12:52:51,679 INFO] Training Loss 1.891127\n",
            "[2023-02-16 12:52:52,550 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.608.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:54,881 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4083.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:57,320 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.187.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:52:59,236 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3867.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:01,459 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.743.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:03,427 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_900.pt\n",
            "[2023-02-16 12:53:06,686 INFO] Training Loss 1.854558\n",
            "[2023-02-16 12:53:07,494 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1584.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:09,753 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1090.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:12,114 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1662.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:14,523 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4840.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:16,810 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6013.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:53:18,094 INFO] Step 1000/ 1000; xent: 1.83; lr: 0.0000632;  32 docs/s;    147 sec\n",
            "[2023-02-16 12:53:18,098 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_1000.pt\n",
            "[2023-02-16 12:53:21,188 INFO] Training Loss 0.000000\n",
            "[2023-02-16 12:53:21,343 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5962.bert.pt, number of examples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5-2 RNN"
      ],
      "metadata": {
        "id": "lABM2F1-SmlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = '/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "!python /content/drive/MyDrive/인공지능/추출요약/SRC/train.py \\\n",
        "  -mode train \\\n",
        "  -encoder rnn \\\n",
        "  -dropout 0.1 \\\n",
        "  -bert_data_path /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean \\\n",
        "  -model_path /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn \\\n",
        "  -lr 2e-3 \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -report_every 1000\\\n",
        "  -save_checkpoint_steps 100 \\\n",
        "  -batch_size 1000 \\\n",
        "  -decay_method noam \\\n",
        "  -train_steps 1000 \\\n",
        "  -accum_count 2 \\\n",
        "  -log_file /content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_rnn.txt \\\n",
        "  -use_interval true \\\n",
        "  -warmup_steps 200 \\\n",
        "  -rnn_size 768 # 신경써서 해야함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNQ-hGwQdHdL",
        "outputId": "ee96e7b0-470d-4191-ccb0-9c3b051e2f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-16 12:57:07.334283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 12:57:07.334376: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 12:57:07.334394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[2023-02-16 12:57:09,203 INFO] Device ID 0\n",
            "[2023-02-16 12:57:09,204 INFO] Device cuda\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-02-16 12:57:13,828 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): RNNEncoder(\n",
            "    (rnn): LayerNormLSTM(\n",
            "      (hidden0): ModuleList(\n",
            "        (0): LayerNormLSTMCell(\n",
            "          768, 384\n",
            "          (ln_ih): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_hh): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_ho): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (hidden1): ModuleList(\n",
            "        (0): LayerNormLSTMCell(\n",
            "          768, 384\n",
            "          (ln_ih): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_hh): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_ho): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2023-02-16 12:57:13,897 INFO] * number of parameters: 114177025\n",
            "[2023-02-16 12:57:13,897 INFO] Start training...\n",
            "[2023-02-16 12:57:14,034 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1061.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:18,398 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4507.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:21,580 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5969.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:25,817 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3086.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:28,654 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4782.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:31,153 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_100.pt\n",
            "[2023-02-16 12:57:34,314 INFO] Training Loss 2.297948\n",
            "[2023-02-16 12:57:35,090 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1399.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:38,177 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4626.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:41,439 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1833.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:44,781 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1130.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:48,694 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4328.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:57:51,487 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_200.pt\n",
            "[2023-02-16 12:57:56,182 INFO] Training Loss 2.274303\n",
            "[2023-02-16 12:57:57,282 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5416.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:01,397 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.839.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:04,938 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.752.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:08,321 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4215.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:11,955 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.231.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:13,923 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_300.pt\n",
            "[2023-02-16 12:58:17,620 INFO] Training Loss 2.202384\n",
            "[2023-02-16 12:58:18,345 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2574.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:21,636 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6223.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:25,871 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5560.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:30,652 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3663.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:34,461 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3623.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:35,655 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_400.pt\n",
            "[2023-02-16 12:58:39,024 INFO] Training Loss 2.070545\n",
            "[2023-02-16 12:58:41,252 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1651.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:44,722 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2533.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:48,256 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4147.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:51,620 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2617.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:58:55,146 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_500.pt\n",
            "[2023-02-16 12:58:58,483 INFO] Training Loss 2.012893\n",
            "[2023-02-16 12:58:58,757 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4177.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:01,953 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6313.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:06,103 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5009.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:10,407 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6444.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:14,837 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6045.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:17,281 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_600.pt\n",
            "[2023-02-16 12:59:20,411 INFO] Training Loss 1.941418\n",
            "[2023-02-16 12:59:22,483 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4785.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:25,651 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3520.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:28,984 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5979.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:33,970 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1132.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:37,802 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6491.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:38,480 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_700.pt\n",
            "[2023-02-16 12:59:41,707 INFO] Training Loss 1.890174\n",
            "[2023-02-16 12:59:45,381 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3266.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:48,470 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5664.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:52,829 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1162.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:57,281 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5334.bert.pt, number of examples: 50\n",
            "[2023-02-16 12:59:59,494 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_800.pt\n",
            "[2023-02-16 13:00:03,003 INFO] Training Loss 1.835096\n",
            "[2023-02-16 13:00:04,037 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.608.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:07,399 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4083.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:11,017 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.187.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:13,743 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3867.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:16,830 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.743.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:19,761 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_900.pt\n",
            "[2023-02-16 13:00:23,216 INFO] Training Loss 1.808650\n",
            "[2023-02-16 13:00:24,165 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1584.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:27,075 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1090.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:30,489 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1662.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:34,712 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4840.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:39,033 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6013.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:00:41,336 INFO] Step 1000/ 1000; xent: 1.79; lr: 0.0000632;  23 docs/s;    207 sec\n",
            "[2023-02-16 13:00:41,340 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_1000.pt\n",
            "[2023-02-16 13:00:44,703 INFO] Training Loss 0.000000\n",
            "[2023-02-16 13:00:44,838 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5962.bert.pt, number of examples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5-3 Transformer"
      ],
      "metadata": {
        "id": "BQP6b3cQTO6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = '/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "!python /content/drive/MyDrive/인공지능/추출요약/SRC/train.py \\\n",
        "  -mode train \\\n",
        "  -encoder transformer \\\n",
        "  -dropout 0.1 \\\n",
        "  -bert_data_path /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean \\\n",
        "  -model_path /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer \\\n",
        "  -lr 2e-3 \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -report_every 1000\\\n",
        "  -save_checkpoint_steps 100 \\\n",
        "  -batch_size 1000 \\\n",
        "  -decay_method noam \\\n",
        "  -train_steps 1000 \\\n",
        "  -accum_count 2 \\\n",
        "  -log_file /content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_transformer.txt \\\n",
        "  -use_interval true \\\n",
        "  -warmup_steps 200 \\\n",
        "  -ff_size 2048 \\\n",
        "  -inter_layers 2 \\\n",
        "  -heads 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz5ylGv4TMAK",
        "outputId": "01218369-1d8a-4679-99b2-30031d1498de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-16 13:00:49.733720: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 13:00:49.733830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 13:00:49.733851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[2023-02-16 13:00:51,656 INFO] Device ID 0\n",
            "[2023-02-16 13:00:51,657 INFO] Device cuda\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-02-16 13:00:56,701 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): TransformerInterEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2023-02-16 13:00:56,754 INFO] * number of parameters: 121647617\n",
            "[2023-02-16 13:00:56,754 INFO] Start training...\n",
            "[2023-02-16 13:00:56,901 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1061.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:00,759 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4507.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:03,452 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5969.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:06,477 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3086.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:08,791 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4782.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:10,710 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_100.pt\n",
            "[2023-02-16 13:01:14,301 INFO] Training Loss 2.187751\n",
            "[2023-02-16 13:01:16,455 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1399.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:18,905 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4626.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:21,513 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1833.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:24,290 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1130.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:27,306 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4328.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:29,426 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_200.pt\n",
            "[2023-02-16 13:01:33,046 INFO] Training Loss 2.247146\n",
            "[2023-02-16 13:01:33,974 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5416.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:36,907 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.839.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:39,479 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.752.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:41,826 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4215.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:44,362 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.231.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:45,832 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_300.pt\n",
            "[2023-02-16 13:01:49,480 INFO] Training Loss 2.229245\n",
            "[2023-02-16 13:01:50,218 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2574.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:52,936 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6223.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:56,158 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5560.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:01:59,197 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3663.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:02,095 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3623.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:02,914 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_400.pt\n",
            "[2023-02-16 13:02:06,605 INFO] Training Loss 2.168181\n",
            "[2023-02-16 13:02:08,512 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1651.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:11,387 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2533.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:14,207 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4147.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:16,759 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.2617.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:19,452 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_500.pt\n",
            "[2023-02-16 13:02:22,985 INFO] Training Loss 2.188936\n",
            "[2023-02-16 13:02:23,247 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4177.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:25,712 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6313.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:28,594 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5009.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:31,412 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6444.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:34,546 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6045.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:36,132 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_600.pt\n",
            "[2023-02-16 13:02:39,831 INFO] Training Loss 2.126147\n",
            "[2023-02-16 13:02:41,542 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4785.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:44,201 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3520.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:46,686 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5979.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:50,004 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1132.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:52,879 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6491.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:02:53,327 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_700.pt\n",
            "[2023-02-16 13:02:56,889 INFO] Training Loss 2.137321\n",
            "[2023-02-16 13:02:59,567 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3266.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:02,158 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5664.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:05,380 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1162.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:08,278 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5334.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:09,976 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_800.pt\n",
            "[2023-02-16 13:03:13,731 INFO] Training Loss 2.114011\n",
            "[2023-02-16 13:03:14,631 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.608.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:17,608 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4083.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:20,276 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.187.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:22,415 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.3867.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:25,109 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.743.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:27,350 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_900.pt\n",
            "[2023-02-16 13:03:31,043 INFO] Training Loss 2.102231\n",
            "[2023-02-16 13:03:31,864 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1584.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:34,365 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1090.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:37,260 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.1662.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:40,126 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.4840.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:42,748 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.6013.bert.pt, number of examples: 50\n",
            "[2023-02-16 13:03:44,221 INFO] Step 1000/ 1000; xent: 2.09; lr: 0.0000632;  28 docs/s;    167 sec\n",
            "[2023-02-16 13:03:44,226 INFO] Saving checkpoint /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "[2023-02-16 13:03:48,939 INFO] Training Loss 0.000000\n",
            "[2023-02-16 13:03:49,092 INFO] Loading train dataset from /content/drive/MyDrive/인공지능/추출요약/data/bert_data/train/korean.train.5962.bert.pt, number of examples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 최종 평가 코드\n",
        "- train.py에서 mode를 test로 선택\n",
        "- valid 데이터 사용\n",
        "  - 이때 데이터 이름을 test로 변경해야 진행되므로 `korean.valid.{}.bert.pt` 데이터를 `korean.test.{}.bert.pt` 데이터로 이름 변경\n",
        "- **주의**\n",
        "  - test 시 pyrouge 라이브러리를 통해 rouge score를 계산하게 되는데, Colab 상에서는 dependency 문제로 인해 에러 발생\n",
        "  - 위의 Install libraries 가이드대로 pyrouge 설치 후 SRC, 데이터, 모델을 로컬 디스크에 다운로드 후 로컬에서 실행해야 함\n"
      ],
      "metadata": {
        "id": "dnyw814OTpGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-1. Classifier"
      ],
      "metadata": {
        "id": "XF8C57FEVDRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = '/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "resdirlocation = '/content/drive/MyDrive/인공지능/추출요약/RESULT'\n",
        "os.makedirs(resdirlocation, exist_ok=True)\n",
        "\n",
        "tmpdirlocation = '/content/drive/MyDrive/인공지능/추출요약/TEMP'\n",
        "os.makedirs(tmpdirlocation, exist_ok=True)\n",
        "\n",
        "\n",
        "!python /content/drive/MyDrive/인공지능/추출요약/SRC/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path /content/drive/MyDrive/인공지능/추출요약/data/bert_data/valid/korean \\\n",
        "  -model_path /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier \\\n",
        "  -result_path /content/drive/MyDrive/인공지능/추출요약/RESULT/ \\\n",
        "  -temp_dir /content/drive/MyDrive/인공지능/추출요약/TEMP/ \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -batch_size 30000 \\\n",
        "  -log_file /content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_classifier.txt \\\n",
        "  -test_from /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_1000.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxDeUlEYTkGu",
        "outputId": "84fb1dcd-0ff4-4b28-f454-f0c37c5cecec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-16 13:09:42.578223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 13:09:42.578315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-16 13:09:42.578335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "[2023-02-16 13:09:44,522 INFO] Loading checkpoint from /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_1000.pt\n",
            "Namespace(accum_count=1, batch_size=30000, bert_data_path='/content/drive/MyDrive/인공지능/추출요약/data/bert_data/valid/korean', beta1=0.9, beta2=0.999, block_trigram=True, dataset='', decay_method='', dropout=0.1, encoder='classifier', ff_size=512, gpu_ranks=[0], heads=4, hidden_size=128, input_text='', inter_layers=2, log_file='/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_classifier.txt', lr=1, max_grad_norm=0, mode='test', model_path='/content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='/content/drive/MyDrive/인공지능/추출요약/RESULT/', rnn_size=512, save_checkpoint_steps=5, seed=666, temp_dir='/content/drive/MyDrive/인공지능/추출요약/TEMP/', test_all=False, test_from='/content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_classifier/model_step_1000.pt', train_from='', train_steps=1000, use_interval=True, visible_gpus='0', warmup_steps=8000, world_size=1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/인공지능/추출요약/SRC/train.py\", line 402, in <module>\n",
            "    test(args, device_id, cp, step)\n",
            "  File \"/content/drive/MyDrive/인공지능/추출요약/SRC/train.py\", line 213, in test\n",
            "    test_iter =data_loader.Dataloader(args, load_dataset(args, 'test', shuffle=False),\n",
            "  File \"/content/drive/MyDrive/인공지능/추출요약/SRC/models/data_loader.py\", line 124, in __init__\n",
            "    self.cur_iter = self._next_dataset_iterator(datasets)\n",
            "  File \"/content/drive/MyDrive/인공지능/추출요약/SRC/models/data_loader.py\", line 145, in _next_dataset_iterator\n",
            "    self.cur_dataset = next(dataset_iter)\n",
            "  File \"/content/drive/MyDrive/인공지능/추출요약/SRC/models/data_loader.py\", line 99, in load_dataset\n",
            "    yield _lazy_dataset_loader(pt, corpus_type)\n",
            "  File \"/content/drive/MyDrive/인공지능/추출요약/SRC/models/data_loader.py\", line 83, in _lazy_dataset_loader\n",
            "    dataset = torch.load(pt_file)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 771, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 270, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 251, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/인공지능/추출요약/data/bert_data/valid/korean.test.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-2. RNN"
      ],
      "metadata": {
        "id": "cCvfLymeWKWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = '/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "resdirlocation = '/content/drive/MyDrive/인공지능/추출요약/RESULT'\n",
        "os.makedirs(resdirlocation, exist_ok=True)\n",
        "\n",
        "tmpdirlocation = '/content/drive/MyDrive/인공지능/추출요약/TEMP'\n",
        "os.makedirs(tmpdirlocation, exist_ok=True)\n",
        "\n",
        "\n",
        "!python /content/drive/MyDrive/인공지능/추출요약/SRC/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path /content/drive/MyDrive/인공지능/추출요약/data/bert_data/valid/korean \\\n",
        "  -model_path /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn \\\n",
        "  -result_path /content/drive/MyDrive/인공지능/추출요약/RESULT/ \\\n",
        "  -temp_dir /content/drive/MyDrive/인공지능/추출요약/TEMP/ \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -batch_size 30000 \\\n",
        "  -log_file /content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_rnn.txt \\\n",
        "  -test_from /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_rnn/model_step_1000.pt"
      ],
      "metadata": {
        "id": "FyMltN5mWEOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-3. Transformer"
      ],
      "metadata": {
        "id": "xxHOr5mq7yys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = '/content/drive/MyDrive/인공지능/추출요약/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "resdirlocation = '/content/drive/MyDrive/인공지능/추출요약/RESULT'\n",
        "os.makedirs(resdirlocation, exist_ok=True)\n",
        "\n",
        "tmpdirlocation = '/content/drive/MyDrive/인공지능/추출요약/TEMP'\n",
        "os.makedirs(tmpdirlocation, exist_ok=True)\n",
        "\n",
        "\n",
        "!python /content/drive/MyDrive/인공지능/추출요약/SRC/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path /content/drive/MyDrive/인공지능/추출요약/data/bert_data/valid/korean \\\n",
        "  -model_path /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer \\\n",
        "  -result_path /content/drive/MyDrive/인공지능/추출요약/RESULT/ \\\n",
        "  -temp_dir /content/drive/MyDrive/인공지능/추출요약/TEMP/ \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -batch_size 30000 \\\n",
        "  -log_file /content/drive/MyDrive/인공지능/추출요약/LOG/KLUE/bert_transformer.txt \\\n",
        "  -test_from /content/drive/MyDrive/인공지능/추출요약/MODEL/KLUE/bert_transformer/model_step_1000.pt"
      ],
      "metadata": {
        "id": "hxvdIFGl7xZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 세줄 요약 추론 코드 구현\n",
        "- train.py에서 mode를 inference로 선택\n",
        "- models > trainer.py의 `summ` 함수 참조\n"
      ],
      "metadata": {
        "id": "MPsS9SV37_oI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 추론 결과에 대한 정량적/정성적 평가 \n",
        "- 가장 성능이 좋았던 transformer encoder로 추론\n",
        "- valid.json 중 5개 검증"
      ],
      "metadata": {
        "id": "cDrIsPCj7_lw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVpUYih78B-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}