{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WQYN_92WMhuEKDj8DnhLUQwlsvYPyZTU",
      "authorship_tag": "ABX9TyOQa9Fx2rnTz0A+XpBzS0io",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jx-dohwan/kluebert_Extract_summary/blob/main/kluebert_Extract_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치"
      ],
      "metadata": {
        "id": "5ZBy3xvviYUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mecab"
      ],
      "metadata": {
        "id": "lUMFREYyiu_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install konlpy"
      ],
      "metadata": {
        "id": "Qvf7JdfuiaGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "id": "vc1bORuWinRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install curl git"
      ],
      "metadata": {
        "id": "HEDJMAoriq3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "id": "pvxxuf7PisWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiprocess"
      ],
      "metadata": {
        "id": "Kp1lfZ5GizTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install multiprocess"
      ],
      "metadata": {
        "id": "6Cxum78FitjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers"
      ],
      "metadata": {
        "id": "4J2FY9u7i2tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "MXwPCEKRi1Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyRouge"
      ],
      "metadata": {
        "id": "LTMKtjw8i62a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path '/content/pyrouge/tools/ROUGE-1.5.5'"
      ],
      "metadata": {
        "id": "sey_OHqFi5JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libxml-parser-perl"
      ],
      "metadata": {
        "id": "pdXNcunLi9G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd pyrouge/tools/ROUGE-1.5.5/data\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "cd WordNet-2.0-Exceptions\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "\n",
        "./buildExeptionDB.pl . exc WordNet-2.0.exc.db\n",
        "cd ../\n",
        "ln -s WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db"
      ],
      "metadata": {
        "id": "9r7wRNCEi-QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorboardX"
      ],
      "metadata": {
        "id": "asPxLctOjCi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorboardX"
      ],
      "metadata": {
        "id": "uo3fZ0CUjAIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Source Codes"
      ],
      "metadata": {
        "id": "lspwNGu7jLzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Fast_Campus/ExSum/SRC ."
      ],
      "metadata": {
        "id": "V9ksOpSnjEhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 Import "
      ],
      "metadata": {
        "id": "GkXfgw6JjPjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import easydict"
      ],
      "metadata": {
        "id": "pRAwyKjJjN3I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터\n",
        "\n",
        "\n",
        "###원본 데이터 탐색\n",
        "- 데이터 구성\n",
        "  - 원문 데이터 40만 건 (신문기사 30만 건, 기고문 6만 건, 잡지기사 1만 건, 법원 판결문 3만 건)을 활용하여 각각 추출요약 40만 건, 생성요약 40만 건, 총 80만 건의 요약문 도출\n",
        "  - 원문으로부터 변형 없이 그대로 선택된 3개 문장으로 추출요약문 생성\n",
        "  - 원문의 내용을 바탕으로 재작성된 생성요약문 생성"
      ],
      "metadata": {
        "id": "oyUWdh3CnSei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4aLJuzSjShA",
        "outputId": "2aff24e4-4f2f-4af2-f766-7a10a413bcf7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original_law.json',\n",
              " 'train_original_news.json',\n",
              " 'train_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = filenames[0]\n",
        "filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "with open(filelocation, 'r') as json_file:\n",
        "  data = json.load(json_file) ['documents']"
      ],
      "metadata": {
        "id": "Gq0TJ2fFnzdL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmQwzvMgoBS8",
        "outputId": "a26051a7-8efc-4695-96a1-e0f1868eb1a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '100004',\n",
              " 'category': '일반행정',\n",
              " 'size': 'small',\n",
              " 'char_count': 377,\n",
              " 'publish_date': '19841226',\n",
              " 'title': '부당노동행위구제재심판정취소',\n",
              " 'text': [[{'index': 0,\n",
              "    'sentence': '원고가 소속회사의 노동조합에서 분규가 발생하자 노조활동을 구실로 정상적인 근무를 해태하고,',\n",
              "    'highlight_indices': ''},\n",
              "   {'index': 1, 'sentence': '노조조합장이 사임한 경우,', 'highlight_indices': ''},\n",
              "   {'index': 2,\n",
              "    'sentence': '노동조합규약에 동 조합장의 직무를 대행할 자를 규정해 두고 있음에도 원고 자신이 주동하여 노조자치수습대책위원회를 구성하여 그 위원장으로 피선되어 근무시간중에도 노조활동을 벌여 운수업체인 소속회사의 업무에 지장을 초래하고',\n",
              "    'highlight_indices': '8,9;68,69'},\n",
              "   {'index': 3,\n",
              "    'sentence': '종업원들에게도 나쁜 영향을 끼쳐 소속회사가 취업규칙을 위반하고',\n",
              "    'highlight_indices': ''},\n",
              "   {'index': 4,\n",
              "    'sentence': '고의로 회사업무능률을 저해하였으며 회사업무상의 지휘명령에 위반하였음을 이유로 원고를 징계해고 하였다면,',\n",
              "    'highlight_indices': '0,3'},\n",
              "   {'index': 5,\n",
              "    'sentence': '이는 원고의 노동조합 활동과는 관계없이 회사취업규칙에 의하여 사내질서를 유지하기 위한 사용자 고유의 징계권에 기하여 이루어진 정당한 징계권의 행사로 보아야 한다.',\n",
              "    'highlight_indices': '17,21'}]],\n",
              " 'annotator_id': 3783,\n",
              " 'document_quality_scores': {'readable': 3,\n",
              "  'accurate': 3,\n",
              "  'informative': 3,\n",
              "  'trustworthy': 3},\n",
              " 'extractive': [5, 4, 2],\n",
              " 'abstractive': ['원고가  주동하여 회사업무능률을 저해하고 회사업무상의 지휘명령에 위반하였다면 이에 따른 징계해고는 사내질서를 유지하기 위한 사용자 고유의 정당한 징계권의 행사로 보아야 한다.']}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원본 데이터에서 필요한 값 추출\n",
        "- text와 extractive 추출\n",
        "  - text : 정규식을 이용해 sentence - highlight_indices 사이의 문장 추출한 후 리스트로 저장\n",
        "  - extracive : 3줄 요약에 해당하는 문장 index 3개가 저장된 리스트\n",
        "- 신문기사, 기고문, 법원 판결분 3개로 나누어져 잇는 파일을 하나로 합침\n",
        "  - train, valid 각각에 대해 수행"
      ],
      "metadata": {
        "id": "fZLg_iNCrBEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train 데이터"
      ],
      "metadata": {
        "id": "Bt6iHAncr59u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOkgAtAoEGM",
        "outputId": "42bc6ed5-eed4-4cc4-9d70-7edbff246cc9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original_law.json',\n",
              " 'train_original_news.json',\n",
              " 'train_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_dic = []\n",
        "\n",
        "for file in filenames:\n",
        "  filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "  with open(filelocation, 'r') as json_file:\n",
        "    data = json.load(json_file)['documents']\n",
        "\n",
        "    for x in tqdm (range(len(data))):\n",
        "      text = data[x]['text']\n",
        "      text = str(text).replace('\"', \"'\")\n",
        "\n",
        "      extractive = data[x]['extractive']\n",
        "      for index, value in enumerate(extractive):\n",
        "        if value == None:\n",
        "          extractive[index] = 0\n",
        "\n",
        "      p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "      texts = p.findall(text)\n",
        "\n",
        "      sentences = []\n",
        "      for t in texts:\n",
        "        sentence = t[:-3]\n",
        "        sentences.append(sentence)\n",
        "\n",
        "      mydict = {}\n",
        "      mydict['text'] = sentences\n",
        "      mydict['extractive'] = extractive\n",
        "      list_dic.append(mydict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEFekWp5sLEc",
        "outputId": "de30f163-ef7f-42e3-f5d3-42ad3281cb19"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24329/24329 [00:01<00:00, 14456.38it/s]\n",
            "100%|██████████| 243983/243983 [00:37<00:00, 6487.93it/s] \n",
            "100%|██████████| 56760/56760 [00:09<00:00, 6300.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmg7GrQSu971",
        "outputId": "9394d7fd-7258-4547-a1dc-52f480171ac8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "325072"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train.json\", 'w') as fh:\n",
        "  json.dump(list_dic, fh)"
      ],
      "metadata": {
        "id": "evjSqF9jukmJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def list_chunk(lst, n):\n",
        "#     return [lst[i:i+n] for i in range(0, len(lst), n)]\n",
        "\n",
        "# data_chunked = list_chunk(data, 32507) ## 전체 데이터를 10개로 분할\n",
        "\n",
        "# for i, d in enumerate(data_chunked):\n",
        "#   with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/train.{}.json\".format(i), 'w') as fh:\n",
        "#     json.dump(d, fh)"
      ],
      "metadata": {
        "id": "LrxQT1E4ttHf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### val "
      ],
      "metadata": {
        "id": "K5ML9zfXv70C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/인공지능/추출요약/data/raw_data/valid'\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22bBuDvuc-X",
        "outputId": "73dfd625-8b90-472b-f765-12162e7bb5a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valid_original_law.json',\n",
              " 'valid_original_news.json',\n",
              " 'valid_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_dic = []\n",
        "\n",
        "for file in filenames:\n",
        "  filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "  with open(filelocation, 'r') as json_file:\n",
        "    data = json.load(json_file)['documents']\n",
        "\n",
        "    for x in tqdm (range(len(data))):\n",
        "      text = data[x]['text']\n",
        "      text = str(text).replace('\"', \"'\")\n",
        "\n",
        "      extractive = data[x]['extractive']\n",
        "      for index, value in enumerate(extractive):\n",
        "        if value == None:\n",
        "          extractive[index] = 0\n",
        "\n",
        "      p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "      texts = p.findall(text)\n",
        "\n",
        "      sentences = []\n",
        "      for t in texts:\n",
        "        sentence = t[:-3]\n",
        "        sentences.append(sentence)\n",
        "\n",
        "      mydict = {}\n",
        "      mydict['text'] = sentences\n",
        "      mydict['extractive'] = extractive\n",
        "      list_dic.append(mydict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCjZwdn5wSBY",
        "outputId": "619d4186-4bd7-4d72-e574-38bc6b74598f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3004/3004 [00:00<00:00, 17603.11it/s]\n",
            "100%|██████████| 30122/30122 [00:03<00:00, 9051.91it/s]\n",
            "100%|██████████| 7008/7008 [00:01<00:00, 4894.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/인공지능/추출요약/data/raw_data/valid.json\", 'w') as fh:\n",
        "  json.dump(list_dic, fh)"
      ],
      "metadata": {
        "id": "0c6lPYLLwT-z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1fvadQTwwe61"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}